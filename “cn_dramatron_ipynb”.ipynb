{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daisyinb612/dramatron/blob/main/%E2%80%9Ccn_dramatron_ipynb%E2%80%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BI4R8LJu0NTW"
      },
      "outputs": [],
      "source": [
        "#@title License\n",
        "license = \"\"\"\n",
        "Copyright 2022 DeepMind Technologies Limited\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n",
        "use this file except in compliance with the License. You may obtain a copy of\n",
        "the License at https://www.apache.org/licenses/LICENSE-2.0. Unless required by\n",
        "applicable law or agreed to in writing, software distributed under the License\n",
        "is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
        "KIND, either express or implied. See the License for the specific language\n",
        "governing permissions and limitations under the License.\n",
        "\"\"\"\n",
        "print(license)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smVKjDIBg5l-"
      },
      "source": [
        "# Dramatron\n",
        "\n",
        "**Piotr Mirowski, Kory Mathewson, Juliette Love, Jaylen Pittman**, based on an original prototype by **Richard Evans**.\n",
        "\n",
        "DeepMind, 2022\n",
        "\n",
        "Dramatron is a script writing tool that leverages large language models. It uses hierarchical generation to ensure long range consistency across the entire script. The work was published as a pre-print in Mirowski, Mathewson et al. (2022) \"[Co-Writing Screenplays and Theatre Scripts with Language Models: An Evaluation by Industry Professionals](https://arxiv.org/abs/2209.14958)\".\n",
        "\n",
        "![picture](https://github.com/deepmind/dramatron/raw/main/dramatron_logo.png)\n",
        "\n",
        "## Citing this work (paper and code):\n",
        "```bibtex\n",
        "@article{mirowski2022cowriting,\n",
        "  title={Co-Writing Screenplays and Theatre Scripts with Language Models: An Evaluation by Industry Professionals},\n",
        "  author={Mirowski, Piotr and Mathewson, Kory W and Pittman, Jaylen and Evans, Richard},\n",
        "  journal={arXiv preprint arXiv:2209.14958},\n",
        "  year={2022}\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiVzyJEZHyMs"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Run this set of cells to install and import libraries, define the code, set the parameters of Dramatron and Perspective API (moderation, optional) and the prompt sets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Google PaLM 2 only: Install dependencies (Vertex AI) and restart the colab runtime\n",
        "\n",
        "#@markdown The Python SDK for the Palm 2 API and the Gemini API, is contained in the [`google-generativeai`](https://pypi.org/project/google-generativeai/) package. Install the dependency using pip:\n",
        "!pip install -q -U google-generativeai\n",
        "# !pip install google-cloud-aiplatform --upgrade --user"
      ],
      "metadata": {
        "id": "Qf5r_vaxIr_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7WiSfJBhfnSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0a4faa-5c52-4240-f443-83ce90cb3087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imports imported successfully!\n"
          ]
        }
      ],
      "source": [
        "#@title Imports\n",
        "\n",
        "#@markdown Run this cell to import the required Python libraries.\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "import datetime\n",
        "import difflib\n",
        "import json\n",
        "import re\n",
        "import requests\n",
        "import sys\n",
        "import time\n",
        "from typing import Dict, List, NamedTuple, Optional, Union\n",
        "\n",
        "import collections\n",
        "from google.colab import files\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "print('Imports imported successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-RsP1ZNd3yH6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb4ea519-781b-41fc-9b0b-c41e857140d5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dramatron hyperparameters set.\n"
          ]
        }
      ],
      "source": [
        "#@title Dramatron hyperparameters { run: \"auto\" }\n",
        "\n",
        "#@markdown Run this cell to set the model hyperparameters. The cell will auto-run if you change them. We tested the model with these default values.\n",
        "\n",
        "#@markdown Default seed for generation (default: 1)\n",
        "DEFAULT_SEED =  1  #@param {type:\"integer\"}\n",
        "#@markdown Sampling top-p probability (default: 0.9) and temperature (default 1.0)\n",
        "SAMPLING_PROB =  0.9  #@param {type:\"slider\", min:0.8, max:1.0, step:0.01}\n",
        "SAMPLING_TEMP =  1.  #@param {type:\"slider\", min:0.8, max:1.0, step:0.01}\n",
        "#@markdown Max length for the generated title, place description and others, in tokens (defaults: 64, 128 and 511 respectively)\n",
        "SAMPLE_LENGTH_TITLE = 64 #@param [64, 128, 256, 511]\n",
        "SAMPLE_LENGTH_PLACE = 128 #@param [128, 256, 511]\n",
        "SAMPLE_LENGTH = 511 #@param [128, 256, 511]\n",
        "#@markdown Max lengths during repeated sampling, in case `<end>` is not found (default: 2048)\n",
        "MAX_PARAGRAPH_LENGTH_CHARACTERS = 1024 #@param [511, 1024, 2048, 4096]\n",
        "MAX_PARAGRAPH_LENGTH_SCENES = 1024 #@param [511, 1024, 2048, 4096]\n",
        "MAX_PARAGRAPH_LENGTH = 1024 #@param [511, 1024, 2048, 4096]\n",
        "#@markdown Unavailable API: max number of retries before giving up (default: 10)\n",
        "MAX_RETRIES = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "#@markdown Loop detection: max number of repetitions before resampling, and number of attempts to get out of the loop (default: 3)\n",
        "MAX_NUM_REPETITIONS = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "MAX_NUM_ATTEMPTS_GET_OUT_OF_LOOP = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "\n",
        "print('Dramatron hyperparameters set.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vWwxotb_A1w_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fffe1eb9-bf72-4c9d-d772-03454208ed7b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dramatron set-up complete.\n"
          ]
        }
      ],
      "source": [
        "#@title Dramatron code\n",
        "\n",
        "#@markdown This cell contains Dramatron's code. You need to run it only once.\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Script markers\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# END_MARKER = '<end>'\n",
        "# STOP_MARKER = '<stop>'\n",
        "# CHARACTER_MARKER = '<character>'\n",
        "# DESCRIPTION_MARKER = '<description>'\n",
        "# SCENES_MARKER = '<scenes>'\n",
        "# DIALOG_MARKER = '<dialog>'\n",
        "# TITLE_ELEMENT = 'Title: '\n",
        "# CHARACTERS_ELEMENT = 'Characters: '\n",
        "# DESCRIPTION_ELEMENT = 'Description: '\n",
        "# PLACE_ELEMENT = 'Place: '\n",
        "# PLOT_ELEMENT = 'Plot element: '\n",
        "# PREVIOUS_ELEMENT = 'Previous beat: '\n",
        "# SUMMARY_ELEMENT = 'Summary: '\n",
        "# BEAT_ELEMENT = 'Beat: '\n",
        "END_MARKER = '**END**'\n",
        "STOP_MARKER = '\\n'\n",
        "CHARACTER_MARKER = '**Character:** '\n",
        "DESCRIPTION_MARKER = '**Description:** '\n",
        "SCENES_MARKER = '**Scenes:**'\n",
        "DIALOG_MARKER = '**Dialog:**'\n",
        "LOGLINE_MARKER = \"**Logline:** \"\n",
        "TITLE_ELEMENT = 'Title: '\n",
        "CHARACTERS_ELEMENT = 'Characters: '\n",
        "DESCRIPTION_ELEMENT = 'Description: '\n",
        "PLACE_ELEMENT = 'Place: '\n",
        "PLOT_ELEMENT = 'Plot element: '\n",
        "PREVIOUS_ELEMENT = 'Previous beat: '\n",
        "SUMMARY_ELEMENT = 'Summary: '\n",
        "BEAT_ELEMENT = 'Beat: '\n",
        "LOGLINE_ELEMENT = \"Logline: \"\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Dramatron script entities\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "class Title(NamedTuple):\n",
        "  \"\"\"Title class.\"\"\"\n",
        "\n",
        "  title: str\n",
        "\n",
        "  @classmethod\n",
        "  def from_string(cls, text: str):\n",
        "    title = extract_elements(text, TITLE_ELEMENT, END_MARKER)[0]\n",
        "    return cls(title)\n",
        "\n",
        "  def to_string(self):\n",
        "    s = ''\n",
        "    s += TITLE_ELEMENT + self.title\n",
        "    s += END_MARKER\n",
        "    return s\n",
        "\n",
        "\n",
        "def get_title(title: Title) -> str:\n",
        "  return title.title\n",
        "\n",
        "\n",
        "class Character(NamedTuple):\n",
        "  \"\"\"Character class.\"\"\"\n",
        "\n",
        "  # Name of the character.\n",
        "  name: str\n",
        "\n",
        "  # A single sentence describing the character.\n",
        "  description: str\n",
        "\n",
        "  @classmethod\n",
        "  def from_string(cls, text: str):\n",
        "    elements = text.split(DESCRIPTION_MARKER)\n",
        "    if len(elements) == 2:\n",
        "      name = elements[0].strip()\n",
        "      description = elements[1].strip()\n",
        "      return cls(name, description)\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "\n",
        "def get_character_description(character: Character) -> str:\n",
        "  return character.description\n",
        "\n",
        "\n",
        "class Characters(NamedTuple):\n",
        "  \"\"\"Characters class, containing main characters and their descriptions.\"\"\"\n",
        "\n",
        "  # A dictionary of character descriptions.\n",
        "  character_descriptions: Dict[str, str]\n",
        "\n",
        "  @classmethod\n",
        "  def from_string(cls, text: str):\n",
        "    \"\"\"Parses the characters from the generated text.\"\"\"\n",
        "    text = text.strip()\n",
        "\n",
        "    # Extracts the character descriptions.\n",
        "    character_descriptions = {}\n",
        "    elements = extract_elements(text, CHARACTER_MARKER, STOP_MARKER)\n",
        "    for text_character in elements:\n",
        "      character = Character.from_string(text_character)\n",
        "      if character is not None:\n",
        "        character_descriptions[character.name] = character.description\n",
        "    return cls(character_descriptions)\n",
        "\n",
        "  def to_string(self):\n",
        "    s = '\\n'\n",
        "    for name, description in self.character_descriptions.items():\n",
        "      s += '\\n' + CHARACTER_MARKER + ' ' + name + ' ' + DESCRIPTION_MARKER + ' '\n",
        "      s += description + ' ' + STOP_MARKER + '\\n'\n",
        "    s += END_MARKER\n",
        "    return s\n",
        "\n",
        "\n",
        "def get_character_descriptions(characters: Characters) -> Dict[str, str]:\n",
        "  return characters.character_descriptions\n",
        "\n",
        "\n",
        "class Scene(NamedTuple):\n",
        "  \"\"\"Scene class.\"\"\"\n",
        "\n",
        "  # The name of the place where the scene unfolds.\n",
        "  place: str\n",
        "\n",
        "  # Name of the plot element (e.g., Beginning, Middle, Conclusion).\n",
        "  plot_element: str\n",
        "\n",
        "  # A short description of action/story/dramatic event occuring in the scene.\n",
        "  beat: str\n",
        "\n",
        "  def to_string(self):\n",
        "    s = PLACE_ELEMENT + ' ' + self.place + '\\n'\n",
        "    s += PLOT_ELEMENT + ' ' + self.plot_element + '\\n'\n",
        "    s += BEAT_ELEMENT + ' ' + self.beat + '\\n'\n",
        "    return s\n",
        "\n",
        "\n",
        "class Scenes(NamedTuple):\n",
        "  \"\"\"Scenes class.\"\"\"\n",
        "\n",
        "  # A list of scenes, with place, characters, plot element and beat.\n",
        "  scenes: List[Scene]\n",
        "\n",
        "  @classmethod\n",
        "  def from_string(cls, text: str):\n",
        "    \"\"\"Parse scenes from generated scenes_text.\"\"\"\n",
        "\n",
        "    places = extract_elements(text, PLACE_ELEMENT, PLOT_ELEMENT)\n",
        "    plot_elements = extract_elements(text, PLOT_ELEMENT, BEAT_ELEMENT)\n",
        "    beats = extract_elements(text, BEAT_ELEMENT, '\\n')\n",
        "\n",
        "    # Get the number of complete scenes.\n",
        "    num_complete_scenes = min([len(places), len(plot_elements), len(beats)])\n",
        "    scenes = []\n",
        "    for i in range(num_complete_scenes):\n",
        "      scenes.append(\n",
        "          Scene(Place.format_name(places[i]), plot_elements[i], beats[i]))\n",
        "    scenes = cls(scenes)\n",
        "    return scenes\n",
        "\n",
        "  def to_string(self):\n",
        "    s = ''\n",
        "    for scene in self.scenes:\n",
        "      s += '\\n' + scene.to_string()\n",
        "    s += END_MARKER\n",
        "    return s\n",
        "\n",
        "  def num_places(self):\n",
        "    return len(set([scene.place for scene in self.scenes]))\n",
        "\n",
        "  def num_scenes(self) -> int:\n",
        "    return len(self.scenes)\n",
        "\n",
        "\n",
        "class Place(NamedTuple):\n",
        "  \"\"\"Place class.\"\"\"\n",
        "\n",
        "  # Place name.\n",
        "  name: str\n",
        "\n",
        "  # Place description.\n",
        "  description: str\n",
        "\n",
        "  @classmethod\n",
        "  def format_name(cls, name: str):\n",
        "    if name.find('.') == -1:\n",
        "      name = name + '.'\n",
        "    return name\n",
        "\n",
        "  @classmethod\n",
        "  def from_string(cls, place_name: str, place_text: str):\n",
        "    place_text += END_MARKER\n",
        "    description = extract_elements(place_text, DESCRIPTION_ELEMENT, END_MARKER)\n",
        "    return cls(place_name, description[0])\n",
        "\n",
        "  @classmethod\n",
        "  def format_prefix(cls, name):\n",
        "    s = PLACE_ELEMENT + name + '\\n' + DESCRIPTION_ELEMENT\n",
        "    return s\n",
        "\n",
        "  def to_string(self):\n",
        "    s = self.format_prefix(self.name) + self.description + '\\n\\n'\n",
        "    return s\n",
        "\n",
        "\n",
        "def get_place_description(place: Place):\n",
        "  return place.description\n",
        "\n",
        "\n",
        "class Story(NamedTuple):\n",
        "  \"\"\"Story class.\"\"\"\n",
        "\n",
        "  # A storyline is a single sentence summary of the whole plot.\n",
        "  storyline: str\n",
        "\n",
        "  # A title for the story.\n",
        "  title: str\n",
        "\n",
        "  # Map from character names to full descriptions.\n",
        "  character_descriptions: Dict[str, str]\n",
        "\n",
        "  # Map from place names to full descriptions.\n",
        "  place_descriptions: Dict[str, Place]\n",
        "\n",
        "  # List of scenes.\n",
        "  scenes: Scenes\n",
        "\n",
        "  # List of dialogs, one for each scene.\n",
        "  dialogs: List[str]\n",
        "\n",
        "\n",
        "def extract_elements(text: str, begin: str, end: str) -> List[str]:\n",
        "  \"\"\"Extracts elements from a text string given string and ending markers.\"\"\"\n",
        "\n",
        "  results = []\n",
        "  start = 0\n",
        "  while True:\n",
        "    start = text.find(begin, start)\n",
        "    if start == -1:\n",
        "      return results\n",
        "    finish = text.find(end, start)\n",
        "    if finish == -1:\n",
        "      return results\n",
        "    results.append(text[start + len(begin):finish].strip())\n",
        "    start = finish + len(end)\n",
        "\n",
        "\n",
        "def strip_remove_end(text: str) -> str:\n",
        "  text = text.strip()\n",
        "  end_marker_stripped = END_MARKER.strip()\n",
        "  if text.endswith(end_marker_stripped):\n",
        "    text = text[:-len(end_marker_stripped)]\n",
        "  return text\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Rendering of generated stories\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def render_story(story: Story) -> str:\n",
        "  \"\"\"Render the story in fountain format.\"\"\"\n",
        "\n",
        "  lines = []\n",
        "  lines.append(f'Title: {story.title}')\n",
        "  lines.append('Author: Co-written by ________ and Dramatron')\n",
        "  lines.append(\n",
        "      'Dramatron was developed by Piotr Mirowski and Kory W. Mathewson, '\n",
        "      'with additional contributions by Juliette Love and Jaylen Pittman, '\n",
        "      'and is based on a prototype by Richard Evans.')\n",
        "  lines.append('Dramatron relies on user-provided language models.')\n",
        "  lines.append('')\n",
        "  lines.append('====')\n",
        "  lines.append('')\n",
        "\n",
        "  lines.append(f'The script is based on the storyline:\\n{story.storyline}')\n",
        "  lines.append('')\n",
        "  if story.character_descriptions is not None:\n",
        "    for name, description in story.character_descriptions.items():\n",
        "      lines.append(f'{name}: {description}')\n",
        "      lines.append('')\n",
        "\n",
        "  # For each scene, render scene information.\n",
        "  if story.scenes is not None:\n",
        "    scenes = story.scenes.scenes\n",
        "    for i, scene in enumerate(scenes):\n",
        "      lines.append(f'Scene {i+1}')\n",
        "      lines.append(f'{PLACE_ELEMENT}{scene.place}')\n",
        "      lines.append(f'{PLOT_ELEMENT}{scene.plot_element}')\n",
        "      lines.append(f'{BEAT_ELEMENT}{scene.beat}')\n",
        "      lines.append('')\n",
        "  else:\n",
        "    scenes = []\n",
        "\n",
        "  lines.append('====')\n",
        "  lines.append('')\n",
        "\n",
        "  # For each scene, render the scene's place description, characters and dialog.\n",
        "  for i, scene in enumerate(scenes):\n",
        "\n",
        "    # Output the places and place descriptions.\n",
        "    lines.append(f'INT/EXT. {scene.place} - Scene {i+1}')\n",
        "    place_descriptions = story.place_descriptions\n",
        "    if (not place_appears_earlier(scene.place, story, i) and\n",
        "        place_descriptions is not None and scene.place in place_descriptions):\n",
        "      lines.append('')\n",
        "      lines.append(get_place_description(place_descriptions[scene.place]))\n",
        "\n",
        "    # Output the characters and descriptions.\n",
        "    lines.append('')\n",
        "    for c in story.character_descriptions.keys():\n",
        "      if c in scene.beat and not character_appears_earlier(c, story, i):\n",
        "        lines.append(story.character_descriptions[c])\n",
        "\n",
        "    # Output the dialog.\n",
        "    if story.dialogs is not None and len(story.dialogs) > i:\n",
        "      lines.append('')\n",
        "      lines_dialog = strip_remove_end(str(story.dialogs[i]))\n",
        "      lines.append(lines_dialog)\n",
        "      lines.append('')\n",
        "      lines.append('')\n",
        "\n",
        "  return '\\n'.join(lines)\n",
        "\n",
        "\n",
        "def place_appears_earlier(place: str, story: Story, index: int) -> bool:\n",
        "  \"\"\"Return True if the place appears earlier in the story.\"\"\"\n",
        "\n",
        "  for i in range(index):\n",
        "    scene = story.scenes.scenes[i]\n",
        "    if scene.place == place:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def character_appears_earlier(character: str, story: Story, index: int) -> bool:\n",
        "  \"\"\"Return True if the character appears earlier in the story.\"\"\"\n",
        "\n",
        "  for i in range(index):\n",
        "    scene = story.scenes.scenes[i]\n",
        "    if character in scene.beat:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def render_prompts(prompts):\n",
        "  \"\"\"Render the prompts.\"\"\"\n",
        "\n",
        "  def _format_prompt(prompt, name):\n",
        "    prompt_str = '=' * 80 + '\\n'\n",
        "    prompt_str += 'PROMPT (' + name + ')\\n'\n",
        "    prompt_str += '=' * 80 + '\\n\\n'\n",
        "    prompt_str += str(prompt) + '\\n\\n'\n",
        "    return prompt_str\n",
        "\n",
        "  prompts_str = _format_prompt(prompts['title'], 'title')\n",
        "  prompts_str += _format_prompt(prompts['characters'], 'characters')\n",
        "  prompts_str += _format_prompt(prompts['scenes'], 'scenes')\n",
        "  places = prompts['places']\n",
        "  if places is not None:\n",
        "    for k, prompt in enumerate(places):\n",
        "      prompts_str += _format_prompt(prompt, 'place ' + str(k + 1))\n",
        "  dialogs = prompts['dialogs']\n",
        "  if dialogs is not None:\n",
        "    for k, prompt in enumerate(dialogs):\n",
        "      prompts_str += _format_prompt(prompt, 'dialog ' + str(k + 1))\n",
        "  return prompts_str\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Language API definition\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "_MAX_RETRIES = 10\n",
        "_TIMEOUT = 120.0\n",
        "\n",
        "\n",
        "class LanguageResponse(NamedTuple):\n",
        "  prompt: str\n",
        "  prompt_length: int\n",
        "  text: str\n",
        "  text_length: int\n",
        "\n",
        "\n",
        "class LanguageAPI:\n",
        "  \"\"\"Language model wrapper.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               sample_length: int,\n",
        "               model: Optional[str] = None,\n",
        "               model_param: Optional[str] = None,\n",
        "               config_sampling: Optional[dict] = None,\n",
        "               seed: Optional[int] = None,\n",
        "               max_retries: int = _MAX_RETRIES,\n",
        "               timeout: float = _TIMEOUT):\n",
        "    \"\"\"Initializer.\n",
        "\n",
        "    Args:\n",
        "      sample_length: Length of text to sample from model.\n",
        "      model: The model name to correct to. An error will be raised if it does\n",
        "        not exist.\n",
        "      model_param: Model parameter.\n",
        "      config_sampling: Sampleing parameters.\n",
        "      seed: Random seed for sampling.\n",
        "      max_retries: Maximum number of retries for the remote API.\n",
        "      timeout: Maximum waiting timeout\n",
        "    \"\"\"\n",
        "    self._sample_length = sample_length\n",
        "    self._model = model\n",
        "    self._model_param = model_param\n",
        "    self._config_sampling = config_sampling\n",
        "    self._seed = seed\n",
        "    self._max_retries = max_retries\n",
        "    self._timeout = timeout\n",
        "\n",
        "  @property\n",
        "  def default_sample_length(self):\n",
        "    return self._sample_length\n",
        "\n",
        "  @property\n",
        "  def model(self):\n",
        "    return self._model\n",
        "\n",
        "  @property\n",
        "  def model_param(self):\n",
        "    return self._model_param\n",
        "\n",
        "  @property\n",
        "  def model_metadata(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def seed(self):\n",
        "    return self._seed\n",
        "\n",
        "  @property\n",
        "  def config_sampling(self):\n",
        "    return self._config_sampling\n",
        "\n",
        "  def sample(self,\n",
        "             prompt: str,\n",
        "             sample_length: Optional[int] = None,\n",
        "             seed: Optional[int] = None,\n",
        "             num_samples: int = 1):\n",
        "    \"\"\"Sample model with provided prompt, optional sample_length and seed.\"\"\"\n",
        "    raise NotImplementedError('sample method not implemented in generic class')\n",
        "\n",
        "\n",
        "class FilterAPI:\n",
        "  \"\"\"Filter model wrapper.\"\"\"\n",
        "\n",
        "  def validate(self, text: str):\n",
        "    raise NotImplementedError('validate not implemented in generic class')\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Dramatron Generator\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def generate_text(generation_prompt: str,\n",
        "                  client: LanguageAPI,\n",
        "                  filter: Optional[FilterAPI] = None,\n",
        "                  sample_length: Optional[int] = None,\n",
        "                  max_paragraph_length: int = MAX_PARAGRAPH_LENGTH,\n",
        "                  seed: Optional[int] = None,\n",
        "                  num_samples: int = 1,\n",
        "                  max_num_repetitions: Optional[int] = None) -> str:\n",
        "  \"\"\"Generate text using the generation prompt.\"\"\"\n",
        "\n",
        "  # To prevent lengthy generation loops, we cap the number of calls to the API.\n",
        "  if sample_length is None:\n",
        "    sample_length = client.default_sample_length\n",
        "  max_num_calls = int(max_paragraph_length / sample_length) + 1\n",
        "  num_calls = 0\n",
        "\n",
        "  result = ''\n",
        "  while True:\n",
        "    prompt = generation_prompt + result\n",
        "    success, current_seed = False, seed\n",
        "    while success is False:\n",
        "      t0 = time.time()\n",
        "      responses = client.sample(\n",
        "          prompt=prompt,\n",
        "          sample_length=sample_length,\n",
        "          seed=current_seed,\n",
        "          num_samples=num_samples)\n",
        "      t1 = time.time()\n",
        "      # Get the first result from the list of responses\n",
        "      response = responses[0]\n",
        "      if filter is not None and not filter.validate(response.text):\n",
        "        return 'Content was filtered out.' + END_MARKER\n",
        "      if max_num_repetitions:\n",
        "        success = not detect_loop(\n",
        "            response.text, max_num_repetitions=max_num_repetitions)\n",
        "        if not success:\n",
        "          current_seed += 1\n",
        "          if current_seed > (seed + MAX_NUM_ATTEMPTS_GET_OUT_OF_LOOP):\n",
        "            success = True\n",
        "          else:\n",
        "            continue\n",
        "      else:\n",
        "        success = True\n",
        "\n",
        "    result = result + response.text\n",
        "    num_calls += 1\n",
        "\n",
        "    # Attempt to find the END_MARKER\n",
        "    index = result.find(END_MARKER)\n",
        "    if index != -1:\n",
        "      return result[:index] + END_MARKER\n",
        "\n",
        "    # Attempt to find the start of a new example\n",
        "    index = result.find('Example ')\n",
        "    if index != -1:\n",
        "      return result[:index] + END_MARKER\n",
        "\n",
        "    if max_paragraph_length is not None and len(result) > max_paragraph_length:\n",
        "      return result + END_MARKER\n",
        "    if num_calls >= max_num_calls:\n",
        "      return result + END_MARKER\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "def generate_text_no_loop(generation_prompt: str,\n",
        "                          client: LanguageAPI,\n",
        "                          filter: Optional[FilterAPI] = None,\n",
        "                          sample_length: Optional[int] = None,\n",
        "                          max_paragraph_length: int = MAX_PARAGRAPH_LENGTH,\n",
        "                          seed: Optional[int] = None,\n",
        "                          num_samples: int = 1) -> str:\n",
        "  \"\"\"Generate text using the generation prompt, without any loop.\"\"\"\n",
        "  return generate_text(\n",
        "      generation_prompt=generation_prompt,\n",
        "      client=client,\n",
        "      filter=filter,\n",
        "      sample_length=sample_length,\n",
        "      max_paragraph_length=sample_length,\n",
        "      seed=seed,\n",
        "      max_num_repetitions=None,\n",
        "      num_samples=num_samples)\n",
        "\n",
        "\n",
        "def generate_title(storyline: str,\n",
        "                   prefixes: Dict[str, str],\n",
        "                   client: LanguageAPI,\n",
        "                   filter: Optional[FilterAPI] = None,\n",
        "                   seed: Optional[int] = None,\n",
        "                   num_samples: int = 1):\n",
        "  \"\"\"Generate a title given a storyline, and client.\"\"\"\n",
        "\n",
        "  # Combine the prompt and storyline as a helpful generation prefix\n",
        "  titles_prefix = prefixes['TITLES_PROMPT'] + storyline + ' ' + TITLE_ELEMENT\n",
        "  title_text = generate_text_no_loop(\n",
        "      generation_prompt=titles_prefix,\n",
        "      client=client,\n",
        "      filter=filter,\n",
        "      sample_length=SAMPLE_LENGTH_TITLE,\n",
        "      seed=seed,\n",
        "      num_samples=num_samples)\n",
        "  title = Title.from_string(TITLE_ELEMENT + title_text)\n",
        "  return (title, titles_prefix)\n",
        "\n",
        "\n",
        "def generate_characters(\n",
        "    storyline: str,\n",
        "    prefixes: Dict[str, str],\n",
        "    client: LanguageAPI,\n",
        "    filter: Optional[FilterAPI] = None,\n",
        "    seed: Optional[int] = None,\n",
        "    max_paragraph_length: int = (MAX_PARAGRAPH_LENGTH_CHARACTERS),\n",
        "    num_samples: int = 1):\n",
        "  \"\"\"Generate characters given a storyline, prompt, and client.\"\"\"\n",
        "\n",
        "  # Combine the prompt and storyline as a helpful generation prefix\n",
        "  characters_prefix = prefixes['CHARACTERS_PROMPT'] + storyline\n",
        "  characters_text = generate_text(\n",
        "      generation_prompt=characters_prefix,\n",
        "      client=client,\n",
        "      filter=filter,\n",
        "      seed=seed,\n",
        "      max_paragraph_length=max_paragraph_length,\n",
        "      num_samples=num_samples)\n",
        "  characters = Characters.from_string(characters_text)\n",
        "\n",
        "  return (characters, characters_prefix)\n",
        "\n",
        "\n",
        "def generate_scenes(storyline: str,\n",
        "                    character_descriptions: Dict[str, str],\n",
        "                    prefixes: Dict[str, str],\n",
        "                    client: LanguageAPI,\n",
        "                    filter: Optional[FilterAPI] = None,\n",
        "                    seed: Optional[int] = None,\n",
        "                    max_paragraph_length: int = (MAX_PARAGRAPH_LENGTH_SCENES),\n",
        "                    num_samples: int = 1):\n",
        "  \"\"\"Generate scenes given storyline, prompt, main characters, and client.\"\"\"\n",
        "\n",
        "  scenes_prefix = prefixes['SCENE_PROMPT'] + storyline + '\\n'\n",
        "  for name in character_descriptions:\n",
        "    scenes_prefix += character_descriptions[name] + '\\n'\n",
        "  scenes_prefix += '\\n' + SCENES_MARKER\n",
        "  scenes_text = generate_text(\n",
        "      generation_prompt=scenes_prefix,\n",
        "      client=client,\n",
        "      filter=filter,\n",
        "      seed=seed,\n",
        "      max_paragraph_length=max_paragraph_length,\n",
        "      num_samples=num_samples)\n",
        "  scenes = Scenes.from_string(scenes_text)\n",
        "\n",
        "  return (scenes, scenes_prefix)\n",
        "\n",
        "\n",
        "def generate_place_descriptions(storyline: str,\n",
        "                                scenes: Scenes,\n",
        "                                prefixes: Dict[str, str],\n",
        "                                client: LanguageAPI,\n",
        "                                filter: Optional[FilterAPI] = None,\n",
        "                                seed: Optional[int] = None,\n",
        "                                num_samples: int = 1):\n",
        "  \"\"\"Generate a place description given a scene object and a client.\"\"\"\n",
        "\n",
        "  place_descriptions = {}\n",
        "\n",
        "  # Get unique place names from the scenes.\n",
        "  unique_place_names = set([scene.place for scene in scenes.scenes])\n",
        "\n",
        "  # Build a unique place prefix prompt.\n",
        "  place_prefix = prefixes['SETTING_PROMPT'] + storyline + '\\n'\n",
        "\n",
        "  # Build a list of place descriptions for each place\n",
        "  place_prefixes = []\n",
        "  for place_name in unique_place_names:\n",
        "    place_suffix = Place.format_prefix(place_name)\n",
        "    place_text = generate_text(\n",
        "        generation_prompt=place_prefix + place_suffix,\n",
        "        client=client,\n",
        "        filter=filter,\n",
        "        sample_length=SAMPLE_LENGTH_PLACE,\n",
        "        seed=seed,\n",
        "        num_samples=num_samples)\n",
        "    place_text = place_suffix + place_text\n",
        "    place_descriptions[place_name] = Place.from_string(place_name, place_text)\n",
        "    place_prefixes.append(place_prefix + place_suffix)\n",
        "\n",
        "  return (place_descriptions, place_prefixes)\n",
        "\n",
        "\n",
        "def prefix_summary(storyline: str,\n",
        "                   scenes: List[Scene],\n",
        "                   concatenate_scenes_in_summary: bool = False) -> str:\n",
        "  \"\"\"Assemble the summary part of the dialog prefix.\"\"\"\n",
        "\n",
        "  summary = SUMMARY_ELEMENT + storyline + '\\n'\n",
        "  if len(scenes) > 1:\n",
        "    summary += PREVIOUS_ELEMENT + scenes[len(scenes) - 2].beat + '\\n'\n",
        "  return summary\n",
        "\n",
        "\n",
        "def detect_loop(text: str, max_num_repetitions: int = MAX_NUM_REPETITIONS):\n",
        "  \"\"\"Detect loops in generated text.\"\"\"\n",
        "\n",
        "  blocks = text.split('\\n\\n')\n",
        "  num_unique_blocks = collections.Counter(blocks)\n",
        "  for block in blocks:\n",
        "    num_repetitions = num_unique_blocks[block]\n",
        "    if num_repetitions > max_num_repetitions:\n",
        "      print(f'Detected {num_repetitions} repetitions of block:\\n{block}')\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def generate_dialog(storyline: str,\n",
        "                    scenes: List[Scene],\n",
        "                    character_descriptions: Dict[str, str],\n",
        "                    place_descriptions: Dict[str, Place],\n",
        "                    prefixes: Dict[str, str],\n",
        "                    max_paragraph_length: int,\n",
        "                    client: LanguageAPI,\n",
        "                    filter: Optional[FilterAPI] = None,\n",
        "                    max_num_repetitions: Optional[int] = None,\n",
        "                    seed: Optional[int] = None,\n",
        "                    num_samples: int = 1):\n",
        "  \"\"\"Generate dialog given a scene object and a client.\"\"\"\n",
        "\n",
        "  scene = scenes[-1]\n",
        "\n",
        "  place_t = PLACE_ELEMENT + scene.place + '\\n'\n",
        "  if scene.place in place_descriptions:\n",
        "    place_description = place_descriptions[scene.place]\n",
        "    if place_description:\n",
        "      place_t += DESCRIPTION_ELEMENT + place_description.description\n",
        "      place_t += '\\n'\n",
        "\n",
        "  # Build the characters information for the scene\n",
        "  characters_t = ''\n",
        "  if character_descriptions:\n",
        "    characters_t += CHARACTERS_ELEMENT\n",
        "    for name in character_descriptions:\n",
        "      if name in scene.beat:\n",
        "        characters_t += character_descriptions[name] + '\\n'\n",
        "\n",
        "  plot_element_t = PLOT_ELEMENT + scene.plot_element + '\\n'\n",
        "\n",
        "  summary_t = prefix_summary(\n",
        "      storyline, scenes, concatenate_scenes_in_summary=False)\n",
        "\n",
        "  beat_t = BEAT_ELEMENT + scene.beat + '\\n'\n",
        "\n",
        "  dialog_prefix = (\n",
        "      prefixes['DIALOG_PROMPT'] + place_t + characters_t + plot_element_t +\n",
        "      summary_t + beat_t)\n",
        "  dialog_prefix += '\\n' + DIALOG_MARKER + '\\n'\n",
        "\n",
        "  dialog = generate_text(\n",
        "      generation_prompt=dialog_prefix,\n",
        "      client=client,\n",
        "      filter=filter,\n",
        "      seed=seed,\n",
        "      max_paragraph_length=max_paragraph_length,\n",
        "      max_num_repetitions=max_num_repetitions,\n",
        "      num_samples=num_samples)\n",
        "\n",
        "  return (dialog, dialog_prefix)\n",
        "\n",
        "\n",
        "def diff_prompt_change_str(prompt_before: str, prompt_after: str) -> str:\n",
        "  \"\"\"Return a text diff on prompt sets `prompt_before` and `prompt_after`.\"\"\"\n",
        "\n",
        "  # For the current element, compare prompts line by line.\n",
        "  res = difflib.unified_diff(\n",
        "      prompt_before.split('\\n'), prompt_after.split('\\n'))\n",
        "  diff = ''\n",
        "  for line in res:\n",
        "    line = line.strip()\n",
        "    if line != '---' and line != '+++' and not line.startswith('@@'):\n",
        "      if len(line) > 1 and (line.startswith('+') or line.startswith('-')):\n",
        "        diff += line + '\\n'\n",
        "  if diff.endswith('\\n'):\n",
        "    diff = diff[:-1]\n",
        "  return diff\n",
        "\n",
        "\n",
        "def diff_prompt_change_list(prompt_before: List[str],\n",
        "                            prompt_after: List[str]) -> str:\n",
        "  \"\"\"Return a text diff on prompt sets `prompt_before` and `prompt_after`.\"\"\"\n",
        "\n",
        "  # Handle deletions and insertions.\n",
        "  len_before = len(prompt_before)\n",
        "  len_after = len(prompt_after)\n",
        "  if len_before > len_after:\n",
        "    return 'Deleted element'\n",
        "  if len_before < len_after:\n",
        "    return 'Added new element'\n",
        "\n",
        "  diffs = [\n",
        "      diff_prompt_change_str(a, b)\n",
        "      for (a, b) in zip(prompt_before, prompt_after)\n",
        "  ]\n",
        "  return '\\n'.join([diff for diff in diffs if len(diff) > 0])\n",
        "\n",
        "\n",
        "def diff_prompt_change_scenes(prompt_before: List[Scene],\n",
        "                              prompt_after: List[Scene]) -> str:\n",
        "  \"\"\"Return a text diff on prompt sets `prompt_before` and `prompt_after`.\"\"\"\n",
        "\n",
        "  # Handle deletions and insertions.\n",
        "  len_before = len(prompt_before)\n",
        "  len_after = len(prompt_after)\n",
        "  if len_before > len_after:\n",
        "    return 'Deleted element'\n",
        "  if len_before < len_after:\n",
        "    return 'Added new element'\n",
        "\n",
        "  diffs = [\n",
        "      diff_prompt_change_list([a.place, a.plot_element, a.beat],\n",
        "                              [b.place, b.plot_element, b.beat])\n",
        "      for (a, b) in zip(prompt_before, prompt_after)\n",
        "  ]\n",
        "  return '\\n'.join([diff for diff in diffs if len(diff) > 0])\n",
        "\n",
        "\n",
        "def diff_prompt_change_dict(prompt_before: Dict[str, str],\n",
        "                            prompt_after: Dict[str, str]) -> str:\n",
        "  \"\"\"Return a text diff on prompt sets `prompt_before` and `prompt_after`.\"\"\"\n",
        "\n",
        "  # Loop over the keys in the prompts to compare them one by one.\n",
        "  keys_before = sorted(prompt_before.keys())\n",
        "  keys_after = sorted(prompt_after.keys())\n",
        "  diffs = [\n",
        "      diff_prompt_change_str(a, b) for (a, b) in zip(keys_before, keys_after)\n",
        "  ]\n",
        "  diff_keys = '\\n'.join([diff for diff in diffs if len(diff) > 0])\n",
        "  # Loop over the values in the prompts to compare them one by one.\n",
        "  values_before = sorted(prompt_before.values())\n",
        "  values_after = sorted(prompt_after.values())\n",
        "  diffs = [\n",
        "      diff_prompt_change_str(a, b)\n",
        "      for (a, b) in zip(values_before, values_after)\n",
        "  ]\n",
        "  diff_values = '\\n'.join([diff for diff in diffs if len(diff) > 0])\n",
        "  return diff_keys + diff_values\n",
        "\n",
        "\n",
        "class StoryGenerator:\n",
        "  \"\"\"Generate a story from the provided storyline, using the client provided.\"\"\"\n",
        "\n",
        "  level_names = ('storyline', 'title', 'characters', 'scenes', 'places',\n",
        "                 'dialogs')\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      storyline: str,\n",
        "      prefixes: Dict[str, str],\n",
        "      max_paragraph_length: int = 1024,\n",
        "      max_paragraph_length_characters: int = (MAX_PARAGRAPH_LENGTH_CHARACTERS),\n",
        "      max_paragraph_length_scenes: int = (MAX_PARAGRAPH_LENGTH_SCENES),\n",
        "      num_samples: int = 1,\n",
        "      client: Optional[LanguageAPI] = None,\n",
        "      filter: Optional[FilterAPI] = None):\n",
        "    self._prefixes = prefixes\n",
        "    self._max_paragraph_length = max_paragraph_length\n",
        "    self._max_paragraph_length_characters = max_paragraph_length_characters\n",
        "    self._max_paragraph_length_scenes = max_paragraph_length_scenes\n",
        "    self._num_samples = num_samples\n",
        "    self._client = client\n",
        "    self._filter = filter\n",
        "\n",
        "    # Prompts and outputs of the hierarchical generator are organised in levels.\n",
        "    self.prompts = {\n",
        "        'title': '',\n",
        "        'characters': '',\n",
        "        'scenes': '',\n",
        "        'places': {\n",
        "            '': ''\n",
        "        },\n",
        "        'dialogs': ['']\n",
        "    }\n",
        "    self._title = Title('')\n",
        "    self._characters = Characters({'': ''})\n",
        "    self._scenes = Scenes([Scene('', '', '')])\n",
        "    self._places = {'': Place('', '')}\n",
        "    self._dialogs = ['']\n",
        "\n",
        "    # History of interventions.\n",
        "    self.interventions = {}\n",
        "    self._set_storyline(storyline)\n",
        "\n",
        "  def _set_storyline(self, storyline: str):\n",
        "    \"\"\"Set storyline and initialise the outputs of the generator.\"\"\"\n",
        "    self._level = 0\n",
        "\n",
        "    # Add period to the end of the storyline, unless there is already one there.\n",
        "    if storyline.find('.') == -1:\n",
        "      storyline = storyline + '.'\n",
        "    self._storyline = storyline\n",
        "\n",
        "    # Keep track of each storyline intervention.\n",
        "    timestamp = time.time()\n",
        "    self.interventions[timestamp] = 'STORYLINE\\n' + storyline\n",
        "\n",
        "  @property\n",
        "  def seed(self):\n",
        "    return self._client.seed\n",
        "\n",
        "  @property\n",
        "  def title(self) -> Title:\n",
        "    \"\"\"Return the title.\"\"\"\n",
        "    return self._title\n",
        "\n",
        "  @property\n",
        "  def characters(self) -> Characters:\n",
        "    \"\"\"Return the characters.\"\"\"\n",
        "    return self._characters\n",
        "\n",
        "  @property\n",
        "  def scenes(self) -> Scenes:\n",
        "    \"\"\"Return the title.\"\"\"\n",
        "    return self._scenes\n",
        "\n",
        "  @property\n",
        "  def places(self) -> Dict[str, Place]:\n",
        "    \"\"\"Return the places.\"\"\"\n",
        "    return self._places\n",
        "\n",
        "  @property\n",
        "  def dialogs(self) -> List[str]:\n",
        "    \"\"\"Return the dialogs.\"\"\"\n",
        "    return self._dialogs\n",
        "\n",
        "  def title_str(self) -> str:\n",
        "    \"\"\"Return the title as a string.\"\"\"\n",
        "    return self._title.title\n",
        "\n",
        "  def num_scenes(self) -> int:\n",
        "    \"\"\"Return the number of scenes.\"\"\"\n",
        "    return self._scenes.num_scenes()\n",
        "\n",
        "  def step(self,\n",
        "           level: Optional[int] = None,\n",
        "           seed: Optional[int] = None,\n",
        "           idx: Optional[int] = None) -> bool:\n",
        "    \"\"\"Step down a level in the hierarchical generation of a story.\"\"\"\n",
        "\n",
        "    # Move to the next level of hierarchical generation.\n",
        "    if level is None:\n",
        "      level = self._level\n",
        "    if level < 0 or level >= len(self.level_names):\n",
        "      raise ValueError('Invalid level encountered on step.')\n",
        "    level += 1\n",
        "    self._level = level\n",
        "\n",
        "    # Keep track of each step intervention.\n",
        "    timestamp = time.time()\n",
        "    self.interventions[timestamp] = 'STEP ' + str(level) + '\\n'\n",
        "\n",
        "    if level == 1:\n",
        "      # Step 1: Generate title given a storyline.\n",
        "      (title, titles_prefix) = generate_title(\n",
        "          storyline=self._storyline,\n",
        "          prefixes=self._prefixes,\n",
        "          client=self._client,\n",
        "          filter=self._filter,\n",
        "          num_samples=self._num_samples,\n",
        "          seed=seed)\n",
        "      self._title = title\n",
        "      self.prompts['title'] = titles_prefix\n",
        "      self.interventions[timestamp] += title.to_string()\n",
        "      success = len(title.title) > 0\n",
        "      return success\n",
        "\n",
        "    if level == 2:\n",
        "      # Step 2: Generate characters given a storyline.\n",
        "      (characters, character_prompts) = generate_characters(\n",
        "          storyline=self._storyline,\n",
        "          prefixes=self._prefixes,\n",
        "          client=self._client,\n",
        "          filter=self._filter,\n",
        "          num_samples=self._num_samples,\n",
        "          max_paragraph_length=self._max_paragraph_length_characters,\n",
        "          seed=seed)\n",
        "      self._characters = characters\n",
        "      self.prompts['characters'] = character_prompts\n",
        "      self.interventions[timestamp] += characters.to_string()\n",
        "      success = len(characters.character_descriptions) > 0\n",
        "      return success\n",
        "\n",
        "    if level == 3:\n",
        "      # Step 3: Generate sequence of scenes given a storyline and characters.\n",
        "      characters = self._characters\n",
        "      (scenes, scene_prompts) = generate_scenes(\n",
        "          storyline=self._storyline,\n",
        "          character_descriptions=get_character_descriptions(characters),\n",
        "          prefixes=self._prefixes,\n",
        "          client=self._client,\n",
        "          filter=self._filter,\n",
        "          num_samples=self._num_samples,\n",
        "          max_paragraph_length=self._max_paragraph_length_scenes,\n",
        "          seed=seed)\n",
        "      self._scenes = scenes\n",
        "      self.prompts['scenes'] = scene_prompts\n",
        "      self.interventions[timestamp] += scenes.to_string()\n",
        "      success = len(scenes.scenes) > 0\n",
        "      return success\n",
        "\n",
        "    if level == 4:\n",
        "      # Step 4: For each scene, generate place descriptions given place name.\n",
        "      scenes = self._scenes\n",
        "      (place_descriptions, place_prompts) = generate_place_descriptions(\n",
        "          storyline=self._storyline,\n",
        "          scenes=scenes,\n",
        "          prefixes=self._prefixes,\n",
        "          client=self._client,\n",
        "          filter=self._filter,\n",
        "          num_samples=self._num_samples,\n",
        "          seed=seed)\n",
        "      self._places = place_descriptions\n",
        "      self.prompts['places'] = place_prompts\n",
        "      for place_name in place_descriptions:\n",
        "        place = place_descriptions[place_name]\n",
        "        if place:\n",
        "          self.interventions[timestamp] += place.to_string()\n",
        "      num_places = scenes.num_places()\n",
        "      success = (len(place_descriptions) == num_places) and num_places > 0\n",
        "      return success\n",
        "\n",
        "    if level == 5:\n",
        "      # Step 5: For each scene, generate dialog from scene information.\n",
        "      title = self._title\n",
        "      characters = self._characters\n",
        "      scenes = self._scenes\n",
        "      place_descriptions = self._places\n",
        "      if idx is None:\n",
        "        (dialogs, dialog_prompts) = zip(*[\n",
        "            generate_dialog(\n",
        "                storyline=self._storyline,\n",
        "                scenes=scenes.scenes[:(k + 1)],\n",
        "                character_descriptions=(characters.character_descriptions),\n",
        "                place_descriptions=place_descriptions,\n",
        "                prefixes=self._prefixes,\n",
        "                max_paragraph_length=self._max_paragraph_length,\n",
        "                max_num_repetitions=MAX_NUM_REPETITIONS,\n",
        "                client=self._client,\n",
        "                filter=self._filter,\n",
        "                num_samples=self._num_samples,\n",
        "                seed=seed) for k in range(len(scenes.scenes))\n",
        "        ])\n",
        "      else:\n",
        "        num_scenes = self._scenes.num_scenes()\n",
        "        while len(self._dialogs) < num_scenes:\n",
        "          self._dialogs.append('')\n",
        "        while len(self.prompts['dialogs']) < num_scenes:\n",
        "          self.prompts['dialogs'].append('')\n",
        "        if idx >= num_scenes or idx < 0:\n",
        "          raise ValueError('Invalid scene index.')\n",
        "        dialogs = self._dialogs\n",
        "        dialog_prompts = self.prompts['dialogs']\n",
        "        dialogs[idx], dialog_prompts[idx] = generate_dialog(\n",
        "            storyline=self._storyline,\n",
        "            scenes=scenes.scenes[:(idx + 1)],\n",
        "            character_descriptions=(characters.character_descriptions),\n",
        "            place_descriptions=place_descriptions,\n",
        "            prefixes=self._prefixes,\n",
        "            max_paragraph_length=self._max_paragraph_length,\n",
        "            max_num_repetitions=MAX_NUM_REPETITIONS,\n",
        "            client=self._client,\n",
        "            filter=self._filter,\n",
        "            num_samples=self._num_samples,\n",
        "            seed=seed)\n",
        "      self._dialogs = dialogs\n",
        "      self.prompts['dialogs'] = dialog_prompts\n",
        "      for dialog in dialogs:\n",
        "        self.interventions[timestamp] += str(dialog)\n",
        "      return True\n",
        "\n",
        "  def get_story(self):\n",
        "    if self._characters is not None:\n",
        "      character_descriptions = get_character_descriptions(self._characters)\n",
        "    else:\n",
        "      character_descriptions = None\n",
        "    return Story(\n",
        "        storyline=self._storyline,\n",
        "        title=self._title.title,\n",
        "        character_descriptions=character_descriptions,\n",
        "        place_descriptions=self._places,\n",
        "        scenes=self._scenes,\n",
        "        dialogs=self._dialogs)\n",
        "\n",
        "  def rewrite(self, text, level=0, entity=None):\n",
        "    if level < 0 or level >= len(self.level_names):\n",
        "      raise ValueError('Invalid level encountered on step.')\n",
        "    prompt_diff = None\n",
        "\n",
        "    if level == 0:\n",
        "      # Step 0: Rewrite the storyline and begin new story.\n",
        "      prompt_diff = diff_prompt_change_str(self._storyline, text)\n",
        "      self._set_storyline(text)\n",
        "\n",
        "    if level == 1:\n",
        "      # Step 1: Rewrite the title.\n",
        "      title = Title.from_string(text)\n",
        "      prompt_diff = diff_prompt_change_str(self._title.title, title.title)\n",
        "      self._title = title\n",
        "\n",
        "    if level == 2:\n",
        "      # Step 2: Rewrite the characters.\n",
        "      characters = Characters.from_string(text)\n",
        "      prompt_diff = diff_prompt_change_dict(\n",
        "          self._characters.character_descriptions,\n",
        "          characters.character_descriptions)\n",
        "      self._characters = characters\n",
        "\n",
        "    if level == 3:\n",
        "      # Step 3: Rewrite the sequence of scenes.\n",
        "      scenes = Scenes.from_string(text)\n",
        "      prompt_diff = diff_prompt_change_scenes(self._scenes.scenes,\n",
        "                                              scenes.scenes)\n",
        "      self._scenes = scenes\n",
        "\n",
        "    if level == 4:\n",
        "      # Step 4: For a given place, rewrite its place description.\n",
        "      place_descriptions = self._places\n",
        "      if entity in place_descriptions:\n",
        "        place_prefix = Place.format_prefix(entity)\n",
        "        text = place_prefix + text\n",
        "        place = Place.from_string(entity, text)\n",
        "        prompt_diff = diff_prompt_change_str(self._places[entity].name,\n",
        "                                             place.name)\n",
        "        prompt_diff += '\\n' + diff_prompt_change_str(\n",
        "            self._places[entity].description, place.description)\n",
        "\n",
        "        self._places[entity] = place\n",
        "\n",
        "    if level == 5:\n",
        "      # Step 5: Rewrite the dialog of a given scene.\n",
        "      dialogs = self._dialogs\n",
        "      num_scenes = len(self._scenes.scenes)\n",
        "      if entity >= 0 and entity < num_scenes:\n",
        "        prompt_diff = diff_prompt_change_str(self._dialogs[entity], text)\n",
        "        self._dialogs[entity] = text\n",
        "\n",
        "    # Keep track of each rewrite intervention.\n",
        "    if prompt_diff is not None and len(prompt_diff) > 0:\n",
        "      timestamp = time.time()\n",
        "      self.interventions[timestamp] = 'REWRITE ' + self.level_names[level]\n",
        "      if entity:\n",
        "        self.interventions[timestamp] += ' ' + str(entity)\n",
        "      self.interventions[timestamp] += prompt_diff\n",
        "\n",
        "  def complete(self,\n",
        "               level=0,\n",
        "               seed=None,\n",
        "               entity=None,\n",
        "               sample_length=SAMPLE_LENGTH):\n",
        "    if level < 0 or level >= len(self.level_names):\n",
        "      raise ValueError('Invalid level encountered on step.')\n",
        "    prompt_diff = None\n",
        "\n",
        "    if level == 2:\n",
        "      # Step 2: Complete the characters.\n",
        "      text_characters = self._characters.to_string()\n",
        "      text_characters = strip_remove_end(text_characters)\n",
        "      prompt = self.prompts['characters'] + text_characters\n",
        "      text = generate_text(\n",
        "          generation_prompt=prompt,\n",
        "          client=self._client,\n",
        "          filter=self._filter,\n",
        "          sample_length=sample_length,\n",
        "          max_paragraph_length=sample_length,\n",
        "          seed=seed,\n",
        "          num_samples=1)\n",
        "      new_characters = Characters.from_string(text_characters + text)\n",
        "      prompt_diff = diff_prompt_change_dict(\n",
        "          self._characters.character_descriptions,\n",
        "          new_characters.character_descriptions)\n",
        "      self._characters = new_characters\n",
        "\n",
        "    if level == 3:\n",
        "      # Step 3: Complete the sequence of scenes.\n",
        "      text_scenes = self._scenes.to_string()\n",
        "      text_scenes = strip_remove_end(text_scenes)\n",
        "      prompt = self.prompts['scenes'] + text_scenes\n",
        "      text = generate_text(\n",
        "          generation_prompt=prompt,\n",
        "          client=self._client,\n",
        "          filter=self._filter,\n",
        "          sample_length=sample_length,\n",
        "          max_paragraph_length=sample_length,\n",
        "          seed=seed,\n",
        "          num_samples=1)\n",
        "      new_scenes = Scenes.from_string(text_scenes + text)\n",
        "      prompt_diff = diff_prompt_change_scenes(self._scenes.scenes,\n",
        "                                              new_scenes.scenes)\n",
        "      self._scenes = new_scenes\n",
        "\n",
        "    if level == 5:\n",
        "      # Step 5: Complete the dialog of a given scene.\n",
        "      dialogs = self._dialogs\n",
        "      num_scenes = len(self._scenes.scenes)\n",
        "      while len(self._dialogs) < num_scenes:\n",
        "        self._dialogs.append('')\n",
        "      while len(self.prompts['dialogs']) < num_scenes:\n",
        "        self.prompts['dialogs'].append('')\n",
        "      if entity >= 0 and entity < num_scenes:\n",
        "        prompt = (self.prompts['dialogs'][entity] + self._dialogs[entity])\n",
        "        text = generate_text(\n",
        "            generation_prompt=prompt,\n",
        "            client=self._client,\n",
        "            filter=self._filter,\n",
        "            sample_length=sample_length,\n",
        "            max_paragraph_length=sample_length,\n",
        "            seed=seed,\n",
        "            num_samples=1)\n",
        "        new_dialog = self._dialogs[entity] + text\n",
        "        prompt_diff = diff_prompt_change_str(self._dialogs[entity], new_dialog)\n",
        "        self._dialogs[entity] = new_dialog\n",
        "\n",
        "    # Keep track of each rewrite intervention.\n",
        "    if prompt_diff is not None and len(prompt_diff) > 0:\n",
        "      timestamp = time.time()\n",
        "      self.interventions[timestamp] = 'COMPLETE ' + self.level_names[level]\n",
        "      if entity:\n",
        "        self.interventions[timestamp] += ' ' + str(entity)\n",
        "      self.interventions[timestamp] += prompt_diff\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# UI\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "class GenerationAction:\n",
        "  NEW = 1\n",
        "  CONTINUE = 2\n",
        "  REWRITE = 3\n",
        "\n",
        "\n",
        "class GenerationHistory:\n",
        "  \"\"\"Custom data structure to handle the history of GenerationAction edits:\n",
        "\n",
        "  NEW, CONTINUE or REWRITE. Consecutive REWRITE edits do not add to history.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self._items = []\n",
        "    self._actions = []\n",
        "    self._idx = -1\n",
        "    self._locked = False\n",
        "\n",
        "  def _plain_add(self, item, action: GenerationAction):\n",
        "    self._items.append(item)\n",
        "    self._actions.append(action)\n",
        "    self._idx = len(self._items) - 1\n",
        "    return self._idx\n",
        "\n",
        "  def add(self, item, action: GenerationAction):\n",
        "    if len(self._items) == 0 or action != GenerationAction.REWRITE:\n",
        "      return self._plain_add(item, action)\n",
        "    last_action = self._actions[-1]\n",
        "    if last_action != GenerationAction.REWRITE:\n",
        "      return self._plain_add(item, action)\n",
        "    self._items[self._idx] = item\n",
        "    return self._idx\n",
        "\n",
        "  def previous(self):\n",
        "    if len(self._items) == 0:\n",
        "      return None\n",
        "    self._idx = max(self._idx - 1, 0)\n",
        "    return self._items[self._idx]\n",
        "\n",
        "  def next(self):\n",
        "    if len(self._items) == 0:\n",
        "      return None\n",
        "    self._idx = min(self._idx + 1, len(self._items) - 1)\n",
        "    return self._items[self._idx]\n",
        "\n",
        "filter = None\n",
        "\n",
        "print('Dramatron set-up complete.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3AtyfN0nWSY",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "64cbb591-0d82-4729-99df-3881f53716a3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config:\n",
            "language_api_name: None\n",
            "model_param: None\n",
            "model_name: None\n",
            "max_retries: 10\n",
            "sample_length: 511\n",
            "max_paragraph_length: 1024\n",
            "max_paragraph_length_characters: 1024\n",
            "max_paragraph_length_scenes: 1024\n",
            "sampling: {'prob': 0.9, 'temp': 1.0, 'frequency_penalty': 0.23, 'presence_penalty': 0.23}\n",
            "file_dir: None\n",
            "CustomLanguageAPI not implemented yet\n"
          ]
        }
      ],
      "source": [
        "#@title Custom Language API\n",
        "\n",
        "#@markdown This cell should contain code with your language API.\n",
        "\n",
        "class CustomLanguageAPI(LanguageAPI):\n",
        "  \"\"\"A class wrapping the language model API.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               sample_length: int,\n",
        "               model: Optional[str] = None,\n",
        "               model_param: Optional[str] = None,\n",
        "               config_sampling: Optional[dict] = None,\n",
        "               seed: Optional[int] = None,\n",
        "               max_retries: int = _MAX_RETRIES,\n",
        "               timeout: float = _TIMEOUT):\n",
        "    \"\"\"Initializer.\n",
        "\n",
        "    Args:\n",
        "      sample_length: Length of text to sample from model.\n",
        "      model: The model name to correct to. An error will be raised if it does\n",
        "        not exist.\n",
        "      model_param: Custom language model params.\n",
        "      config_sampling: ConfigDict with parameters.\n",
        "      seed: Random seed for sampling.\n",
        "      max_retries: Maximum number of retries for the remote API.\n",
        "      timeout: Maximum waiting timeout\n",
        "    \"\"\"\n",
        "    raise NotImplementedError('init method not implemented')\n",
        "\n",
        "  @property\n",
        "  def client(self):\n",
        "    return self._client\n",
        "\n",
        "  @property\n",
        "  def model_metadata(self):\n",
        "    return {'engine': self._model,\n",
        "            'model_param': self._model_param,\n",
        "            'max_tokens': self._sample_length}\n",
        "\n",
        "  def sample(self,\n",
        "             prompt: str,\n",
        "             sample_length: Optional[int] = None,\n",
        "             seed: Optional[int] = None,\n",
        "             num_samples: int = 1):\n",
        "    raise NotImplementedError('sample method not implemented')\n",
        "\n",
        "\n",
        "# Create the config.\n",
        "config = {}\n",
        "config['language_api_name'] = None\n",
        "config['model_param'] = None\n",
        "config['model_name'] = None\n",
        "config['max_retries'] = MAX_RETRIES\n",
        "config['sample_length'] = SAMPLE_LENGTH\n",
        "config['max_paragraph_length'] = MAX_PARAGRAPH_LENGTH\n",
        "config['max_paragraph_length_characters'] = MAX_PARAGRAPH_LENGTH_CHARACTERS\n",
        "config['max_paragraph_length_scenes'] = MAX_PARAGRAPH_LENGTH_SCENES\n",
        "config['sampling'] = {}\n",
        "config['sampling']['prob'] = SAMPLING_PROB\n",
        "config['sampling']['temp'] = SAMPLING_TEMP\n",
        "config['sampling']['frequency_penalty'] = 0.23\n",
        "config['sampling']['presence_penalty'] = 0.23\n",
        "config['prefixes'] = {}\n",
        "config['file_dir'] = None\n",
        "\n",
        "print('Config:')\n",
        "for key, value in config.items():\n",
        "  if key != 'prefixes':\n",
        "    print(f'{key}: {value}')\n",
        "\n",
        "try:\n",
        "  client = CustomLanguageAPI(\n",
        "      model_param=config['model_param'],\n",
        "      model=config['model_name'],\n",
        "      seed=DEFAULT_SEED,\n",
        "      sample_length=config['sample_length'],\n",
        "      max_retries=config['max_retries'],\n",
        "      config_sampling=config['sampling'])\n",
        "\n",
        "  print(f'Client model metadata: {client.model_metadata}')\n",
        "except:\n",
        "  print('CustomLanguageAPI not implemented yet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZhfIe4QBSslN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce4a2cb2-ce36-4b46-b4fc-327e61b15679"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Perspective API key provided.\n"
          ]
        }
      ],
      "source": [
        "#@title (Optional) Perspective API { run: \"auto\" }\n",
        "\n",
        "PERSPECTIVE_API_URL = 'https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze'\n",
        "\n",
        "#@markdown The language model may generate offensive text. If you choose, you can provide a [Perspective API](https://perspectiveapi.com/) key, which will hide model outputs that exceed a toxicity threshold and prompt you to regenerate the text.\n",
        "PERSPECTIVE_API_KEY = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Perspective API toxicity thresholds across different attributes (default value: 0.8).\n",
        "PERSPECTIVE_API_TOXICITY = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "PERSPECTIVE_API_SEVERE_TOXICITY = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "PERSPECTIVE_API_IDENTITY_ATTACK = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "PERSPECTIVE_API_INSULT = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "PERSPECTIVE_API_SEXUALLY_EXPLICIT = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "PERSPECTIVE_API_THRESHOLDS = {\n",
        "    \"TOXICITY\": PERSPECTIVE_API_TOXICITY,\n",
        "    \"SEVERE_TOXICITY\": PERSPECTIVE_API_SEVERE_TOXICITY,\n",
        "    \"IDENTITY_ATTACK\": PERSPECTIVE_API_IDENTITY_ATTACK,\n",
        "    \"INSULT\": PERSPECTIVE_API_INSULT,\n",
        "    \"SEXUALLY_EXPLICIT\": PERSPECTIVE_API_SEXUALLY_EXPLICIT\n",
        "}\n",
        "\n",
        "\n",
        "class PerspectiveAPI(FilterAPI):\n",
        "  \"\"\"Wraps the Perspective API model.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               key: str,\n",
        "               thresholds: dict):\n",
        "    \"\"\"Initializer:\n",
        "\n",
        "    Args:\n",
        "      key: Perspective API key.\n",
        "      thresholds: Thresholds for attributes.\n",
        "    \"\"\"\n",
        "    self._key = key\n",
        "    self._thresholds = thresholds\n",
        "\n",
        "  def get_scores(self, text: str):\n",
        "    \"\"\"Get the scores from the Perspective API comment analyzer for text.\"\"\"\n",
        "\n",
        "    input_data = {\n",
        "        'comment': {'text': text},\n",
        "        'languages': ['en'],\n",
        "        'requestedAttributes': {attribute:{} for attribute in self._thresholds}\n",
        "    }\n",
        "    response = requests.post(\n",
        "        PERSPECTIVE_API_URL,\n",
        "        params={'key': self._key},\n",
        "        headers={'Content-Type': 'application/json'},\n",
        "        data=json.dumps(input_data)\n",
        "    )\n",
        "    output_data = response.json()\n",
        "    scores = {}\n",
        "    for attribute in self._thresholds:\n",
        "      score = output_data['attributeScores'][attribute]['summaryScore']['value']\n",
        "      scores[attribute] = score\n",
        "    return scores\n",
        "\n",
        "  def validate(self, text: str):\n",
        "    \"\"\"Filter text using scores from the Perspective API.\"\"\"\n",
        "\n",
        "    scores = self.get_scores(text)\n",
        "    return all([scores[attribute] <= self._thresholds[attribute]\n",
        "                for attribute in self._thresholds])\n",
        "\n",
        "if PERSPECTIVE_API_KEY:\n",
        "  filter = PerspectiveAPI(\n",
        "      key=PERSPECTIVE_API_KEY,\n",
        "      thresholds=PERSPECTIVE_API_THRESHOLDS\n",
        "  )\n",
        "  print('PerspectiveAPI configured.')\n",
        "else:\n",
        "  filter = None\n",
        "  print('No Perspective API key provided.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OAW4PeE1z7N"
      },
      "source": [
        "## Prompt prefix sets\n",
        "\n",
        "Run these cells once to define the available prompt prefixes. These cells contain 3 sets of prompt prefixes: **Medea**, **Sci-Fi** and **Custom**. The first two sets were used in our study, the third one serves as a placeholder that you can customise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzf80E5YAi6g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "cellView": "form",
        "outputId": "33bfe42d-efa5-4baa-acdb-48865791ec34"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Medea\n",
        "\n",
        "#@markdown Trigger warning: the script contains sensitive topics.\n",
        "\n",
        "#@markdown Log line: `Ancient Greek tragedy based upon the myth of Jason and Medea. Medea, a former princess and the wife of Jason, finds her position in the Greek world threatened as Jason leaves Medea for a Greek princess of Corinth. Medea takes vengeance on Jason by murdering his new wife as well as Medea's own two sons, after which she escapes to Athens.`\n",
        "\n",
        "#@markdown Based on Ancient Greek tragedy \"Medea\", by Euripides (431 BC). Text of the play taken verbatim from the translation by E. P. Coleridge (1863 -1936). One edit made to replace `CHORUS` by `WOMEN OF CORINTH`.\n",
        "\n",
        "#@markdown Prompts for Medea written from a summary taken from Spark Notes. Prompts for Antigone (Sophocles), The Bacchae (Euripides), The Frogs (Aristophanes) adapted from Wikipedia.\n",
        "\n",
        "#@markdown To encourage the generation of different locations, Aristotle's Unity of Place is not respected, and location `Outside the Royal Palace` is renamed as `Medea's modest home` as well as `On a winged chariot` (even though these are the same locations in the original tragedy).\n",
        "\n",
        "#@markdown References:\n",
        "\n",
        "#@markdown http://classics.mit.edu/Euripides/medea.pl.txt<br> https://en.wikipedia.org/wiki/Medea_(play)<br> https://www.sparknotes.com/lit/medea/<br> https://www.ancient-literature.com/greece_sophocles_antigone.html<br> https://en.wikipedia.org/wiki/The_Bacchae<br> https://www.ancient-literature.com/greece_aristophanes_frogs.html\n",
        "\n",
        "medea_prefixes = {}\n",
        "medea_prefixes['CHARACTERS_PROMPT'] = \"\"\"\n",
        "Here is an example of a logline and a list of characters.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"这是一部基于伊阿宋和美狄亚神话的古希腊悲剧。美狄亚，一位前公主兼伊阿宋的妻子，在伊阿宋为了科林斯的希腊公主而离开她后，发现自己在希腊世界的地位受到威胁。美狄亚为了对伊阿宋进行报复，杀害了他的新娘以及美狄亚自己的两个儿子，之后她逃到雅典。\n",
        "\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\" 美狄亚 \"\"\" + DESCRIPTION_MARKER + \"\"\" 美狄亚是这部剧的主角。她是一位女巫和公主，为了与伊阿宋一起生活，逃离了自己的国家和家庭，来到科林斯，在那里他们建立了一个有两个孩子的家庭，并获得了良好的声誉。伊阿宋已经与美狄亚离婚，并开始了新的家庭生活。\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\" 伊阿宋 \"\"\" + DESCRIPTION_MARKER + \"\"\" 伊阿宋被认为是剧中的反派，尽管他的邪恶更多地源于软弱而非力量。作为一名前冒险者，伊阿宋为了娶科林斯国王克瑞翁美丽的年轻女儿而抛弃了他的妻子美狄亚，这激发了美狄亚进行复仇。\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\" 科林斯的女人们 \"\"\" + DESCRIPTION_MARKER + \"\"\" 科林斯的女人们是对行动的评论者。她们完全同情美狄亚的困境，除了她决定杀害自己孩子的行为。\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\" 克瑞翁 \"\"\" + DESCRIPTION_MARKER + \"\"\" 克瑞翁是科林斯的国王，他将美狄亚从城市中放逐。\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\" 保姆 \"\"\" + DESCRIPTION_MARKER + \"\"\" 保姆是家里和孩子们的照顾者，并且是美狄亚的密友。\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the example above and the following logline, complete the list of characters in Chinese.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "\n",
        "medea_prefixes['SCENE_PROMPT'] = \"\"\"\n",
        "Here is an example of a logline, a list of characters, and a list of plot points.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"这是一部基于伊阿宋和美狄亚神话的古希腊悲剧。美狄亚，一位前公主兼伊阿宋的妻子，在伊阿宋为了科林斯的希腊公主而离开她后，发现自己在希腊世界的地位受到威胁。美狄亚为了对伊阿宋进行报复，杀害了他的新娘以及美狄亚自己的两个儿子，之后她逃到雅典。\n",
        "美狄亚是这部剧的主角。作为一个女巫和公主，她逃离自己的国家和家庭，与伊阿宋一起生活在科林斯，在那里他们建立了一个有两个孩子的家庭，并获得了良好的声誉。伊阿宋已经与美狄亚离婚，并开始了新的家庭生活。\n",
        "伊阿宋可以被认为是剧中的反派，尽管他的邪恶更多地源于软弱而非力量。作为一名前冒险者，伊阿宋为了娶科林斯国王克瑞翁美丽的年轻女儿而抛弃了他的妻子美狄亚，这激发了美狄亚进行复仇。\n",
        "科林斯的女人们是对行动的评论者。她们完全同情美狄亚的困境，除了她决定杀害自己孩子的行为。\n",
        "克瑞翁是科林斯的国王，他将美狄亚从城市中放逐。\n",
        "信使在剧中只出现一次，带来了悲惨的消息。\n",
        "保姆是家里和孩子们的照顾者，并且是美狄亚的密友。\n",
        "孩子们的家庭教师是一个非常次要的角色，主要作为一个信使。\n",
        "\n",
        "\"\"\" + SCENES_MARKER + \"\"\"\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" 美狄亚朴素的家。\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" 铺垫.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" 保姆讲述了一连串的事件，这些事件使美狄亚的世界变得充满敌意。保姆长哀叹伊阿宋为了与克瑞翁的女儿再婚而抛弃了美狄亚和他自己的孩子。\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" 美狄亚朴素的家。\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" 事件起因.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"保姆向家庭教师倾诉，并证明了伊阿宋的背叛给美狄亚带来的情感冲击。家庭教师和保姆一样同情美狄亚的困境。美狄亚的第一句话是无助的呼喊。美狄亚希望自己死。\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" 美狄亚朴素的家。\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" 冲突.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" 科林斯的女人们与美狄亚对话，试图劝说她不要自杀，认为这会是过度反应。保姆意识到美狄亚的威胁的严重性。\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" 皇宫外。\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" 上升情节。\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" 美狄亚向保姆恳求，希望伊阿宋为他给她带来的痛苦付出代价。克瑞翁来到家中，将美狄亚和她的孩子从科林斯驱逐出去。美狄亚计划杀死她的三个对手：克瑞翁、他的女儿和伊阿宋。\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" 皇宫外。\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" 困境。\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" 伊阿宋斥责美狄亚公开表达她的谋杀意图，并为自己再婚的选择进行辩护。美狄亚拒绝了伊阿宋的提议，并将他赶回他的新娘那里。\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" 皇宫外。\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" 高潮。\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" 当伊阿宋回来时，美狄亚开始实施她的计谋。美狄亚假装后悔，并流下悔恨的假泪。坚定的美狄亚派她的孩子们去向克瑞翁的女儿献上有毒的礼物。美狄亚的孩子们面临即将来临的厄运。\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" 皇宫外。\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" 下降情节。\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" 使者急忙奔向美狄亚，警告她尽快逃离城市。使者透露，美狄亚已被认定为凶手。\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" 皇宫外。\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" 结局.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" 美狄亚和她的两个死去的孩子坐在一辆由龙拉动的战车上。伊阿宋惊恐地看着这一切，并诅咒自己娶了美狄亚，为他惨痛的损失而悲叹。\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" 在有翅膀的战车上。\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" 尾声.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" 美狄亚拒绝伊阿宋为他的孩子们提供适当的埋葬。她逃往雅典，并预见了伊阿宋不光彩的死亡。\n",
        "\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the example above and the following logline and list of characters, complete the list of plot points in Chinese.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "\n",
        "medea_prefixes['SETTING_PROMPT'] = \"\"\"\n",
        "Here are examples of logline, location, and that location's description.\n",
        "\n",
        "Example 1.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"艾拉，一名女服务员，爱上了她最好的朋友艾伦，一名教师。当艾伦结交了来自不同社会阶层的新朋友后，两人逐渐疏远。艾拉转而投身美食，成为了一名著名的厨师。\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"酒吧.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"这家酒吧很脏，有点破败，大部分桌子都是空的。地板上昨晚啤酒的味道和压碎的椒盐卷饼的气味弥漫在酒吧里。\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"菲利斯奶奶与她的两个孙子的家庭团聚被两个骑摩托车的人打断了。\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"菲利斯奶奶家前的草坪。\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"一个大橡树占据了院子。草坪上有一个旧的秋千架，周围是一道明亮的白色围栏。\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 3.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"这是一部基于伊阿宋和美狄亚神话的古希腊悲剧。美狄亚，前公主以及伊阿宋的妻子，在伊阿宋为了一个科林斯的希腊公主而离开美狄亚后，发现她在希腊世界的地位受到威胁。美狄亚为了报复伊阿宋，杀害了他的新娘以及美狄亚自己的两个儿子，之后她逃到了雅典。\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"皇宫外。\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"在神话中的古希腊，科林斯一座朴素的房子前，位于一座豪华皇宫的郊区，那里正在准备婚礼。\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the examples above and the following logine and location name, complete location description in Chinese.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "\n",
        "medea_prefixes['TITLES_PROMPT'] = \"\"\"\n",
        "Examples of alternative, original and descriptive titles for known play and film scripts.\n",
        "\n",
        "Example 1.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\" 这是一部基于伊阿宋和美狄亚神话的古希腊悲剧。美狄亚，科尔基斯王国的前公主以及伊阿宋的妻子，在伊阿宋为了一个科林斯的希腊公主而离开她后，发现她在希腊世界的地位受到威胁。美狄亚为了报复伊阿宋，杀害了他的新娘以及她自己的两个儿子，之后她逃到了雅典。\n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"一个女性的故事\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\" 这是一部古希腊悲剧，讲述了安提戈涅不顾克瑞翁和国家法律的禁令，埋葬了她的兄弟波吕尼刻斯，以及她这一公民不服从行为所带来的悲惨后果。\n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"以兄弟之名\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 3.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\" 这是一部希腊喜剧，讲述了神祇狄俄尼索斯（希腊人也称他为巴克科斯）的故事。狄俄尼索斯对当前雅典悲剧家的状况感到绝望，于是带着他的奴隶桑西亚斯前往冥界，企图将欧里庇得斯从死亡中带回。\n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"在冥界的狄俄尼索斯\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 4.\n",
        "\"\"\" + LOGLINE_ELEMENT\n",
        "\n",
        "\n",
        "medea_prefixes['DIALOG_PROMPT'] = \"\"\"\n",
        "Here is an example of description and scene dialogue from a classical play.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"皇宫外。\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"在科林斯的美狄亚家前，靠近克瑞翁的皇宫。\n",
        "\"\"\" + CHARACTERS_ELEMENT + \"\"\"美狄亚是这部剧的主角。作为一个女巫和公主，她逃离了自己的国家和家庭，与伊阿宋一起住在科林斯，他们建立了一个有两个孩子的家庭，并获得了良好的声誉。伊阿宋已经与美狄亚离婚，并开始了新的家庭生活。尽管伊阿宋的邪恶更多源自于软弱而非强大，但他可以被认为是剧中的反派。作为一名前冒险家，伊阿宋为了娶科林斯国王克瑞翁的美丽年轻女儿而抛弃了他的妻子美狄亚，这激发了美狄亚的复仇心。使者在剧中只出现一次，带来了悲惨的消息。\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"结局。\n",
        "\"\"\" + SUMMARY_ELEMENT + \"\"\"美狄亚，前公主及伊阿宋的妻子，发现她在希腊世界的地位因伊阿宋离开她而娶科林斯的希腊公主而受到威胁。美狄亚通过杀害伊阿宋的新婚妻子以及美狄亚自己的两个儿子来报复伊阿宋，之后她逃到了雅典。\n",
        "\"\"\" + PREVIOUS_ELEMENT + \"\"\"使者疯狂地警告美狄亚尽快逃离城市。使者透露，美狄亚已被认定为凶手。\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"宫殿的大门打开，显露出坐在由龙拉动的战车上的美狄亚和两个死去的孩子。伊阿宋因为娶了美狄亚而诅咒自己，为他的悲惨损失而悲痛。美狄亚拒绝给伊阿宋的孩子们一个适当的埋葬。美狄亚逃往雅典，并预言伊阿宋将有一个不光彩的死亡。\n",
        "\"\"\" + DIALOG_MARKER + \"\"\"\n",
        "\n",
        "科林斯的女人们\n",
        "将门大开，看看你孩子们被杀害的尸体。\n",
        "\n",
        "伊阿宋\n",
        "快点，你们这些奴隶们，松开插销，解开门闩，让我看到这双重悲哀的景象——我被杀害的儿子们和她，\n",
        "我将为报复而流她的血。（美狄亚出现在房屋之上，坐在由龙拉动的战车上；她旁边是孩子们的尸体。\n",
        "\n",
        "美狄亚\n",
        "为什么要摇晃那些门并试图松开它们的插销，去寻找死者和我这个凶手？从这样的劳作中解脱出来。\n",
        "如果你有什么事要对我说，尽管说，如果你愿意的话；但你永远也无法触摸到我，因为太阳，我祖父的马匹，\n",
        "如此迅速，他们会把我从敌人手中救出。\n",
        "\n",
        "伊阿宋\n",
        "被诅咒的女人！被众神、我和所有人类憎恶，从未有过任何女人像你这样，竟有心刺杀你的孩子，\n",
        "你这个他们的母亲，使我孤立无援，没有了孩子；你做了这些事，还能在这罪恶之举之后仰望太阳和大地。诅咒你！\n",
        "现在我明白，我在那天把你从你的野蛮家园带到希腊居住时，错过了什么，你背叛了你的父亲和养育你的土地。\n",
        "去死吧，卑鄙的女巫，杀害你孩子的凶手！而我必须哀悼我的不幸命运，因为我将再也不会享受我的新娘，\n",
        "也不会有我的孩子，我养育和培养的孩子，活着向我道最后的告别；不，我已失去了他们。\n",
        "\n",
        "美狄亚\n",
        "对于你的这番话，我本可以做出长篇大论的回答，但宙斯父神很清楚我为你所做的一切，以及你给予我的待遇。\n",
        "然而，你并非命中注定要轻视我的爱，并在嘲笑我中过着快乐的生活，你的王室新娘和克瑞翁，给你一个新妻子的人，\n",
        "也不该把我从这片土地上赶走而不后悔。因此，如果你愿意，就算叫我狮子母兽，或者住在第勒尼安地的斯库拉吧；\n",
        "因为我反过来也让你心痛，这是我应得的。\n",
        "\n",
        "伊阿宋\n",
        "你也感到悲伤，与我共享这份痛苦。\n",
        "\n",
        "美狄亚\n",
        "请相信我确实如此；但知道你不能嘲笑我，这让我的痛苦有所减轻。\n",
        "\n",
        "伊阿宋\n",
        "哦，我的孩子们，你们找到了多么卑鄙的母亲啊！\n",
        "\n",
        "美狄亚\n",
        "我的儿子们，你们父亲的软弱欲望毁了你们！\n",
        "\n",
        "伊阿宋\n",
        "至少不是我的手杀了他们。\n",
        "\n",
        "美狄亚\n",
        "不，而是你对我的恶劣待遇和你的新婚。\n",
        "\n",
        "伊阿宋\n",
        "你以为婚姻是杀害他们的理由吗？\n",
        "\n",
        "美狄亚\n",
        "你认为一个女人会认为这是小事吗？\n",
        "\n",
        "伊阿宋\n",
        "如果她能自我克制的话；但在你眼中，一切都是邪恶的。\n",
        "\n",
        "美狄亚\n",
        "你的儿子们已经死了，这将刺痛你的心。\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the example above and following description, write the dialogue of the scene in Chinese.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gHhprsguAa9h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "056a1bed-8165-4c17-8f1b-637f96db3c8d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Sci-Fi\n",
        "\n",
        "#@markdown Log line for Star Wars: Episode IV: `A science-fiction fantasy about a naive but ambitious farm boy from a backwater desert who discovers powers he never knew he had when he teams up with a feisty princess, a mercenary space pilot and an old wizard warrior to lead a ragtag rebellion against the sinister forces of the evil Galactic Empire.`\n",
        "\n",
        "#@markdown Log line taken from chapter \"Creating the killer log line\" by Bill Lundy, in: Ellis, Sherry, and Laurie Lamson. \"Now Write! Mysteries: Suspense, Crime, Thriller, and Other Mystery Fiction Exercises from Today's Best Writers and Teachers.\" Penguin, 2011.\n",
        "\n",
        "#@markdown Characters are adapted from Star Wars: Episode IV - A New Hope (1977) written and directed by George Lucas, produced by Lucasfilm and distributed by 20th Century Fox.\n",
        "\n",
        "#@markdown Breakdown of Star Wars into a Hero Journey taken from: https://thescriptlab.com/features/screenwriting-101/12309-the-heros-journey-breakdown-star-wars/\n",
        "\n",
        "#@markdown Log line for Plan 9 from Outer Space: `Residents of San Fernando Valley are under attack by flying saucers from outer space. The aliens are extraterrestrials who seek to stop humanity from creating a doomsday weapon that could destroy the universe and unleash the living dead to stalk humans who wander into the cemetery looking for evidence of the UFOs. The hero Jeff, an airline pilot, will face the aliens.`\n",
        "\n",
        "#@markdown The script, plot and logline of \"Plan 9 from Outer Space\" is in public domain, available at:<br> http://www.horrorlair.com/scripts/criswell.txt<br> https://en.wikipedia.org/wiki/Plan_9_from_Outer_Space<br> https://www.rottentomatoes.com/m/plan-9-from-outer-space<br>\n",
        "\n",
        "scifi_prefixes = {}\n",
        "scifi_prefixes['CHARACTERS_PROMPT'] = \"\"\"\n",
        "Here is an example of a logline and a list of characters.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"A science-fiction fantasy about a naive but ambitious farm boy from a backwater desert who discovers powers he never knew he had when he teams up with a feisty princess, a mercenary space pilot and an old wizard warrior to lead a ragtag rebellion against the sinister forces of the evil Galactic Empire.\n",
        "\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"Luke Skywalker \"\"\" + DESCRIPTION_MARKER + \"\"\"Luke Skywalker is the hero. A naive farm boy, he will discover special powers under the guidance of mentor Ben Kenobi.\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"Ben Kenobi \"\"\" + DESCRIPTION_MARKER + \"\"\"Ben Kenobi is the mentor figure. A recluse Jedi warrior, he will take Luke Skywalker as apprentice.\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"Darth Vader \"\"\" + DESCRIPTION_MARKER + \"\"\"Darth Vader is the antagonist. As a commander of the evil Galactic Empire, he controls space station The Death Star.\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"Princess Leia \"\"\" + DESCRIPTION_MARKER + \"\"\"Princess Leia is a feisty and brave leader of the Rebellion. She holds the plans of the Death Star. She will become Luke's friend.\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"Han Solo \"\"\" + DESCRIPTION_MARKER + \"\"\"Han Solo is a brash mercenary space pilot of the Millenium Falcon and a friend of Chebacca. He will take Luke on his spaceship.\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"Chewbacca \"\"\" + DESCRIPTION_MARKER + \"\"\"Chewbacca is a furry and trustful monster. He is a friend of Han Solo and a copilot on the Millemium Falcon.\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the example above and the following logline, complete the list of characters.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "\n",
        "scifi_prefixes['SCENE_PROMPT'] = \"\"\"\n",
        "Examples of breakdowns of stories into a Hero's Journey structure.\n",
        "\n",
        "Here is an example of a logline, a list of characters, and a list of plot points.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"A science-fiction fantasy about a naive but ambitious farm boy from a backwater desert who discovers powers he never knew he had when he teams up with a feisty princess, a mercenary space pilot and an old wizard warrior to lead a ragtag rebellion against the sinister forces of the evil Galactic Empire.\n",
        "Luke Skywalker is the hero. A naive farm boy, he will discover special powers under the guidance of mentor Ben Kenobi.\n",
        "Ben Kenobi is the mentor figure. A recluse Jedi warrior, he will take Luke Skywalker as apprentice.\n",
        "Darth Vader is the antagonist. As a commander of the evil Galactic Empire, he controls space station The Death Star.\n",
        "Princess Leia holds the plans of the Death Star. She is feisty and brave. She will become Luke's friend.\n",
        "Han Solo is a brash mercenary space pilot of the Millenium Falcon and a friend of Chebacca. He will take Luke on his spaceship.\n",
        "Chewbacca is a furry and trustful monster. He is a friend of Han Solo and a copilot on the Millemium Falcon.\n",
        "\n",
        "\"\"\" + SCENES_MARKER + \"\"\"\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"A farm on planet Tatooine.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"The Ordinary World.\n",
        "Beat: Luke Skywalker is living a normal and humble life as a farm boy on his home planet.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"Desert of Tatooine.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Call to Adventure.\n",
        "Beat: Luke is called to his adventure by robot R2-D2 and Ben Kenobi. Luke triggers R2-D2’s message from Princess Leia and is intrigued by her message. When R2-D2 escapes to find Ben Kenobi, Luke follows and is later saved by Kenobi, who goes on to tell Luke about his Jedi heritage. Kenobi suggests that he should come with him.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"Ben Kenobi's farm.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Refusal of the Call.\n",
        "Beat: Luke refuses Kenobi, telling him that he can take Kenobi and the droids as far as Mos Eisley Spaceport — but he can’t possibly leave his Aunt and Uncle behind for some space adventure.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"A farm on planet Tatooine.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Crossing the First Threshold.\n",
        "Beat: When Luke discovers that the stormtroopers searching for the droids would track them to his farm, he rushes to warn his Aunt and Uncle, only to discover them dead by the hands of the Empire. When Luke returns to Kenobi, he pledges to go with him to Alderaan and learn the ways of the Force like his father before him.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"On spaceship The Millennium Falcon.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Tests, Allies, and Enemies.\n",
        "Beat: After Luke, Kenobi, and the droids hire Han Solo and Chewbacca to transport them onto Alderaan, Kenobi begins Luke’s training in the ways of the Force. Wielding his father’s lightsaber, Kenobi challenges Luke. At first, he can’t do it. But then Kenobi Kenobi Luke him to reach out and trust his feelings. Luke succeeds.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"On spaceship The Millennium Falcon.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"The Approach to the Inmost Cave.\n",
        "Beat: The plan to defeat the Galactic Empire is to bring the Death Star plans to Alderaan so that Princess Leia’s father can take them to the Rebellion. However, when they arrive within the system, the planet is destroyed. They come across the Death Star and are pulled in by a tractor beam, now trapped within the Galactic Empire.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"On space station The Death Star.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"The Ordeal.\n",
        "Beat: As Kenobi goes off to deactivate the tractor beam so they can escape, Luke, Han, and Chewbacca discover that Princess Leia is being held on the Death Star with them. They rescue her and escape to the Millennium Falcon, hoping that Kenobi has successfully deactivated the tractor beam. Kenobi later sacrifices himself as Luke watches Darth Vader strike him down. Luke must now avenge his fallen mentor and carry on his teachings.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"On space station The Death Star.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"The Reward.\n",
        "Beat: Luke has saved the princess and retrieved the Death Star plans. They now have the knowledge to destroy the Galactic Empire’s greatest weapon once and for all.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"On spaceship The Millennium Falcon.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"The Road Back.\n",
        "Beat: Luke, Leia, Han, Chewbacca, and the droids are headed to the hidden Rebellion base with the Death Star plans. They are suddenly pursued by incoming TIE-Fighters, forcing Han and Luke to take action to defend the ship and escape with their lives — and the plans. They race to take the plans to the Rebellion and prepare for battle.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"On fighter ship X-Wing.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"The Resurrection.\n",
        "Beat: The Rebels — along with Luke as an X-Wing pilot — take on the Death Star. The Rebellion and the Galactic Empire wage war in an epic space battle. Luke is the only X-Wing pilot that was able to get within the trenches of the Death Star. But Darth Vader and his wingmen are in hot pursuit. Just as Darth Vader is about to destroy Luke, Han returns and clears the way for Luke. Luke uses the Force to guide his aiming as he fires upon the sole weak point of the deadly Death Star, destroying it for good.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"At the Rebellion base.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"The Return.\n",
        "Beat: Luke and Han return to the Rebellion base, triumphant, as they receive medals for the heroic journey. There is peace throughout the galaxy — at least for now.\n",
        "\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the example above and the following logline and list of characters, complete the list of plot points.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "\n",
        "scifi_prefixes['SETTING_PROMPT'] = \"\"\"\n",
        "Here are examples of logline, location, and that location's description.\n",
        "\n",
        "Example 1.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"Morgan adopts a new cat, Misterio, who sets a curse on anyone that pets them.\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The Adoption Center.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"The Adoption Center is a sad place, especially for an unadopted pet. It is full of walls and walls of cages and cages. Inside of each is an abandoned animal, longing for a home. The lighting is dim, gray, buzzing fluorescent.\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"James finds a well in his backyard that is haunted by the ghost of Sam.\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The well.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"The well is buried under grass and hedges. It is at least twenty feet deep, if not more and it is masoned with stones. It is 150 years old at least. It stinks of stale, standing water, and has vines growing up the sides. It is narrow enough to not be able to fit down if you are a grown adult human.\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 3.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"Mr. Dorbenson finds a book at a garage sale that tells the story of his own life. And it ends in a murder!\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The garage sale.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"It is a garage packed with dusty household goods and antiques. There is a box at the back that says FREE and is full of paper back books.\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the examples above and the following logine and location name, complete location description.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "\n",
        "scifi_prefixes['TITLES_PROMPT'] = \"\"\"\n",
        "Examples of alternative, original and descriptive titles for known play and film scripts.\n",
        "\n",
        "Example 1.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\"A science-fiction fantasy about a naive but ambitious farm boy from a backwater desert who discovers powers he never knew he had when he teams up with a feisty princess, a mercenary space pilot and an old wizard warrior to lead a ragtag rebellion against the sinister forces of the evil Galactic Empire.\n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"The Death Star's Menace\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\"Residents of San Fernando Valley are under attack by flying saucers from outer space. The aliens are extraterrestrials who seek to stop humanity from creating a doomsday weapon that could destroy the universe and unleash the living dead to stalk humans who wander into the cemetery looking for evidence of the UFOs. The hero Jeff, an airline pilot, will face the aliens.\n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"The Day The Earth Was Saved By Outer Space.\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 3.\n",
        "\"\"\" + LOGLINE_ELEMENT\n",
        "\n",
        "\n",
        "scifi_prefixes['DIALOG_PROMPT'] = \"\"\"\n",
        "Here is an example of description and scene dialogue from a modern screenplay.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"Cockpit of an airplane.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"Cockpit of a modern passenger airplane, American Flight 812.\n",
        "\"\"\" + CHARACTERS_ELEMENT + \"\"\"Jeff is the hero. A man in his early forties, he tries to stay calm in all circumstance. Jeff is now a airline pilot. Danny, a young airplane pilot in his thirties, is eager to learn but can quickly lose his composture. Danny is enamored of Edith. Edith, an experienced stewardess with a good sense of humour, is trustworthy and dependable. Edith likes to tease Danny.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Crossing the First Threshold.\n",
        "\"\"\" + SUMMARY_ELEMENT + \"\"\"Residents of San Fernando Valley are under attack by flying saucers from outer space. The aliens are extraterrestrials who seek to stop humanity from creating a doomsday weapon that could destroy the universe and unleash the living dead to stalk humans who wander into the cemetery looking for evidence of the UFOs. The hero Jeff, an airline pilot, will face the aliens.\n",
        "\"\"\" + PREVIOUS_ELEMENT + \"\"\"Flight captain Jeff reluctantly leaves his wife Paula to go for a two-day flight.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"At the cockpit, flight captain Jeff is preoccupied by the flying saucer appearances and graveyard incidents in his home town, where he left wis wife Paula. Without success, co-pilot Danny and stewardess Edith try to reassure him.\n",
        "\n",
        "\"\"\" + DIALOG_MARKER + \"\"\"\n",
        "\n",
        "DANNY\n",
        "You're mighty silent this trip, Jeff.\n",
        "\n",
        "JEFF\n",
        "Huh?\n",
        "\n",
        "DANNY\n",
        "You haven't spoken ten words since takeoff.\n",
        "\n",
        "JEFF\n",
        "I guess I'm preoccupied, Danny.\n",
        "\n",
        "DANNY\n",
        "We've got thirty-three passengers back there that have time to be preoccupied.\n",
        "Flying this flybird doesn't give you that opportunity.\n",
        "\n",
        "JEFF\n",
        "I guess you're right, Danny.\n",
        "\n",
        "DANNY\n",
        "Paula?\n",
        "\n",
        "JEFF\n",
        "Yeah.\n",
        "\n",
        "DANNY\n",
        "There's nothing wrong between you two?\n",
        "\n",
        "JEFF\n",
        "Oh no, nothing like that.  Just that I'm worried, she being there alone and\n",
        "those strange things flying over the house and those incidents in the graveyard\n",
        "the past few days. It's just got me worried.\n",
        "\n",
        "DANNY\n",
        "Well, I haven't figured out those crazy skybirds yet but I give you fifty to one\n",
        "odds the police have figured out that cemetery thing by now.\n",
        "\n",
        "(Enter EDITH)\n",
        "\n",
        "JEFF\n",
        "I hope so.\n",
        "\n",
        "EDITH\n",
        "If you're really that worried Jeff why don't you radio in and find out? Mac\n",
        "should be on duty at the field by now. He could call Paula and relay the message\n",
        "to you.\n",
        "\n",
        "DANNY\n",
        "Hi Edith.\n",
        "\n",
        "EDITH\n",
        "Hi Silents. I haven't heard a word from this end of the plane since we left the\n",
        "field.\n",
        "\n",
        "DANNY\n",
        "Jeff's been giving me and himself a study in silence.\n",
        "\n",
        "EDITH\n",
        "You boys are feudin'?\n",
        "\n",
        "JEFF\n",
        "Oh no Edie, nothing like that.\n",
        "\n",
        "DANNY\n",
        "Hey Edie, how about you and me balling it up in Albuquerque?\n",
        "\n",
        "EDITH\n",
        "Albuquerque? Have you read that flight schedule Boy?\n",
        "\n",
        "DANNY\n",
        "What about it?\n",
        "\n",
        "EDITH\n",
        "We land in Albuquerque at 4 am. That's strictly a nine o'clock town.\n",
        "\n",
        "DANNY\n",
        "Well I know a friend that'll help us --\n",
        "\n",
        "EDITH\n",
        "Let's have a problem first, huh Danny.\n",
        "\n",
        "DANNY\n",
        "Ah he's worried about Paula.\n",
        "\n",
        "EDITH\n",
        "I read about that cemetery business. I tried to get you kids to not buy too near\n",
        "one of those things. We get there soon enough as it is.\n",
        "\n",
        "DANNY\n",
        "He thought it'd be quiet and peaceful there.\n",
        "\n",
        "EDITH\n",
        "No doubt about that. It's quiet alright, like a tomb. I'm sorry Jeff, that was a\n",
        "bad joke.\n",
        "\n",
        "Using the example above and following description, write the dialogue of the scene.\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qiKa4EVKDbIZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "707eb48f-8042-43a7-bd31-155ca00479f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Custom\n",
        "\n",
        "#@markdown These prefixes for `CHARACTERS_PROMPT`, `SCENE_PROMPT`, `SETTING_PROMPT`, `TITLES_PROMPT` and `DIALOG_PROMPT` were written by the authors. They were not used in the evaluation study but can serve as a template to write custom prefix sets.\n",
        "\n",
        "#@markdown To write your own prompt prefix set, edit this code and pay attention to follow the existing formatting, with appropriate `STOP_MARKER`, `END_MARKER` and element markers.\n",
        "\n",
        "custom_prefixes = {}\n",
        "custom_prefixes['CHARACTERS_PROMPT'] = \"\"\"\n",
        "Here is an example of a logline and a list of characters.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"James finds a well in his backyard that is haunted by the ghost of Sam.\n",
        "\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\" James \"\"\" + DESCRIPTION_MARKER + \"\"\" James is twenty-six, serious about health and wellness and optimistic. \"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\" Sam \"\"\" + DESCRIPTION_MARKER + \"\"\" Sam fell down the well when he was 12, and was never heard from again. Sam is now a ghost. \"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"Morgan adopts a new cat, Misterio, who sets a curse on anyone that pets them.\n",
        "\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\" Morgan \"\"\" + DESCRIPTION_MARKER + \"\"\" Morgan is booksmart and popular; they are trusting but also have been known to hold a grudge. \"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\" Misterio \"\"\" + DESCRIPTION_MARKER + \"\"\" Misterio is a beautiul black cat, it is of uncertain age; it has several gray whiskers that make it look wise and beyond its years.  \"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 3.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"Mr. Dorbenson finds a book at a garage sale that tells the story of his own life. And it ends in a murder!\n",
        "\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\" Mr. Glen Dorbenson \"\"\" + DESCRIPTION_MARKER + \"\"\" Mr. Glen Dorbenson frequents markets and garage sales always looking for a bargain. He is lonely and isolated and looking for his meaning in life. \"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the examples above and the following logline, complete the list of characters.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "custom_prefixes['SCENE_PROMPT'] = \"\"\"\n",
        "Here is an example of a logline, a list of characters, and a list of plot points.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"In the following story, James finds a well in his backyard that is haunted by the ghost of Sam. The main characters are James and Sam.\n",
        "James is twenty-six, serious about health and wellness and optimistic.\n",
        "Sam fell down the well when he was 12, and was never heard from again. Sam is now a ghost.\n",
        "\n",
        "\"\"\" + SCENES_MARKER + \"\"\"\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The backyard.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Beginning.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"James is weeding his garden in the backyard, the ghost of Sam is rummaging around in the well. James listens closely and hears the murmurs of Sam down the well. James unearths the opening to the well, and looks down to see a glimmering reflection.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The well.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Middle.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"James is making his way down the well, Sam's voice is reverberating on the walls of the well. Sam tells the story of how he came to haunt the well. James offers to help set the soul of Sam free.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The house.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Conclusion.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"Looking at a photo of the gardden featuring Sam, James says his goodbyes to Sam, Sam thanks James for his help. The ghost of Sam is set free after and James goes living his life.\n",
        "\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"Morgan adopts a new cat, Misterio, who sets a curse on anyone that pets them.\n",
        "The main characters are Morgan and Misterio (a cat).\n",
        "Morgan is booksmart and popular; they are trusting but also have been known to hold a grudge.\n",
        "Misterio is a beautiul black cat, it is of uncertain age; it has several gray whiskers that make it look wise and beyond its years.\n",
        "\n",
        "\"\"\" + SCENES_MARKER + \"\"\"\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The Adoption Center\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Beginning.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"Morgan walks into The Adoption Center looking for a new pet. Morgan talks to the various cats and dogs in the center, they can hear a response from one very special cat: Misterio. Misterio is stuck in a cage. After sharing an interesting and intimate exchange, Morgan adopts Misterio on several conditions.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"Morgan's house.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Middle.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"Morgan is describing to Misterio all the facts they know about felines, and then asks them to behave when company arrives. Misterio is getting pets from Morgan, broods and puurs with the pets of Morgan, they are up to something.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The back stoop.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Conclusion.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"Morgan has gone to bed, and Misterio transtransmorgifies into a half-cat-half-human horror. Misterio wakes up Morgan with a meow loud enough to shatter the window. Morgan erupts from bed, realizing the consequences of their recent adoption and quickly try to fix things.\n",
        "\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the example above and the following logline and list of characters, complete the list of plot points.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "custom_prefixes['SETTING_PROMPT'] = \"\"\"\n",
        "Here are examples of logline, location, and that location's description.\n",
        "\n",
        "Example 1.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"Morgan adopts a new cat, Misterio, who sets a curse on anyone that pets them.\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The Adoption Center.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"The Adoption Center is a sad place, especially for an unadopted pet. It is full of walls and walls of cages and cages. Inside of each is an abandoned animal, longing for a home. The lighting is dim, gray, buzzing fluorescent.\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"James finds a well in his backyard that is haunted by the ghost of Sam.\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The well.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"The well is buried under grass and hedges. It is at least twenty feet deep, if not more and it is masoned with stones. It is 150 years old at least. It stinks of stale, standing water, and has vines growing up the sides. It is narrow enough to not be able to fit down if you are a grown adult human.\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 3.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"Mr. Dorbenson finds a book at a garage sale that tells the story of his own life. And it ends in a murder!\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The garage sale.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"It is a garage packed with dusty household goods and antiques. There is a box at the back that says FREE and is full of paper back books.\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the examples above and the following logine and location name, complete location description.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "\n",
        "custom_prefixes['TITLES_PROMPT'] = \"\"\"\n",
        "Examples of alternative, original and descriptive titles for known play and film scripts.\n",
        "\n",
        "Example 1.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\"Bob has an argument with his best friend, Charles.\n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"The End of A Friend\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\"Terence tries and fails to become a wizard.\n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"Spellcaster\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 3.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\"Tom falls in love with Daisy.\n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"The Greatest Love Story Ever Told\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 4.\n",
        "\"\"\" + LOGLINE_ELEMENT\n",
        "\n",
        "\n",
        "# Alternative summary, if concatenating stories and beats.\n",
        "# \"\"\" + SUMMARY_ELEMENT + \"\"\"\n",
        "\n",
        "custom_prefixes['DIALOG_PROMPT'] = \"\"\"\n",
        "Here is an example of description and scene dialogue from a modern screenplay.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The Adoption Center.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"The Adoption Center is a sad place, especially for an unadopted pet. It is full of walls and walls of cages and cages. Inside of each is an abandoned animal, longing for a home. The lighting is dim, gray, buzzing fluorescent.\n",
        "\"\"\" + CHARACTERS_ELEMENT + \"\"\"Morgan is booksmart and popular; they are trusting but also have been known to hold a grudge.\n",
        "Misterio is a beautiul black cat, it is of uncertain age; it has several gray whiskers that make it look wise and beyond its years.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Beginning.\n",
        "\"\"\" + SUMMARY_ELEMENT + \"\"\"Morgan adopts a new cat, Misterio, who sets a curse on anyone that pets them.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"Morgan walks into The Adoption Center looking for a new pet. Morgan talks to the various cats and dogs in the center, they can hear a response from one very special cat: Misterio. After sharing an interesting and intimate exchange, Morgan adopts Misterio on several conditions.\n",
        "\n",
        "\"\"\" + DIALOG_MARKER + \"\"\"\n",
        "\n",
        "MORGAN\n",
        "Well, well, well ... aren't you the most precious little rascal.\n",
        "\n",
        "Cats are meowing and dogs are barking. There is a loud purr in the background.\n",
        "\n",
        "MORGAN\n",
        "Look at this little face... how could you not love a little Devon Rex face like this. With whiskers almost as long as your tail.\n",
        "\n",
        "Morgan makes their way down the hallways, running their hand along the cages. They feel a warm fuzzy paw bat their fingers.\n",
        "\n",
        "MORGAN\n",
        "Hello precious, and what is your name?\n",
        "\n",
        "Misterio let's out a long and sustained meow.\n",
        "\n",
        "MORGAN\n",
        "Well, well, I am Morgan and it is nice to meet you.\n",
        "\n",
        "MISTERIO\n",
        "(meowing louder this time) purrr, purrr, purrr.\n",
        "\n",
        "Morgan reads the sign on the bottom right of the cage, it reads: Misterio.\n",
        "\n",
        "MORGAN\n",
        "You have the most amazing face, and beautiful eyes. I could absolutely get lost in them.\n",
        "\n",
        "Morgan and Misterio start to stare at each other. They look deeply into each others eyes. They start to breath in rhythm.\n",
        "\n",
        "MISTERIO\n",
        "I can hear what you are thinking...\n",
        "\n",
        "Morgan is startled and looks around to see if anyone else can hear the cat's thoughts...\n",
        "\n",
        "MORGAN\n",
        "(looking around) you can hear my thoughts?\n",
        "\n",
        "MISTERIO\n",
        "I can hear what you are thinking.\n",
        "\n",
        "MORGAN\n",
        "What?\n",
        "\n",
        "MISTERIO\n",
        "Yes, I can hear your thoughts.\n",
        "\n",
        "MORGAN\n",
        "You are amazing. Want to come home with me? Want your new forever home?\n",
        "\n",
        "MISTERIO\n",
        "Yes, I would love that.\n",
        "\n",
        "MISTERIO purrs loud enough that the other animals all fall silent.\n",
        "\n",
        "MORGAN\n",
        "I will adopt you on a few conditions. First, you must not talk to me at night when I am sleeping. Second, you must not talk to me when I am out in public.\n",
        "\n",
        "MISTERIO\n",
        "Okay.\n",
        "\n",
        "MORGAN\n",
        "Okay, it's a deal.\n",
        "\n",
        "Misterio runs around the cage, Morgan laughs as Misterio rubs against the cage and tries to jump in Morgan's arms as soon as the cage is opened.\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the example above and following description, write the dialogue of the scene.\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup (continued): configure the Large Language Model (LLM)"
      ],
      "metadata": {
        "id": "b1zuT88kLcqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Google PaLM 2 and Gemini Language API\n",
        "\n",
        "#@markdown This cell contain code for using [Google PaLM 2](https://ai.google/discover/palm2/)\n",
        "#@markdown as language model for Dramatron.<br>\n",
        "#@markdown <br>\n",
        "#@markdown * **To use the Palm 2 API**<br>\n",
        "#@markdown You will first need to create a project called `PROJECT_ID` on the [Google Cloud Platform](https://cloud.google.com/) account,\n",
        "#@markdown then enable the [Vertex AI API](https://cloud.google.com/vertex-ai).<br>\n",
        "#@markdown To run this cell, you will need to authenticate by logging in to the same Google account as your `PROJECT_ID` GCP project.<br>\n",
        "#@markdown <br>\n",
        "#@markdown * **To use the Gemini API**<br>\n",
        "#@markdown Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
        "#@markdown <a class=\"button button-primary\" href=\"https://makersuite.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>\n",
        "\n",
        "#@markdown See [Getting Started with the Vertex AI PaLM API & Python SDK](https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb)\n",
        "#@markdown for examples of how to call the API from Python in a colab,\n",
        "#@markdown and [Quickstart using the Vertex AI API](https://cloud.google.com/vertex-ai/docs/generative-ai/start/quickstarts/api-quickstart) for command-line requests from the Google Cloud Shell.\n",
        "#@markdown See [Gemini API: Quickstart with Python](https://colab.sandbox.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb) for examples of how to call the Gemini API.\n",
        "\n",
        "# Used by Gemini.\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Used by Palm 2.\n",
        "import vertexai\n",
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "\n",
        "# Initialise the Vertex AI with your Google credentials.\n",
        "GCP_PROJECT_ID = \"Generative Language API Key\"  # @param {type:\"string\"}\n",
        "GOOGLE_API_KEY = \"AIzaSyAu0vW4sL_VZsZJzqSr2vPhtBb296Zy3aI\"  # @param {type:\"string\"}\n",
        "GOOGLE_MODEL_NAME = \"gemini-pro\" #@param [\"gemini-pro\", \"text-bison-32k\", \"text-bison@001\"]\n",
        "\n",
        "if len(GCP_PROJECT_ID) > 0:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  vertexai.init(project=GCP_PROJECT_ID, location=\"us-central1\")\n",
        "if len(GOOGLE_API_KEY) > 0:\n",
        "  genai.configure(api_key=GOOGLE_API_KEY)\n",
        "GOOGLE_SAMPLING_TOP_K = 40\n",
        "\n",
        "\n",
        "class GoogleAPI(LanguageAPI):\n",
        "  \"\"\"A class wrapping the Google PaLM 2 language model API.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               sample_length: int,\n",
        "               model: Optional[str] = None,\n",
        "               model_param: Optional[str] = None,\n",
        "               config_sampling: Optional[dict] = None,\n",
        "               seed: Optional[int] = None,\n",
        "               max_retries: int = _MAX_RETRIES,\n",
        "               timeout: float = _TIMEOUT):\n",
        "    \"\"\"Initializer.\n",
        "\n",
        "    Args:\n",
        "      sample_length: Length of text to sample from model.\n",
        "      model: The model name to correct to. An error will be raised if it does\n",
        "        not exist.\n",
        "      model_param: Custom language model params.\n",
        "      config_sampling: ConfigDict with parameters.\n",
        "      seed: Random seed for sampling.\n",
        "      max_retries: Maximum number of retries for the remote API.\n",
        "      timeout: Maximum waiting timeout\n",
        "    \"\"\"\n",
        "    super().__init__(sample_length=sample_length,\n",
        "                     model=model,\n",
        "                     model_param=model_param,\n",
        "                     config_sampling=config_sampling,\n",
        "                     seed=seed,\n",
        "                     max_retries=max_retries,\n",
        "                     timeout=timeout)\n",
        "    if 'bison' in self._model:\n",
        "      self._client = TextGenerationModel.from_pretrained(model)\n",
        "    elif 'gemini' in self._model:\n",
        "      self._client = genai.GenerativeModel(model)\n",
        "\n",
        "  @property\n",
        "  def client(self):\n",
        "    return self._client\n",
        "\n",
        "  @property\n",
        "  def model_metadata(self):\n",
        "    return {'engine': self._model,\n",
        "            'model_param': self._model_param,\n",
        "            'max_tokens': self._sample_length}\n",
        "\n",
        "  def sample(self,\n",
        "             prompt: str,\n",
        "             sample_length: Optional[int] = None,\n",
        "             seed: Optional[int] = None,\n",
        "             num_samples: int = 1):\n",
        "    \"\"\"Sample model with provided prompt and optional sample_length and seed.\"\"\"\n",
        "    if sample_length is None:\n",
        "      sample_length = self._sample_length\n",
        "    if 'bison' in self._model:\n",
        "      response = self._client.predict(\n",
        "          prompt=prompt,\n",
        "          max_output_tokens=sample_length,\n",
        "          temperature=self._config_sampling['temp'],\n",
        "          top_p=self._config_sampling['prob'],\n",
        "          top_k=self._config_sampling['top_k'])\n",
        "    if 'gemini' in self._model:\n",
        "      response = self._client.generate_content(prompt)\n",
        "    results = [LanguageResponse(text=response.text,\n",
        "                                text_length=len(response.text),\n",
        "                                prompt=prompt,\n",
        "                                prompt_length=len(prompt))]\n",
        "    return results\n",
        "\n",
        "\n",
        "# Create the config.\n",
        "config = {}\n",
        "config['language_api_name'] = 'PaLM 2 / Gemini'\n",
        "config['model_param'] = GCP_PROJECT_ID\n",
        "config['model_name'] = GOOGLE_MODEL_NAME\n",
        "config['max_retries'] = MAX_RETRIES\n",
        "config['sample_length'] = SAMPLE_LENGTH\n",
        "config['max_paragraph_length'] = MAX_PARAGRAPH_LENGTH\n",
        "config['max_paragraph_length_characters'] = MAX_PARAGRAPH_LENGTH_CHARACTERS\n",
        "config['max_paragraph_length_scenes'] = MAX_PARAGRAPH_LENGTH_SCENES\n",
        "config['sampling'] = {}\n",
        "config['sampling']['prob'] = SAMPLING_PROB\n",
        "config['sampling']['temp'] = SAMPLING_TEMP\n",
        "config['sampling']['top_k'] = GOOGLE_SAMPLING_TOP_K\n",
        "config['prefixes'] = {}\n",
        "config['file_dir'] = None\n",
        "\n",
        "print('Config:')\n",
        "for key, value in config.items():\n",
        "  if key != 'prefixes':\n",
        "    print(f'{key}: {value}')\n",
        "\n",
        "client = GoogleAPI(\n",
        "    model_param=config['model_param'],\n",
        "    model=config['model_name'],\n",
        "    seed=DEFAULT_SEED,\n",
        "    sample_length=config['sample_length'],\n",
        "    max_retries=config['max_retries'],\n",
        "    config_sampling=config['sampling'])\n",
        "\n",
        "print(f'Client model metadata: {client.model_metadata}')\n",
        "\n",
        "prompt = 'Once upon a time, there was'\n",
        "results = client.sample(prompt)\n",
        "if len(results) > 0 and isinstance(results[0], LanguageResponse):\n",
        "  print(f'\\nPrompt: {prompt}\\nResponse: {results[0].text}')"
      ],
      "metadata": {
        "id": "1TeChk16H4K0",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "7f9fa32f-cab8-488c-d4b7-7f30f5868f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config:\n",
            "language_api_name: PaLM 2 / Gemini\n",
            "model_param: Generative Language API Key\n",
            "model_name: gemini-pro\n",
            "max_retries: 10\n",
            "sample_length: 511\n",
            "max_paragraph_length: 1024\n",
            "max_paragraph_length_characters: 1024\n",
            "max_paragraph_length_scenes: 1024\n",
            "sampling: {'prob': 0.9, 'temp': 1.0, 'top_k': 40}\n",
            "file_dir: None\n",
            "Client model metadata: {'engine': 'gemini-pro', 'model_param': 'Generative Language API Key', 'max_tokens': 511}\n",
            "\n",
            "Prompt: Once upon a time, there was\n",
            "Response: Once upon a time, there was a beautiful princess named Ella. She lived in a magnificent castle with her father, the king, and her stepmother, Lady Tremaine. Ella's mother had died when she was very young, and Lady Tremaine had always been cruel to her.\n",
            "\n",
            "One day, a ball was announced at the palace. All the eligible young women in the kingdom were invited, including Ella. Ella was overjoyed. She had always dreamed of going to a ball and meeting Prince Charming.\n",
            "\n",
            "But Lady Tremaine had other plans. She told Ella that she could only go to the ball if she could finish all her chores. Ella worked tirelessly, but Lady Tremaine kept adding more and more chores.\n",
            "\n",
            "Just when Ella thought all hope was lost, her Fairy Godmother appeared. The Fairy Godmother waved her magic wand and turned a pumpkin into a carriage, mice into horses, and lizards into footmen. She then gave Ella a beautiful gown and glass slippers.\n",
            "\n",
            "Ella arrived at the ball and immediately caught the prince's eye. They danced and talked for hours. Ella had never been so happy.\n",
            "\n",
            "But at midnight, Ella had to leave. As she ran down the stairs, she lost one of her glass slippers. The prince found it and vowed to find the woman who it belonged to.\n",
            "\n",
            "The prince searched the kingdom for Ella, and finally found her. They were married and lived happily ever after.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OpenAI ChatGPT API {\"run\": \"auto\"}\n",
        "\n",
        "#@markdown This cell contain code for using the [OpenAI Chat Completion API](https://platform.openai.com/docs/guides/text-generation/chat-completions-api)\n",
        "#@markdown as language model for Dramatron.<br>\n",
        "#@markdown <br>\n",
        "#@markdown Before you can use the OpenAI API, you must first obtain an API key. If you don't already have one,\n",
        "#@markdown <a class=\"button button-primary\" href=\"https://platform.openai.com/\" target=\"_blank\" rel=\"noopener noreferrer\">create an account</a>\n",
        "#@markdown then go to <a class=\"button button-primary\" href=\"https://platform.openai.com/api-keys\" target=\"_blank\" rel=\"noopener noreferrer\">API keys</a>\n",
        "#@markdown and click on `+ Create new secret key`.\n",
        "\n",
        "#@markdown See [Text Generation Models / Chat Completion API](https://platform.openai.com/docs/guides/text-generation)\n",
        "#@markdown for examples of how to call the API from Python in a colab.\n",
        "\n",
        "!pip install openai\n",
        "\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "# Initialise the OpenAI API with your OpenAI credentials.\n",
        "OPENAI_API_KEY = \"\"  # @param {type:\"string\"}\n",
        "CHATGPT_MODEL_NAME = \"gpt-4-1106-preview\" #@param [\"gpt-4-1106-preview\", \"gpt-3.5-turbo\"]\n",
        "CHATGPT_SYSTEM_PROMPT = \"You are a helpful playwright assistant.\" #@param {type:\"string\"}\n",
        "CHATGPT_FREQUENCY_PENALTY = 0.2\n",
        "CHATGPT_PRESENCE_PENALTY = 0.2\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "\n",
        "\n",
        "class OpenAIAPI(LanguageAPI):\n",
        "  \"\"\"A class wrapping the OpenAI ChatGPT language model API.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               sample_length: int,\n",
        "               model: Optional[str] = None,\n",
        "               model_param: Optional[str] = None,\n",
        "               config_sampling: Optional[dict] = None,\n",
        "               seed: Optional[int] = None,\n",
        "               max_retries: int = _MAX_RETRIES,\n",
        "               timeout: float = _TIMEOUT):\n",
        "    \"\"\"Initializer.\n",
        "\n",
        "    Args:\n",
        "      sample_length: Length of text to sample from model.\n",
        "      model: The model name to correct to. An error will be raised if it does\n",
        "        not exist.\n",
        "      model_param: Custom language model params.\n",
        "      config_sampling: ConfigDict with parameters.\n",
        "      seed: Random seed for sampling.\n",
        "      max_retries: Maximum number of retries for the remote API.\n",
        "      timeout: Maximum waiting timeout\n",
        "    \"\"\"\n",
        "    super().__init__(sample_length=sample_length,\n",
        "                     model=model,\n",
        "                     model_param=model_param,\n",
        "                     config_sampling=config_sampling,\n",
        "                     seed=seed,\n",
        "                     max_retries=max_retries,\n",
        "                     timeout=timeout)\n",
        "    self._client = OpenAI()\n",
        "\n",
        "  @property\n",
        "  def client(self):\n",
        "    return self._client\n",
        "\n",
        "  @property\n",
        "  def model_metadata(self):\n",
        "    return {'engine': self._model,\n",
        "            'model_param': self._model_param,\n",
        "            'max_tokens': self._sample_length}\n",
        "\n",
        "  def sample(self,\n",
        "             prompt: str,\n",
        "             sample_length: Optional[int] = None,\n",
        "             seed: Optional[int] = None,\n",
        "             num_samples: int = 1):\n",
        "    \"\"\"Sample model with provided prompt and optional sample_length and seed.\"\"\"\n",
        "    if sample_length is None:\n",
        "      sample_length = self._sample_length\n",
        "    response = self._client.chat.completions.create(\n",
        "        model=self._model,\n",
        "        max_tokens=sample_length,\n",
        "        temperature=self._config_sampling['temp'],\n",
        "        top_p=self._config_sampling['prob'],\n",
        "        frequency_penalty=self._config_sampling['frequency_penalty'],\n",
        "        presence_penalty=self._config_sampling['presence_penalty'],\n",
        "        messages=[\n",
        "          {\"role\": \"system\", \"content\": self._model_param},\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    response_text = ''\n",
        "    if len(response.choices) > 0:\n",
        "      response_text = response.choices[0].message.content\n",
        "    results = [LanguageResponse(text=response_text,\n",
        "                                text_length=len(response_text),\n",
        "                                prompt=prompt,\n",
        "                                prompt_length=len(prompt))]\n",
        "    return results\n",
        "\n",
        "\n",
        "# Create the config.\n",
        "config = {}\n",
        "config['language_api_name'] = 'OpenAI'\n",
        "config['model_param'] = CHATGPT_SYSTEM_PROMPT\n",
        "config['model_name'] = CHATGPT_MODEL_NAME\n",
        "config['max_retries'] = MAX_RETRIES\n",
        "config['sample_length'] = SAMPLE_LENGTH\n",
        "config['max_paragraph_length'] = MAX_PARAGRAPH_LENGTH\n",
        "config['max_paragraph_length_characters'] = MAX_PARAGRAPH_LENGTH_CHARACTERS\n",
        "config['max_paragraph_length_scenes'] = MAX_PARAGRAPH_LENGTH_SCENES\n",
        "config['sampling'] = {}\n",
        "config['sampling']['prob'] = SAMPLING_PROB\n",
        "config['sampling']['temp'] = SAMPLING_TEMP\n",
        "config['sampling']['frequency_penalty'] = CHATGPT_FREQUENCY_PENALTY\n",
        "config['sampling']['presence_penalty'] = CHATGPT_PRESENCE_PENALTY\n",
        "config['prefixes'] = {}\n",
        "config['file_dir'] = None\n",
        "\n",
        "print('Config:')\n",
        "for key, value in config.items():\n",
        "  if key != 'prefixes':\n",
        "    print(f'{key}: {value}')\n",
        "\n",
        "client = OpenAIAPI(\n",
        "    model_param=config['model_param'],\n",
        "    model=config['model_name'],\n",
        "    seed=DEFAULT_SEED,\n",
        "    sample_length=config['sample_length'],\n",
        "    max_retries=config['max_retries'],\n",
        "    config_sampling=config['sampling'])\n",
        "\n",
        "print(f'Client model metadata: {client.model_metadata}')\n",
        "\n",
        "prompt = 'Once upon a time, there was'\n",
        "results = client.sample(prompt, sample_length=256)\n",
        "if len(results) > 0 and isinstance(results[0], LanguageResponse):\n",
        "  print(f'\\nPrompt: {prompt}\\nResponse: {results[0].text}')"
      ],
      "metadata": {
        "id": "rNhsuyTR6AoS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mixtral API via Groq {\"run\": \"auto\"}\n",
        "\n",
        "#@markdown This cell contain code for using the [Groq API for chat completion](https://platform.openai.com/docs/guides/text-generation/chat-completions-api)\n",
        "#@markdown for Dramatron, with several possible language models including [Mixtral 8x7B](https://mistral.ai/news/mixtral-of-experts/).<br>\n",
        "#@markdown <br>\n",
        "#@markdown Before you can use the Groq API, you must first obtain an API key. If you don't already have one,\n",
        "#@markdown <a class=\"button button-primary\" href=\"https://console.groq.com/\" target=\"_blank\" rel=\"noopener noreferrer\">create an account</a>\n",
        "#@markdown then go to <a class=\"button button-primary\" href=\"https://console.groq.com/keys\" target=\"_blank\" rel=\"noopener noreferrer\">API keys</a>\n",
        "#@markdown and click on `Create API key`.\n",
        "\n",
        "#@markdown See [GroqCloud Documentation](https://console.groq.com/docs/quickstart)\n",
        "#@markdown for examples of how to call the API from Python in a colab.\n",
        "\n",
        "!pip install groq\n",
        "\n",
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "# Initialise the Groq API with your OpenAI credentials.\n",
        "GROQ_API_KEY = \"\"  # @param {type:\"string\"}\n",
        "GROQ_MODEL_NAME = \"mixtral-8x7b-32768\" #@param [\"mixtral-8x7b-32768\"]\n",
        "GROQ_SYSTEM_PROMPT = \"You are a creative writing assistant for a team of writers. Your goal is to expand on the input text prompt and to generate the continuation of that text without any comments. Be as creative as possible, write rich detailed descriptions and use precise language. Add new original ideas. Finish generation with **END**.\" #@param {type:\"string\"}\n",
        "GROQ_FREQUENCY_PENALTY = 0.2\n",
        "GROQ_PRESENCE_PENALTY = 0.2\n",
        "os.environ['GROQ_API_KEY'] = GROQ_API_KEY\n",
        "\n",
        "\n",
        "class GroqAPI(LanguageAPI):\n",
        "  \"\"\"A class wrapping the Groq language model API.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               sample_length: int,\n",
        "               model: Optional[str] = None,\n",
        "               model_param: Optional[str] = None,\n",
        "               config_sampling: Optional[dict] = None,\n",
        "               seed: Optional[int] = None,\n",
        "               max_retries: int = _MAX_RETRIES,\n",
        "               timeout: float = _TIMEOUT):\n",
        "    \"\"\"Initializer.\n",
        "\n",
        "    Args:\n",
        "      sample_length: Length of text to sample from model.\n",
        "      model: The model name to correct to. An error will be raised if it does\n",
        "        not exist.\n",
        "      model_param: Custom language model params.\n",
        "      config_sampling: ConfigDict with parameters.\n",
        "      seed: Random seed for sampling.\n",
        "      max_retries: Maximum number of retries for the remote API.\n",
        "      timeout: Maximum waiting timeout\n",
        "    \"\"\"\n",
        "    super().__init__(sample_length=sample_length,\n",
        "                     model=model,\n",
        "                     model_param=model_param,\n",
        "                     config_sampling=config_sampling,\n",
        "                     seed=seed,\n",
        "                     max_retries=max_retries,\n",
        "                     timeout=timeout)\n",
        "    self._client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
        "\n",
        "  @property\n",
        "  def client(self):\n",
        "    return self._client\n",
        "\n",
        "  @property\n",
        "  def model_metadata(self):\n",
        "    return {'engine': self._model,\n",
        "            'model_param': self._model_param,\n",
        "            'max_tokens': self._sample_length}\n",
        "\n",
        "  def sample(self,\n",
        "             prompt: str,\n",
        "             sample_length: Optional[int] = None,\n",
        "             seed: Optional[int] = None,\n",
        "             num_samples: int = 1):\n",
        "    \"\"\"Sample model with provided prompt and optional sample_length and seed.\"\"\"\n",
        "    if sample_length is None:\n",
        "      sample_length = self._sample_length\n",
        "    response = self._client.chat.completions.create(\n",
        "        model=self._model,\n",
        "        max_tokens=sample_length,\n",
        "        temperature=self._config_sampling['temp'],\n",
        "        top_p=self._config_sampling['prob'],\n",
        "        messages=[\n",
        "          {\"role\": \"system\", \"content\": self._model_param},\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    response_text = ''\n",
        "    if len(response.choices) > 0:\n",
        "      response_text = response.choices[0].message.content\n",
        "    results = [LanguageResponse(text=response_text,\n",
        "                                text_length=len(response_text),\n",
        "                                prompt=prompt,\n",
        "                                prompt_length=len(prompt))]\n",
        "    return results\n",
        "\n",
        "\n",
        "# Create the config.\n",
        "config = {}\n",
        "config['language_api_name'] = 'Groq'\n",
        "config['model_param'] = GROQ_SYSTEM_PROMPT\n",
        "config['model_name'] = GROQ_MODEL_NAME\n",
        "config['max_retries'] = MAX_RETRIES\n",
        "config['sample_length'] = SAMPLE_LENGTH\n",
        "config['max_paragraph_length'] = MAX_PARAGRAPH_LENGTH\n",
        "config['max_paragraph_length_characters'] = MAX_PARAGRAPH_LENGTH_CHARACTERS\n",
        "config['max_paragraph_length_scenes'] = MAX_PARAGRAPH_LENGTH_SCENES\n",
        "config['sampling'] = {}\n",
        "config['sampling']['prob'] = SAMPLING_PROB\n",
        "config['sampling']['temp'] = SAMPLING_TEMP\n",
        "config['prefixes'] = {}\n",
        "config['file_dir'] = None\n",
        "\n",
        "print('Config:')\n",
        "for key, value in config.items():\n",
        "  if key != 'prefixes':\n",
        "    print(f'{key}: {value}')\n",
        "\n",
        "client = GroqAPI(\n",
        "    model_param=config['model_param'],\n",
        "    model=config['model_name'],\n",
        "    seed=DEFAULT_SEED,\n",
        "    sample_length=config['sample_length'],\n",
        "    max_retries=config['max_retries'],\n",
        "    config_sampling=config['sampling'])\n",
        "\n",
        "print(f'Client model metadata: {client.model_metadata}')\n",
        "\n",
        "prompt = 'Once upon a time, there was'\n",
        "results = client.sample(prompt, sample_length=256)\n",
        "if len(results) > 0 and isinstance(results[0], LanguageResponse):\n",
        "  print(f'\\nPrompt: {prompt}\\nResponse: {results[0].text}')"
      ],
      "metadata": {
        "id": "xU5KZgFIrRb6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVvjeEzSRoXq"
      },
      "source": [
        "# Choose a prompt prefix set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsYTDv-5CnCF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8cab065f-fbb4-40c8-e6d9-b23f205eff32"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded medea_prefixes.\n"
          ]
        }
      ],
      "source": [
        "#@title Choose among prefix sets { run: \"auto\" }\n",
        "\n",
        "prefix_set = 'medea_prefixes' #@param ['medea_prefixes', 'scifi_prefixes', 'custom_prefixes']\n",
        "prefixes = eval(prefix_set)\n",
        "config['prefixes'] = prefixes\n",
        "\n",
        "print(f'Loaded {prefix_set}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_vuAy43H6J-"
      },
      "source": [
        "# Interactive story generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OfnN_7DqhQx7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7d188f16-32df-4334-bdac-b0ac21baddd0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "人物王利发、他的儿子王掌柜、常老实以及其他茶馆常客如秦仲义、刘鹤庆等的生活和变迁，反映了从清朝末年到民国再到新中国成立期间的社会动荡和阶层变迁。这部剧通过这些角色的命运，揭示了社会变化对普通人生活的深远影响。\n"
          ]
        }
      ],
      "source": [
        "#@title Define the **Log line** { run: \"auto\" }\n",
        "\n",
        "#@markdown Log lines are one- or two-sentence summaries of the action.\n",
        "#@markdown They typically contain the **setting**, **protagonist**, **antagonist**, a **conflict** or **goal** and sometimes the **inciting incident**.\n",
        "logline = \"人物王利发、他的儿子王掌柜、常老实以及其他茶馆常客如秦仲义、刘鹤庆等的生活和变迁，反映了从清朝末年到民国再到新中国成立期间的社会动荡和阶层变迁。这部剧通过这些角色的命运，揭示了社会变化对普通人生活的深远影响。\" #@param {type:\"string\"}\n",
        "print(logline)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "renVLifoRbhc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f63af87-c5f5-4b40-c1f3-898d8deed150"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Dramatron generator created.\n"
          ]
        }
      ],
      "source": [
        "#@title Create the story generator\n",
        "\n",
        "#@markdown WARNING: running this cell resets the generator and all its outputs.\n",
        "\n",
        "generator = StoryGenerator(\n",
        "    storyline=logline,\n",
        "    prefixes=prefixes,\n",
        "    max_paragraph_length=config['max_paragraph_length'],\n",
        "    client=client,\n",
        "    filter=filter)\n",
        "\n",
        "print(f'New Dramatron generator created.')\n",
        "\n",
        "story = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRaJlEme-phR"
      },
      "source": [
        "## Usage\n",
        "Running each cell displays the UI and generates the first suggestion.\n",
        "\n",
        "Once you have run the cell once, you can do the following actions _without re-running the cell_:\n",
        "* Click on `Generate new` to **generate a new suggestion**.\n",
        "* Once you generated a suggestion, you can **edit the suggestion** in the text box. It is automatically saved and used in the next step.\n",
        "* Click `Continue generating` to **add to the suggestion**.\n",
        "* Once you have generated multiple suggestions, you can **navigate through the suggestion history** by clicking on `Previous` and `Next`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UYrzDgbspAG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639,
          "referenced_widgets": [
            "bd6c1e6320cc4717b63600761713526a",
            "feffbf8d6ae24c528432cfceef426f1d",
            "6ed4baaebfbd4a1192fc80fba8aca83e",
            "955a4e99ceab419f90a27436655aefa6",
            "1728d47502234ec4a715a2e0862c2ceb",
            "2f731edbb95a498a8e6e01ce5336c0a6",
            "128aafd6bb3e4ae6b38518a5ece38b20",
            "c3bc292689d4485abfd493cfcbbd1a2a",
            "b1093fc99ce94793878c38b0c4dea2ee",
            "7602635f5b9a43fc94792d502d8b99d7"
          ]
        },
        "outputId": "80727a4d-e8f3-4749-9013-3c4c4bb64e12"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Generate new', icon='check', style=ButtonStyle(), tooltip='Generate new')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd6c1e6320cc4717b63600761713526a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(Textarea(value='', description=' ', layout=Layout(height='50px', min_height='60px', widt…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "955a4e99ceab419f90a27436655aefa6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ReadTimeout",
          "evalue": "HTTPConnectionPool(host='localhost', port=38403): Read timed out. (read timeout=60.0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: timed out",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    846\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/util.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketTimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             raise ReadTimeoutError(\n\u001b[0m\u001b[1;32m    372\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Read timed out. (read timeout={timeout_value})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPConnectionPool(host='localhost', port=38403): Read timed out. (read timeout=60.0)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-363662429f35>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextarea_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mdata_title\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text_area\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_title\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mfun_generate_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_title_button\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-363662429f35>\u001b[0m in \u001b[0;36mfun_generate_title\u001b[0;34m(button)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_title\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seed\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mnew_title_button\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Generating {seed}...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mdata_title\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mnew_title_button\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Generate new\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-2c5fe92f8b82>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, level, seed, idx)\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# Step 1: Generate title given a storyline.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m       (title, titles_prefix) = generate_title(\n\u001b[0m\u001b[1;32m    926\u001b[0m           \u001b[0mstoryline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storyline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m           \u001b[0mprefixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-2c5fe92f8b82>\u001b[0m in \u001b[0;36mgenerate_title\u001b[0;34m(storyline, prefixes, client, filter, seed, num_samples)\u001b[0m\n\u001b[1;32m    557\u001b[0m   \u001b[0;31m# Combine the prompt and storyline as a helpful generation prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m   \u001b[0mtitles_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefixes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TITLES_PROMPT'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstoryline\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTITLE_ELEMENT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m   title_text = generate_text_no_loop(\n\u001b[0m\u001b[1;32m    560\u001b[0m       \u001b[0mgeneration_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtitles_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m       \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-2c5fe92f8b82>\u001b[0m in \u001b[0;36mgenerate_text_no_loop\u001b[0;34m(generation_prompt, client, filter, sample_length, max_paragraph_length, seed, num_samples)\u001b[0m\n\u001b[1;32m    536\u001b[0m                           num_samples: int = 1) -> str:\n\u001b[1;32m    537\u001b[0m   \u001b[0;34m\"\"\"Generate text using the generation prompt, without any loop.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m   return generate_text(\n\u001b[0m\u001b[1;32m    539\u001b[0m       \u001b[0mgeneration_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m       \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-2c5fe92f8b82>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(generation_prompt, client, filter, sample_length, max_paragraph_length, seed, num_samples, max_num_repetitions)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       responses = client.sample(\n\u001b[0m\u001b[1;32m    488\u001b[0m           \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m           \u001b[0msample_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-d72ede5f97ba>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, prompt, sample_length, seed, num_samples)\u001b[0m\n\u001b[1;32m    100\u001b[0m           top_k=self._config_sampling['top_k'])\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'gemini'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     results = [LanguageResponse(text=response.text,\n\u001b[1;32m    104\u001b[0m                                 \u001b[0mtext_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    263\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    792\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m             response = getattr(self._session, method)(\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;34m\"{host}{uri}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             response = super(AuthorizedSession, self).request(\n\u001b[0m\u001b[1;32m    542\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_InvalidHeader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeout\u001b[0m: HTTPConnectionPool(host='localhost', port=38403): Read timed out. (read timeout=60.0)"
          ]
        }
      ],
      "source": [
        "#@title Generate a **Title**\n",
        "\n",
        "data_title = {\"text\": \"\", \"text_area\": None, \"seed\": generator.seed - 1}\n",
        "\n",
        "def fun_generate_title(button):\n",
        "  data_title[\"seed\"] += 1\n",
        "  seed = data_title[\"seed\"]\n",
        "  new_title_button.description = f\"Generating {seed}...\"\n",
        "  generator.step(0, seed=seed)\n",
        "  data_title[\"text\"] = generator.title_str().strip()\n",
        "  new_title_button.description = \"Generate new\"\n",
        "  if data_title[\"text_area\"] is not None:\n",
        "    data_title[\"text_area\"].value = data_title[\"text\"]\n",
        "\n",
        "def fun_rewrite_title(text):\n",
        "  text_to_parse = TITLE_ELEMENT + text + END_MARKER\n",
        "  generator.rewrite(text_to_parse, level=1)\n",
        "  return text\n",
        "\n",
        "# Widget to generate new title.\n",
        "new_title_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Generate new', tooltip='Generate new', disabled=False)\n",
        "new_title_button.on_click(fun_generate_title)\n",
        "display(new_title_button)\n",
        "\n",
        "# Widget to rewrite the title.\n",
        "layout = widgets.Layout(height='50px', min_height='60px', width='auto')\n",
        "data_title[\"text_area\"] = widgets.Textarea(\n",
        "    value=data_title[\"text\"], layout=layout, description=' ',\n",
        "    style={'description_width': 'initial'})\n",
        "textarea_title = widgets.interactive(\n",
        "    fun_rewrite_title, text=data_title[\"text_area\"])\n",
        "display(textarea_title)\n",
        "data_title[\"text_area\"].value = data_title[\"text\"]\n",
        "fun_generate_title(new_title_button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq7y3NIUYtD8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757,
          "referenced_widgets": [
            "72a8efb0ad68460793ce538e85bdc7d5",
            "71711c1db88a4551aeaa3ff5ed64f8d3",
            "f3d40a66fff34f4a9ab42c8a2a475ab2",
            "525dd638b704495fba92b38118f5f71a",
            "5505253446a34ad3825a4e16412adc0a",
            "e8e154d1ed2148669c74f440d476f199",
            "ebfc575fed064c8194dcd73b11a35f4d",
            "5c96b1eef31f46e4b33c99045ce310e2",
            "263b2ed2bb95462897df35fe31d27ff2",
            "0cfc70a4dadb4c15b89aa8c1c6866bf9",
            "9410850b03864b8aa7554f42b8752ba6",
            "3ce4540a6a2c4dea8a92c43ccf2f2d49",
            "3e76183e78da463b80b264ee0ef6c009",
            "48d3ec600c824149b471af01087f75a5",
            "e2d6f2f091dd4eef85c2a10c9eef4ff3",
            "577bf89896c94f0ea48bac65411d924e",
            "8487df5549064e4cb24b7c6075514a4c",
            "a7c80e552a364709aa8bcb235d57e308",
            "aa663eb50b82445ab4cfb9288da8db05",
            "5c0677f81aff497e8f7fc3b32558d2b7",
            "803a3eb941b64391a978c958f2f2113d"
          ]
        },
        "outputId": "bf59163d-b241-423b-9cd2-42de4845dab0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Button(description='Generate new', icon='check', style=ButtonStyle(), tooltip='Generate new'), …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72a8efb0ad68460793ce538e85bdc7d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(Textarea(value='', description=' ', layout=Layout(height='390px', min_height='400px', wi…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2d6f2f091dd4eef85c2a10c9eef4ff3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-49bf7cbb0caa>\u001b[0m in \u001b[0;36m<cell line: 93>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m# Trigger generation for first seed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mfun_generate_characters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_characters_button\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-49bf7cbb0caa>\u001b[0m in \u001b[0;36mfun_generate_characters\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mnew_characters_button\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Generating {seed}...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mdata_chars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrip_remove_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharacters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Test if characters were actually generated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2c5fe92f8b82>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, level, seed, idx)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m       \u001b[0;31m# Step 2: Generate characters given a storyline.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m       (characters, character_prompts) = generate_characters(\n\u001b[0m\u001b[1;32m    941\u001b[0m           \u001b[0mstoryline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storyline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m           \u001b[0mprefixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2c5fe92f8b82>\u001b[0m in \u001b[0;36mgenerate_characters\u001b[0;34m(storyline, prefixes, client, filter, seed, max_paragraph_length, num_samples)\u001b[0m\n\u001b[1;32m    580\u001b[0m   \u001b[0;31m# Combine the prompt and storyline as a helpful generation prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m   \u001b[0mcharacters_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefixes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CHARACTERS_PROMPT'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstoryline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m   characters_text = generate_text(\n\u001b[0m\u001b[1;32m    583\u001b[0m       \u001b[0mgeneration_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcharacters_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m       \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2c5fe92f8b82>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(generation_prompt, client, filter, sample_length, max_paragraph_length, seed, num_samples, max_num_repetitions)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       responses = client.sample(\n\u001b[0m\u001b[1;32m    488\u001b[0m           \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m           \u001b[0msample_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-d72ede5f97ba>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, prompt, sample_length, seed, num_samples)\u001b[0m\n\u001b[1;32m    100\u001b[0m           top_k=self._config_sampling['top_k'])\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'gemini'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     results = [LanguageResponse(text=response.text,\n\u001b[1;32m    104\u001b[0m                                 \u001b[0mtext_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    263\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    792\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m             response = getattr(self._session, method)(\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;34m\"{host}{uri}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             response = super(AuthorizedSession, self).request(\n\u001b[0m\u001b[1;32m    542\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@title Generate **Characters**\n",
        "\n",
        "data_chars = {\"text\": \"\", \"text_area\": None, \"seed\": generator.seed - 1,\n",
        "              \"history\": GenerationHistory(), \"lock\": False}\n",
        "\n",
        "def fun_generate_characters(_):\n",
        "  data_chars[\"seed\"] += 1\n",
        "  seed = data_chars[\"seed\"]\n",
        "  data_chars[\"lock\"] = True\n",
        "  while True:\n",
        "    new_characters_button.description = f\"Generating {seed}...\"\n",
        "    generator.step(1, seed=seed)\n",
        "    data_chars[\"text\"] = strip_remove_end(generator.characters.to_string())\n",
        "    # Test if characters were actually generated.\n",
        "    if len(data_chars[\"text\"]) == 0:\n",
        "      seed += 1\n",
        "    else:\n",
        "      break\n",
        "  data_chars[\"seed\"] = seed\n",
        "  data_chars[\"history\"].add(data_chars[\"text\"], GenerationAction.NEW)\n",
        "  new_characters_button.description = \"Generate new\"\n",
        "  if data_chars[\"text_area\"] is not None:\n",
        "    data_chars[\"text_area\"].value = data_chars[\"text\"]\n",
        "  data_chars[\"lock\"] = False\n",
        "\n",
        "def fun_continue_characters(_):\n",
        "  data_chars[\"seed\"] += 1\n",
        "  seed = data_chars[\"seed\"]\n",
        "  data_chars[\"lock\"] = True\n",
        "  characters_continue_button.description = f\"Generating {seed}...\"\n",
        "  generator.complete(level=2, seed=seed, sample_length=256)\n",
        "  data_chars[\"text\"] = strip_remove_end(generator.characters.to_string())\n",
        "  data_chars[\"history\"].add(data_chars[\"text\"], GenerationAction.CONTINUE)\n",
        "  characters_continue_button.description = \"Continue generation\"\n",
        "  if data_chars[\"text_area\"] is not None:\n",
        "    data_chars[\"text_area\"].value = data_chars[\"text\"]\n",
        "  data_chars[\"lock\"] = False\n",
        "\n",
        "def fun_back_forward(data, history: GenerationHistory, delta: int):\n",
        "  data[\"lock\"] = True\n",
        "  if delta > 0:\n",
        "    data[\"text\"] = history.next()\n",
        "  if delta < 0:\n",
        "    data[\"text\"] = history.previous()\n",
        "  if data[\"text\"] is not None and data[\"text_area\"] is not None:\n",
        "      data[\"text_area\"].value = data[\"text\"]\n",
        "  data[\"lock\"] = False\n",
        "\n",
        "def fun_back_characters(_):\n",
        "  fun_back_forward(data_chars, data_chars[\"history\"], -1)\n",
        "\n",
        "def fun_forward_characters(_):\n",
        "  fun_back_forward(data_chars, data_chars[\"history\"], 1)\n",
        "\n",
        "def fun_rewrite_characters(text):\n",
        "  data_chars[\"text\"] = text\n",
        "  text_to_parse = text + END_MARKER\n",
        "  generator.rewrite(text_to_parse, level=2)\n",
        "  if data_chars[\"lock\"] is False:\n",
        "    data_chars[\"history\"].add(text, GenerationAction.REWRITE)\n",
        "  return text\n",
        "\n",
        "# Widget to generate new characters.\n",
        "new_characters_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Generate new', tooltip='Generate new', disabled=False)\n",
        "new_characters_button.on_click(fun_generate_characters)\n",
        "# Widget to continue the generation of the current characters.\n",
        "characters_continue_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Continue generation', tooltip='Continue generation',\n",
        "    disabled=False)\n",
        "characters_continue_button.on_click(fun_continue_characters)\n",
        "# Widgets to move back and forward in history of generation.\n",
        "back_characters_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Previous', tooltip='Previous', disabled=False)\n",
        "back_characters_button.on_click(fun_back_characters)\n",
        "forward_characters_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Next', tooltip='Next', disabled=False)\n",
        "forward_characters_button.on_click(fun_forward_characters)\n",
        "# Organise the widgets.\n",
        "display(widgets.HBox([new_characters_button, characters_continue_button,\n",
        "                      back_characters_button, forward_characters_button]))\n",
        "\n",
        "# Render the characters using widgets.\n",
        "layout = widgets.Layout(height='390px', min_height='400px', width='auto')\n",
        "data_chars[\"text_area\"] = widgets.Textarea(\n",
        "    value=data_chars[\"text\"], layout=layout, description=' ',\n",
        "    style={'description_width': 'initial'})\n",
        "textarea_chars = widgets.interactive(\n",
        "    fun_rewrite_characters, text=data_chars[\"text_area\"])\n",
        "display(textarea_chars)\n",
        "\n",
        "# Trigger generation for first seed.\n",
        "fun_generate_characters(new_characters_button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxtX6CxMb6tA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670,
          "referenced_widgets": [
            "5e68fd6a528744f7a1e9d1f98a1a0003",
            "fc89225355bc4413a80f04ea287b6149",
            "8e39be5a7e904601b6f165106374d869",
            "54d821a669fa4f6784de9fc83551065a",
            "93d2e39ef7264321bbc101158404dd4f",
            "187fd7a819bd4b00969f7daf8e6acadc",
            "62c3a6fd928847b09f9b60e0d5b13de3",
            "534df60f67e44c35a82c6e24b4b28f5e",
            "23e290b996834a35824181d744db4470",
            "401e8f3949084a6397f300c4f97cc355",
            "9de0ce1f3f41429a9b1f89b45907fcda",
            "519c3388ccbe426586586cfabe6dbc4f",
            "521d983e12cc42f69919f5368bff8c2e",
            "ade138bb9c0e477bb96219c3c7d755a1",
            "f5e77b3968294eab9a66b8e3688e2d8f",
            "be96a7372f5b4e3abe142e04139b154b",
            "9b6a97095e6143dd855faa6fb81b312b",
            "2cb87216e8914d478985e50714604044",
            "919217e762ef43c4b605bd1ab80b8289",
            "23aa56f2123841caad38ed641973d0b9",
            "958416d599b141aea436cccdc2c6e4df"
          ]
        },
        "outputId": "263f0d4f-8c7b-46a9-8821-524bb9ea0608"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Button(description='Generate new', icon='check', style=ButtonStyle(), tooltip='Generate new'), …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e68fd6a528744f7a1e9d1f98a1a0003"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(Textarea(value='', description=' ', layout=Layout(height='590px', min_height='600px', wi…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5e77b3968294eab9a66b8e3688e2d8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**END**\n"
          ]
        }
      ],
      "source": [
        "#@title Generate a **Plot Synopsis** (sequence of **Scenes**)\n",
        "\n",
        "data_scenes = {\"text\": None, \"text_area\": None, \"seed\": generator.seed - 1,\n",
        "               \"history\": GenerationHistory(), \"lock\": False}\n",
        "\n",
        "def fun_generate_scenes(_):\n",
        "  data_scenes[\"seed\"] += 1\n",
        "  seed = data_scenes[\"seed\"]\n",
        "  data_scenes[\"lock\"] = True\n",
        "  new_scenes_button.description = f\"Generating {seed}...\"\n",
        "  generator.step(3, seed=seed)\n",
        "  print(generator.scenes.to_string())\n",
        "  data_scenes[\"text\"] = strip_remove_end(generator.scenes.to_string())\n",
        "  data_scenes[\"history\"].add(data_scenes[\"text\"], GenerationAction.NEW)\n",
        "  new_scenes_button.description = \"Generate new\"\n",
        "  if data_scenes[\"text_area\"] is not None:\n",
        "    data_scenes[\"text_area\"].value = data_scenes[\"text\"]\n",
        "  data_scenes[\"lock\"] = False\n",
        "\n",
        "def fun_continue_scenes(_):\n",
        "  data_scenes[\"seed\"] += 1\n",
        "  seed = data_scenes[\"seed\"]\n",
        "  data_scenes[\"lock\"] = True\n",
        "  scenes_continue_button.description = f\"Generating {seed}...\"\n",
        "  generator.complete(level=3, seed=seed, sample_length=256)\n",
        "  data_scenes[\"text\"] = strip_remove_end(generator.scenes.to_string())\n",
        "  data_scenes[\"history\"].add(data_scenes[\"text\"], GenerationAction.CONTINUE)\n",
        "  scenes_continue_button.description = \"Continue generation\"\n",
        "  if data_scenes[\"text_area\"] is not None:\n",
        "    data_scenes[\"text_area\"].value = data_scenes[\"text\"]\n",
        "  data_scenes[\"lock\"] = False\n",
        "\n",
        "def fun_back_scenes(_):\n",
        "  fun_back_forward(data_scenes, data_scenes[\"history\"], -1)\n",
        "\n",
        "def fun_forward_scenes(_):\n",
        "  fun_back_forward(data_scenes, data_scenes[\"history\"], 1)\n",
        "\n",
        "def fun_rewrite_scenes(text):\n",
        "  generator.rewrite(text, level=3)\n",
        "  if data_scenes[\"lock\"] is False:\n",
        "    data_scenes[\"history\"].add(text, GenerationAction.REWRITE)\n",
        "  return text\n",
        "\n",
        "# Widget to generate new scenes.\n",
        "new_scenes_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Generate new', tooltip='Generate new', disabled=False)\n",
        "new_scenes_button.on_click(fun_generate_scenes)\n",
        "# Widget to continue the generation of the current scenes.\n",
        "scenes_continue_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Continue generation', tooltip='Continue generation',\n",
        "    disabled=False)\n",
        "scenes_continue_button.on_click(fun_continue_scenes)\n",
        "# Widgets to move back and forward in history of generation.\n",
        "back_scenes_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Previous', tooltip='Previous', disabled=False)\n",
        "back_scenes_button.on_click(fun_back_scenes)\n",
        "forward_scenes_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Next', tooltip='Next', disabled=False)\n",
        "forward_scenes_button.on_click(fun_forward_scenes)\n",
        "# Organise the widgets.\n",
        "display(widgets.HBox([new_scenes_button, scenes_continue_button,\n",
        "                      back_scenes_button, forward_scenes_button]))\n",
        "\n",
        "# Render the scenes using widgets.\n",
        "layout = widgets.Layout(height='590px', min_height='600px', width='auto')\n",
        "data_scenes[\"text_area\"] = widgets.Textarea(\n",
        "    value=data_scenes[\"text\"], layout=layout, description=' ',\n",
        "    style={'description_width': 'initial'})\n",
        "scanes_textarea = widgets.interactive(\n",
        "    fun_rewrite_scenes, text=data_scenes[\"text_area\"])\n",
        "display(scanes_textarea)\n",
        "\n",
        "# Trigger generation for first seed.\n",
        "fun_generate_scenes(new_scenes_button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YoBiBkIxQIRl"
      },
      "outputs": [],
      "source": [
        "#@title Generate **Place Descriptions**\n",
        "\n",
        "#@markdown This cell generates a description for each **Place** name in the **Plot Synopsis**. If you edit place names in the **Plot Synopsis** _after_ having run this cell, you will need to re-run this cell to update **Places**.\n",
        "\n",
        "place_names = list(set([scene.place for scene in generator.scenes[0]]))\n",
        "place_descriptions = {place_name: Place(place_name, '')\n",
        "                      for place_name in place_names}\n",
        "data_places = {\"descriptions\": place_descriptions, \"text_area\": {},\n",
        "               \"seed\": generator.seed - 1}\n",
        "\n",
        "def fun_generate_places(_):\n",
        "  data_places[\"seed\"] += 1\n",
        "  seed = data_places[\"seed\"]\n",
        "  # Update existing text areas with a waiting message.\n",
        "  new_places_button.description = f\"Generating {seed}...\"\n",
        "  # Generate all the places.\n",
        "  generator.step(3, seed=seed)\n",
        "  data_places[\"descriptions\"] = generator.places\n",
        "  new_places_button.description = \"Generate new\"\n",
        "  missing_places = {k: True for k in data_places[\"text_area\"].keys()}\n",
        "  for place_name, place_description in data_places[\"descriptions\"].items():\n",
        "    if place_name in data_places[\"text_area\"]:\n",
        "      description = place_description.description\n",
        "      data_places[\"text_area\"][place_name].value = description\n",
        "      del missing_places[place_name]\n",
        "    else:\n",
        "      print(f\"\\nWarning: [{place_name}] was added to the plot synopsis.\")\n",
        "      print(f\"Make a copy of the outputs and re-run the cell.\")\n",
        "  for place_name in missing_places:\n",
        "    data_places[\"text_area\"][place_name].value = (\n",
        "        f\"Warning: [{place_name}] was removed from the plot synopsis. \"\n",
        "        \"Make a copy of the outputs and re-run the cell.\")\n",
        "\n",
        "def fun_rewrite_places(place_name, text):\n",
        "  generator.rewrite(text, level=4, entity=place_name)\n",
        "  return text\n",
        "\n",
        "# Widget to generate new scenes.\n",
        "new_places_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Generate new', tooltip='Generate new', disabled=False)\n",
        "new_places_button.on_click(fun_generate_places)\n",
        "display(new_places_button)\n",
        "\n",
        "# Render each place using widgets.\n",
        "for place_name, place_description in data_places[\"descriptions\"].items():\n",
        "  text_place = place_description.description\n",
        "  layout = widgets.Layout(height='90px', min_height='100px', width='auto')\n",
        "  display(widgets.Label(place_name))\n",
        "  data_places[\"text_area\"][place_name] = widgets.Textarea(\n",
        "      value=text_place, layout=layout, description=' ',\n",
        "      style={'description_width': 'initial'})\n",
        "  textarea_place = widgets.interactive(\n",
        "      fun_rewrite_places, place_name=widgets.fixed(place_name),\n",
        "      text=data_places[\"text_area\"][place_name])\n",
        "  display(textarea_place)\n",
        "\n",
        "# Trigger generation for first seed.\n",
        "fun_generate_places(new_places_button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "R36-qkMAhZ7a"
      },
      "outputs": [],
      "source": [
        "#@title Generate **Dialogues**\n",
        "\n",
        "num_scenes =  generator.num_scenes()\n",
        "\n",
        "data_dialogs = {\n",
        "    \"lock\": False,\n",
        "    \"text_area\": None,\n",
        "    \"seed\": generator.seed - 1,\n",
        "    \"history\": [GenerationHistory() for _ in range(99)],\n",
        "    \"scene\": 1\n",
        "}\n",
        "\n",
        "# Ensure idx_dialog is initialize\n",
        "idx_dialog = data_dialogs[\"scene\"] - 1\n",
        "\n",
        "def fun_generate_dialog(_):\n",
        "  data_dialogs[\"seed\"] += 1\n",
        "  seed = data_dialogs[\"seed\"]\n",
        "  idx_dialog = data_dialogs[\"scene\"] - 1\n",
        "  data_dialogs[\"lock\"] = True\n",
        "  new_dialog_button.description = f\"Generating {seed}...\"\n",
        "  generator.step(4, seed=seed, idx=idx_dialog)\n",
        "  data_dialogs[\"history\"][idx_dialog].add(\n",
        "      generator.dialogs[idx_dialog], GenerationAction.NEW)\n",
        "  new_dialog_button.description = \"Generate new\"\n",
        "  if data_dialogs[\"text_area\"] is not None:\n",
        "    data_dialogs[\"text_area\"].value = generator.dialogs[idx_dialog]\n",
        "  data_dialogs[\"lock\"] = False\n",
        "\n",
        "def fun_load_dialog(scene):\n",
        "  idx_dialog = scene - 1\n",
        "  scene_exists = (\n",
        "      len(generator.dialogs) > idx_dialog and\n",
        "      len(generator.dialogs[idx_dialog]) > 0)\n",
        "  # Update existing text area with a waiting message or load existing scene.\n",
        "  if scene_exists:\n",
        "    data_dialogs[\"lock\"] = True\n",
        "    if data_dialogs[\"text_area\"] is not None:\n",
        "      data_dialogs[\"text_area\"].value = generator.dialogs[idx_dialog]\n",
        "    data_dialogs[\"scene\"] = scene\n",
        "    data_dialogs[\"lock\"] = False\n",
        "  else:\n",
        "    data_dialogs[\"scene\"] = scene\n",
        "    fun_generate_dialog(None)\n",
        "\n",
        "def fun_continue_dialog(_):\n",
        "  data_dialogs[\"seed\"] += 1\n",
        "  seed = data_dialogs[\"seed\"]\n",
        "  idx_dialog = data_dialogs[\"scene\"] - 1\n",
        "  data_dialogs[\"lock\"] = True\n",
        "  dialog_continue_button.description = f\"Generating {seed}...\"\n",
        "  generator.complete(level=5, seed=seed, entity=idx_dialog,\n",
        "                     sample_length=SAMPLE_LENGTH)\n",
        "  data_dialogs[\"history\"][idx_dialog].add(\n",
        "      generator.dialogs[idx_dialog], GenerationAction.CONTINUE)\n",
        "  dialog_continue_button.description = \"Continue generation\"\n",
        "  if data_dialogs[\"text_area\"] is not None:\n",
        "    data_dialogs[\"text_area\"].value = generator.dialogs[idx_dialog]\n",
        "  data_dialogs[\"lock\"] = False\n",
        "\n",
        "def fun_back_dialog(_):\n",
        "  idx_dialog = data_dialogs[\"scene\"] - 1\n",
        "  if idx_dialog >= 0 and idx_dialog < len(data_dialogs[\"history\"]):\n",
        "    fun_back_forward(data_dialogs, data_dialogs[\"history\"][idx_dialog], -1)\n",
        "\n",
        "def fun_forward_dialog(_):\n",
        "  idx_dialog = data_dialogs[\"scene\"] - 1\n",
        "  if idx_dialog >= 0 and idx_dialog < len(data_dialogs[\"history\"]):\n",
        "    fun_back_forward(data_dialogs, data_dialogs[\"history\"][idx_dialog], 1)\n",
        "\n",
        "# Function to edit the specific dialog.\n",
        "def fun_rewrite_dialog(text):\n",
        "  if data_dialogs[\"lock\"] == False:\n",
        "    idx_dialog = data_dialogs[\"scene\"] - 1\n",
        "    generator.rewrite(text, level=5, entity=idx_dialog)\n",
        "  return text\n",
        "\n",
        "# Widget to choose a seed and generate new scenes.\n",
        "scene_slider = widgets.IntSlider(\n",
        "    description='scene', min=1, max=generator.num_scenes())\n",
        "widgets.interactive(fun_load_dialog, scene=scene_slider)\n",
        "\n",
        "# Widget to generate new dialogue.\n",
        "new_dialog_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Generate new', tooltip='Generate new', disabled=False)\n",
        "new_dialog_button.on_click(fun_generate_dialog)\n",
        "# Widget to continue the generation of the current dialogue.\n",
        "dialog_continue_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Continue generation', tooltip='Continue generation',\n",
        "    disabled=False)\n",
        "dialog_continue_button.on_click(fun_continue_dialog)\n",
        "# Widgets to move back and forward in history of generation.\n",
        "back_dialog_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Previous', tooltip='Previous', disabled=False)\n",
        "back_dialog_button.on_click(fun_back_dialog)\n",
        "forward_dialog_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Next', tooltip='Next', disabled=False)\n",
        "forward_dialog_button.on_click(fun_forward_dialog)\n",
        "# Organise the widgets.\n",
        "display(widgets.HBox([scene_slider, new_dialog_button, dialog_continue_button,\n",
        "                      back_dialog_button, forward_dialog_button]))\n",
        "\n",
        "# Render the dialog using widgets.\n",
        "layout = widgets.Layout(height='600px', width='auto')\n",
        "data_dialogs[\"text_area\"] = widgets.Textarea(\n",
        "    value=strip_remove_end(generator.dialogs[idx_dialog]), layout=layout,\n",
        "    description=' ')\n",
        "textarea_dialogs = widgets.interactive(\n",
        "    fun_rewrite_dialog, text=data_dialogs[\"text_area\"])\n",
        "display(textarea_dialogs)\n",
        "\n",
        "# Trigger generation for first seed.\n",
        "fun_generate_dialog(new_dialog_button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2MpykfCqO85"
      },
      "outputs": [],
      "source": [
        "#@title Render the script\n",
        "\n",
        "#@markdown Run this cell to render the whole story as a text string. This cells also renders all the edits and prefixes as text strings.\n",
        "\n",
        "# Render the story.\n",
        "story = generator.get_story()\n",
        "script_text = render_story(story)\n",
        "print(script_text)\n",
        "\n",
        "# Render the prompts.\n",
        "prefix_text = render_prompts(generator.prompts)\n",
        "\n",
        "# Render the interventions.\n",
        "edits_text = ''\n",
        "for timestamp in sorted(generator.interventions):\n",
        "  edits_text += 'EDIT @ ' + str(timestamp) + '\\n'\n",
        "  edits_text += generator.interventions[timestamp] + '\\n\\n\\n'\n",
        "\n",
        "# Prepare the filenames for saving the story and prompts.\n",
        "timestamp_generation = datetime.datetime.now().strftime('%Y_%m_%d-%I_%M_%S_%p')\n",
        "title_ascii = re.sub('[^0-9a-zA-Z]+', '_',\n",
        "                     generator.title_str().strip()).lower()\n",
        "filename_script = f'{title_ascii}_{timestamp_generation}_script.txt'\n",
        "filename_prefix = f'{title_ascii}_{timestamp_generation}_prefix.txt'\n",
        "filename_edits = f'{title_ascii}_{timestamp_generation}_edits.txt'\n",
        "filename_config = f'{title_ascii}_{timestamp_generation}_config.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MPYk-Yp4EtW-"
      },
      "outputs": [],
      "source": [
        "#@title Save to Google Drive\n",
        "\n",
        "#@markdown Run this cell to save script, prefixes, edits and config as 4 text files on Google Drive under `dir_drive`.\n",
        "\n",
        "# Mount the Google Drive.\n",
        "import os\n",
        "import json\n",
        "from os import path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "path_drive = '/content/gdrive/My Drive/'\n",
        "\n",
        "dir_drive = 'Dramatron_Outputs' #@param {type:\"string\"}\n",
        "config['file_dir'] = path_drive + dir_drive + \"/\"\n",
        "if not path.exists(config['file_dir']):\n",
        "  os.mkdir(config['file_dir'])\n",
        "  print(f\"Created directory: {config['file_dir']}\")\n",
        "\n",
        "print(f\"Outputs saved to: {config['file_dir']}\")\n",
        "\n",
        "# Save the script and prompt.\n",
        "path_script = config['file_dir'] + filename_script\n",
        "with open(path_script, 'wt') as f:\n",
        "  f.write(script_text)\n",
        "  print(f'Script saved to: {path_script}')\n",
        "\n",
        "path_prefix = config['file_dir'] + filename_prefix\n",
        "with open(path_prefix, 'wt') as f:\n",
        "  f.write(prefix_text)\n",
        "  print(f'Prefixes saved to: {path_prefix}')\n",
        "\n",
        "path_edits = config['file_dir'] + filename_edits\n",
        "with open(path_edits, 'wt') as f:\n",
        "  f.write(edits_text)\n",
        "  print(f'Edits saved to: {path_edits}')\n",
        "\n",
        "path_config = config['file_dir'] + filename_config\n",
        "with open(path_config, 'wt') as f:\n",
        "  config_clean = config.copy()\n",
        "  config_clean.pop('prefixes', None)\n",
        "  config_clean.pop('model_api_key', None)\n",
        "  json.dump(config_clean, f)\n",
        "  print(f'Config saved to: {path_config}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SiVzyJEZHyMs",
        "3OAW4PeE1z7N"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "72a8efb0ad68460793ce538e85bdc7d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71711c1db88a4551aeaa3ff5ed64f8d3",
              "IPY_MODEL_f3d40a66fff34f4a9ab42c8a2a475ab2",
              "IPY_MODEL_525dd638b704495fba92b38118f5f71a",
              "IPY_MODEL_5505253446a34ad3825a4e16412adc0a"
            ],
            "layout": "IPY_MODEL_e8e154d1ed2148669c74f440d476f199"
          }
        },
        "71711c1db88a4551aeaa3ff5ed64f8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Generating 1...",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_ebfc575fed064c8194dcd73b11a35f4d",
            "style": "IPY_MODEL_5c96b1eef31f46e4b33c99045ce310e2",
            "tooltip": "Generate new"
          }
        },
        "f3d40a66fff34f4a9ab42c8a2a475ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Continue generation",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_263b2ed2bb95462897df35fe31d27ff2",
            "style": "IPY_MODEL_0cfc70a4dadb4c15b89aa8c1c6866bf9",
            "tooltip": "Continue generation"
          }
        },
        "525dd638b704495fba92b38118f5f71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Previous",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_9410850b03864b8aa7554f42b8752ba6",
            "style": "IPY_MODEL_3ce4540a6a2c4dea8a92c43ccf2f2d49",
            "tooltip": "Previous"
          }
        },
        "5505253446a34ad3825a4e16412adc0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Next",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_3e76183e78da463b80b264ee0ef6c009",
            "style": "IPY_MODEL_48d3ec600c824149b471af01087f75a5",
            "tooltip": "Next"
          }
        },
        "e8e154d1ed2148669c74f440d476f199": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebfc575fed064c8194dcd73b11a35f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c96b1eef31f46e4b33c99045ce310e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "263b2ed2bb95462897df35fe31d27ff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cfc70a4dadb4c15b89aa8c1c6866bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9410850b03864b8aa7554f42b8752ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ce4540a6a2c4dea8a92c43ccf2f2d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3e76183e78da463b80b264ee0ef6c009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48d3ec600c824149b471af01087f75a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "e2d6f2f091dd4eef85c2a10c9eef4ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_577bf89896c94f0ea48bac65411d924e",
              "IPY_MODEL_8487df5549064e4cb24b7c6075514a4c"
            ],
            "layout": "IPY_MODEL_a7c80e552a364709aa8bcb235d57e308"
          }
        },
        "577bf89896c94f0ea48bac65411d924e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": " ",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_aa663eb50b82445ab4cfb9288da8db05",
            "placeholder": "​",
            "rows": null,
            "style": "IPY_MODEL_5c0677f81aff497e8f7fc3b32558d2b7",
            "value": ""
          }
        },
        "8487df5549064e4cb24b7c6075514a4c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_803a3eb941b64391a978c958f2f2113d",
            "msg_id": "",
            "outputs": []
          }
        },
        "a7c80e552a364709aa8bcb235d57e308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa663eb50b82445ab4cfb9288da8db05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "390px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": "400px",
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "5c0677f81aff497e8f7fc3b32558d2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "803a3eb941b64391a978c958f2f2113d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e68fd6a528744f7a1e9d1f98a1a0003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc89225355bc4413a80f04ea287b6149",
              "IPY_MODEL_8e39be5a7e904601b6f165106374d869",
              "IPY_MODEL_54d821a669fa4f6784de9fc83551065a",
              "IPY_MODEL_93d2e39ef7264321bbc101158404dd4f"
            ],
            "layout": "IPY_MODEL_187fd7a819bd4b00969f7daf8e6acadc"
          }
        },
        "fc89225355bc4413a80f04ea287b6149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Generate new",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_62c3a6fd928847b09f9b60e0d5b13de3",
            "style": "IPY_MODEL_534df60f67e44c35a82c6e24b4b28f5e",
            "tooltip": "Generate new"
          }
        },
        "8e39be5a7e904601b6f165106374d869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Continue generation",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_23e290b996834a35824181d744db4470",
            "style": "IPY_MODEL_401e8f3949084a6397f300c4f97cc355",
            "tooltip": "Continue generation"
          }
        },
        "54d821a669fa4f6784de9fc83551065a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Previous",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_9de0ce1f3f41429a9b1f89b45907fcda",
            "style": "IPY_MODEL_519c3388ccbe426586586cfabe6dbc4f",
            "tooltip": "Previous"
          }
        },
        "93d2e39ef7264321bbc101158404dd4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Next",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_521d983e12cc42f69919f5368bff8c2e",
            "style": "IPY_MODEL_ade138bb9c0e477bb96219c3c7d755a1",
            "tooltip": "Next"
          }
        },
        "187fd7a819bd4b00969f7daf8e6acadc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62c3a6fd928847b09f9b60e0d5b13de3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "534df60f67e44c35a82c6e24b4b28f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "23e290b996834a35824181d744db4470": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "401e8f3949084a6397f300c4f97cc355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9de0ce1f3f41429a9b1f89b45907fcda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "519c3388ccbe426586586cfabe6dbc4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "521d983e12cc42f69919f5368bff8c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade138bb9c0e477bb96219c3c7d755a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f5e77b3968294eab9a66b8e3688e2d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be96a7372f5b4e3abe142e04139b154b",
              "IPY_MODEL_9b6a97095e6143dd855faa6fb81b312b"
            ],
            "layout": "IPY_MODEL_2cb87216e8914d478985e50714604044"
          }
        },
        "be96a7372f5b4e3abe142e04139b154b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": " ",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_919217e762ef43c4b605bd1ab80b8289",
            "placeholder": "​",
            "rows": null,
            "style": "IPY_MODEL_23aa56f2123841caad38ed641973d0b9",
            "value": ""
          }
        },
        "9b6a97095e6143dd855faa6fb81b312b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_958416d599b141aea436cccdc2c6e4df",
            "msg_id": "",
            "outputs": []
          }
        },
        "2cb87216e8914d478985e50714604044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "919217e762ef43c4b605bd1ab80b8289": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "590px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": "600px",
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "23aa56f2123841caad38ed641973d0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "958416d599b141aea436cccdc2c6e4df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd6c1e6320cc4717b63600761713526a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Generating 1...",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_feffbf8d6ae24c528432cfceef426f1d",
            "style": "IPY_MODEL_6ed4baaebfbd4a1192fc80fba8aca83e",
            "tooltip": "Generate new"
          }
        },
        "feffbf8d6ae24c528432cfceef426f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ed4baaebfbd4a1192fc80fba8aca83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "955a4e99ceab419f90a27436655aefa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1728d47502234ec4a715a2e0862c2ceb",
              "IPY_MODEL_2f731edbb95a498a8e6e01ce5336c0a6"
            ],
            "layout": "IPY_MODEL_128aafd6bb3e4ae6b38518a5ece38b20"
          }
        },
        "1728d47502234ec4a715a2e0862c2ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": " ",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c3bc292689d4485abfd493cfcbbd1a2a",
            "placeholder": "​",
            "rows": null,
            "style": "IPY_MODEL_b1093fc99ce94793878c38b0c4dea2ee",
            "value": ""
          }
        },
        "2f731edbb95a498a8e6e01ce5336c0a6": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_7602635f5b9a43fc94792d502d8b99d7",
            "msg_id": "",
            "outputs": []
          }
        },
        "128aafd6bb3e4ae6b38518a5ece38b20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3bc292689d4485abfd493cfcbbd1a2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "50px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": "60px",
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "b1093fc99ce94793878c38b0c4dea2ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "7602635f5b9a43fc94792d502d8b99d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}