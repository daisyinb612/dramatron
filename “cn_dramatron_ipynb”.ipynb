{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daisyinb612/dramatron/blob/main/%E2%80%9Ccn_dramatron_ipynb%E2%80%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BI4R8LJu0NTW"
      },
      "outputs": [],
      "source": [
        "#@title License\n",
        "license = \"\"\"\n",
        "Copyright 2022 DeepMind Technologies Limited\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n",
        "use this file except in compliance with the License. You may obtain a copy of\n",
        "the License at https://www.apache.org/licenses/LICENSE-2.0. Unless required by\n",
        "applicable law or agreed to in writing, software distributed under the License\n",
        "is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
        "KIND, either express or implied. See the License for the specific language\n",
        "governing permissions and limitations under the License.\n",
        "\"\"\"\n",
        "print(license)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smVKjDIBg5l-"
      },
      "source": [
        "# Dramatron\n",
        "\n",
        "**Piotr Mirowski, Kory Mathewson, Juliette Love, Jaylen Pittman**, based on an original prototype by **Richard Evans**.\n",
        "\n",
        "DeepMind, 2022\n",
        "\n",
        "Dramatron is a script writing tool that leverages large language models. It uses hierarchical generation to ensure long range consistency across the entire script. The work was published as a pre-print in Mirowski, Mathewson et al. (2022) \"[Co-Writing Screenplays and Theatre Scripts with Language Models: An Evaluation by Industry Professionals](https://arxiv.org/abs/2209.14958)\".\n",
        "\n",
        "![picture](https://github.com/deepmind/dramatron/raw/main/dramatron_logo.png)\n",
        "\n",
        "## Citing this work (paper and code):\n",
        "```bibtex\n",
        "@article{mirowski2022cowriting,\n",
        "  title={Co-Writing Screenplays and Theatre Scripts with Language Models: An Evaluation by Industry Professionals},\n",
        "  author={Mirowski, Piotr and Mathewson, Kory W and Pittman, Jaylen and Evans, Richard},\n",
        "  journal={arXiv preprint arXiv:2209.14958},\n",
        "  year={2022}\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiVzyJEZHyMs"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Run this set of cells to install and import libraries, define the code, set the parameters of Dramatron and Perspective API (moderation, optional) and the prompt sets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Google PaLM 2 only: Install dependencies (Vertex AI) and restart the colab runtime\n",
        "\n",
        "#@markdown The Python SDK for the Palm 2 API and the Gemini API, is contained in the [`google-generativeai`](https://pypi.org/project/google-generativeai/) package. Install the dependency using pip:\n",
        "!pip install -q -U google-generativeai\n",
        "# !pip install google-cloud-aiplatform --upgrade --user"
      ],
      "metadata": {
        "id": "Qf5r_vaxIr_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7WiSfJBhfnSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0a4faa-5c52-4240-f443-83ce90cb3087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imports imported successfully!\n"
          ]
        }
      ],
      "source": [
        "#@title Imports\n",
        "\n",
        "#@markdown Run this cell to import the required Python libraries.\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "import datetime\n",
        "import difflib\n",
        "import json\n",
        "import re\n",
        "import requests\n",
        "import sys\n",
        "import time\n",
        "from typing import Dict, List, NamedTuple, Optional, Union\n",
        "\n",
        "import collections\n",
        "from google.colab import files\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "print('Imports imported successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-RsP1ZNd3yH6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb4ea519-781b-41fc-9b0b-c41e857140d5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dramatron hyperparameters set.\n"
          ]
        }
      ],
      "source": [
        "#@title Dramatron hyperparameters { run: \"auto\" }\n",
        "\n",
        "#@markdown Run this cell to set the model hyperparameters. The cell will auto-run if you change them. We tested the model with these default values.\n",
        "\n",
        "#@markdown Default seed for generation (default: 1)\n",
        "DEFAULT_SEED =  1  #@param {type:\"integer\"}\n",
        "#@markdown Sampling top-p probability (default: 0.9) and temperature (default 1.0)\n",
        "SAMPLING_PROB =  0.9  #@param {type:\"slider\", min:0.8, max:1.0, step:0.01}\n",
        "SAMPLING_TEMP =  1.  #@param {type:\"slider\", min:0.8, max:1.0, step:0.01}\n",
        "#@markdown Max length for the generated title, place description and others, in tokens (defaults: 64, 128 and 511 respectively)\n",
        "SAMPLE_LENGTH_TITLE = 64 #@param [64, 128, 256, 511]\n",
        "SAMPLE_LENGTH_PLACE = 128 #@param [128, 256, 511]\n",
        "SAMPLE_LENGTH = 511 #@param [128, 256, 511]\n",
        "#@markdown Max lengths during repeated sampling, in case `<end>` is not found (default: 2048)\n",
        "MAX_PARAGRAPH_LENGTH_CHARACTERS = 1024 #@param [511, 1024, 2048, 4096]\n",
        "MAX_PARAGRAPH_LENGTH_SCENES = 1024 #@param [511, 1024, 2048, 4096]\n",
        "MAX_PARAGRAPH_LENGTH = 1024 #@param [511, 1024, 2048, 4096]\n",
        "#@markdown Unavailable API: max number of retries before giving up (default: 10)\n",
        "MAX_RETRIES = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "#@markdown Loop detection: max number of repetitions before resampling, and number of attempts to get out of the loop (default: 3)\n",
        "MAX_NUM_REPETITIONS = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "MAX_NUM_ATTEMPTS_GET_OUT_OF_LOOP = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "\n",
        "print('Dramatron hyperparameters set.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vWwxotb_A1w_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fffe1eb9-bf72-4c9d-d772-03454208ed7b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dramatron set-up complete.\n"
          ]
        }
      ],
      "source": [
        "#@title Dramatron code\n",
        "\n",
        "#@markdown This cell contains Dramatron's code. You need to run it only once.\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Script markers\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# END_MARKER = '<end>'\n",
        "# STOP_MARKER = '<stop>'\n",
        "# CHARACTER_MARKER = '<character>'\n",
        "# DESCRIPTION_MARKER = '<description>'\n",
        "# SCENES_MARKER = '<scenes>'\n",
        "# DIALOG_MARKER = '<dialog>'\n",
        "# TITLE_ELEMENT = 'Title: '\n",
        "# CHARACTERS_ELEMENT = 'Characters: '\n",
        "# DESCRIPTION_ELEMENT = 'Description: '\n",
        "# PLACE_ELEMENT = 'Place: '\n",
        "# PLOT_ELEMENT = 'Plot element: '\n",
        "# PREVIOUS_ELEMENT = 'Previous beat: '\n",
        "# SUMMARY_ELEMENT = 'Summary: '\n",
        "# BEAT_ELEMENT = 'Beat: '\n",
        "END_MARKER = '**END**'\n",
        "STOP_MARKER = '\\n'\n",
        "CHARACTER_MARKER = '**Character:** '\n",
        "DESCRIPTION_MARKER = '**Description:** '\n",
        "SCENES_MARKER = '**Scenes:**'\n",
        "DIALOG_MARKER = '**Dialog:**'\n",
        "LOGLINE_MARKER = \"**Logline:** \"\n",
        "TITLE_ELEMENT = 'Title: '\n",
        "CHARACTERS_ELEMENT = 'Characters: '\n",
        "DESCRIPTION_ELEMENT = 'Description: '\n",
        "PLACE_ELEMENT = 'Place: '\n",
        "PLOT_ELEMENT = 'Plot element: '\n",
        "PREVIOUS_ELEMENT = 'Previous beat: '\n",
        "SUMMARY_ELEMENT = 'Summary: '\n",
        "BEAT_ELEMENT = 'Beat: '\n",
        "LOGLINE_ELEMENT = \"Logline: \"\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Dramatron script entities\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "class Title(NamedTuple):\n",
        "  \"\"\"Title class.\"\"\"\n",
        "\n",
        "  title: str\n",
        "\n",
        "  @classmethod\n",
        "  def from_string(cls, text: str):\n",
        "    title = extract_elements(text, TITLE_ELEMENT, END_MARKER)[0]\n",
        "    return cls(title)\n",
        "\n",
        "  def to_string(self):\n",
        "    s = ''\n",
        "    s += TITLE_ELEMENT + self.title\n",
        "    s += END_MARKER\n",
        "    return s\n",
        "\n",
        "\n",
        "def get_title(title: Title) -> str:\n",
        "  return title.title\n",
        "\n",
        "\n",
        "class Character(NamedTuple):\n",
        "  \"\"\"Character class.\"\"\"\n",
        "\n",
        "  # Name of the character.\n",
        "  name: str\n",
        "\n",
        "  # A single sentence describing the character.\n",
        "  description: str\n",
        "\n",
        "  @classmethod\n",
        "  def from_string(cls, text: str):\n",
        "    elements = text.split(DESCRIPTION_MARKER)\n",
        "    if len(elements) == 2:\n",
        "      name = elements[0].strip()\n",
        "      description = elements[1].strip()\n",
        "      return cls(name, description)\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "\n",
        "def get_character_description(character: Character) -> str:\n",
        "  return character.description\n",
        "\n",
        "\n",
        "class Characters(NamedTuple):\n",
        "  \"\"\"Characters class, containing main characters and their descriptions.\"\"\"\n",
        "\n",
        "  # A dictionary of character descriptions.\n",
        "  character_descriptions: Dict[str, str]\n",
        "\n",
        "  @classmethod\n",
        "  def from_string(cls, text: str):\n",
        "    \"\"\"Parses the characters from the generated text.\"\"\"\n",
        "    text = text.strip()\n",
        "\n",
        "    # Extracts the character descriptions.\n",
        "    character_descriptions = {}\n",
        "    elements = extract_elements(text, CHARACTER_MARKER, STOP_MARKER)\n",
        "    for text_character in elements:\n",
        "      character = Character.from_string(text_character)\n",
        "      if character is not None:\n",
        "        character_descriptions[character.name] = character.description\n",
        "    return cls(character_descriptions)\n",
        "\n",
        "  def to_string(self):\n",
        "    s = '\\n'\n",
        "    for name, description in self.character_descriptions.items():\n",
        "      s += '\\n' + CHARACTER_MARKER + ' ' + name + ' ' + DESCRIPTION_MARKER + ' '\n",
        "      s += description + ' ' + STOP_MARKER + '\\n'\n",
        "    s += END_MARKER\n",
        "    return s\n",
        "\n",
        "\n",
        "def get_character_descriptions(characters: Characters) -> Dict[str, str]:\n",
        "  return characters.character_descriptions\n",
        "\n",
        "\n",
        "class Scene(NamedTuple):\n",
        "  \"\"\"Scene class.\"\"\"\n",
        "\n",
        "  # The name of the place where the scene unfolds.\n",
        "  place: str\n",
        "\n",
        "  # Name of the plot element (e.g., Beginning, Middle, Conclusion).\n",
        "  plot_element: str\n",
        "\n",
        "  # A short description of action/story/dramatic event occuring in the scene.\n",
        "  beat: str\n",
        "\n",
        "  def to_string(self):\n",
        "    s = PLACE_ELEMENT + ' ' + self.place + '\\n'\n",
        "    s += PLOT_ELEMENT + ' ' + self.plot_element + '\\n'\n",
        "    s += BEAT_ELEMENT + ' ' + self.beat + '\\n'\n",
        "    return s\n",
        "\n",
        "\n",
        "class Scenes(NamedTuple):\n",
        "  \"\"\"Scenes class.\"\"\"\n",
        "\n",
        "  # A list of scenes, with place, characters, plot element and beat.\n",
        "  scenes: List[Scene]\n",
        "\n",
        "  @classmethod\n",
        "  def from_string(cls, text: str):\n",
        "    \"\"\"Parse scenes from generated scenes_text.\"\"\"\n",
        "\n",
        "    places = extract_elements(text, PLACE_ELEMENT, PLOT_ELEMENT)\n",
        "    plot_elements = extract_elements(text, PLOT_ELEMENT, BEAT_ELEMENT)\n",
        "    beats = extract_elements(text, BEAT_ELEMENT, '\\n')\n",
        "\n",
        "    # Get the number of complete scenes.\n",
        "    num_complete_scenes = min([len(places), len(plot_elements), len(beats)])\n",
        "    scenes = []\n",
        "    for i in range(num_complete_scenes):\n",
        "      scenes.append(\n",
        "          Scene(Place.format_name(places[i]), plot_elements[i], beats[i]))\n",
        "    scenes = cls(scenes)\n",
        "    return scenes\n",
        "\n",
        "  def to_string(self):\n",
        "    s = ''\n",
        "    for scene in self.scenes:\n",
        "      s += '\\n' + scene.to_string()\n",
        "    s += END_MARKER\n",
        "    return s\n",
        "\n",
        "  def num_places(self):\n",
        "    return len(set([scene.place for scene in self.scenes]))\n",
        "\n",
        "  def num_scenes(self) -> int:\n",
        "    return len(self.scenes)\n",
        "\n",
        "\n",
        "class Place(NamedTuple):\n",
        "  \"\"\"Place class.\"\"\"\n",
        "\n",
        "  # Place name.\n",
        "  name: str\n",
        "\n",
        "  # Place description.\n",
        "  description: str\n",
        "\n",
        "  @classmethod\n",
        "  def format_name(cls, name: str):\n",
        "    if name.find('.') == -1:\n",
        "      name = name + '.'\n",
        "    return name\n",
        "\n",
        "  @classmethod\n",
        "  def from_string(cls, place_name: str, place_text: str):\n",
        "    place_text += END_MARKER\n",
        "    description = extract_elements(place_text, DESCRIPTION_ELEMENT, END_MARKER)\n",
        "    return cls(place_name, description[0])\n",
        "\n",
        "  @classmethod\n",
        "  def format_prefix(cls, name):\n",
        "    s = PLACE_ELEMENT + name + '\\n' + DESCRIPTION_ELEMENT\n",
        "    return s\n",
        "\n",
        "  def to_string(self):\n",
        "    s = self.format_prefix(self.name) + self.description + '\\n\\n'\n",
        "    return s\n",
        "\n",
        "\n",
        "def get_place_description(place: Place):\n",
        "  return place.description\n",
        "\n",
        "\n",
        "class Story(NamedTuple):\n",
        "  \"\"\"Story class.\"\"\"\n",
        "\n",
        "  # A storyline is a single sentence summary of the whole plot.\n",
        "  storyline: str\n",
        "\n",
        "  # A title for the story.\n",
        "  title: str\n",
        "\n",
        "  # Map from character names to full descriptions.\n",
        "  character_descriptions: Dict[str, str]\n",
        "\n",
        "  # Map from place names to full descriptions.\n",
        "  place_descriptions: Dict[str, Place]\n",
        "\n",
        "  # List of scenes.\n",
        "  scenes: Scenes\n",
        "\n",
        "  # List of dialogs, one for each scene.\n",
        "  dialogs: List[str]\n",
        "\n",
        "\n",
        "def extract_elements(text: str, begin: str, end: str) -> List[str]:\n",
        "  \"\"\"Extracts elements from a text string given string and ending markers.\"\"\"\n",
        "\n",
        "  results = []\n",
        "  start = 0\n",
        "  while True:\n",
        "    start = text.find(begin, start)\n",
        "    if start == -1:\n",
        "      return results\n",
        "    finish = text.find(end, start)\n",
        "    if finish == -1:\n",
        "      return results\n",
        "    results.append(text[start + len(begin):finish].strip())\n",
        "    start = finish + len(end)\n",
        "\n",
        "\n",
        "def strip_remove_end(text: str) -> str:\n",
        "  text = text.strip()\n",
        "  end_marker_stripped = END_MARKER.strip()\n",
        "  if text.endswith(end_marker_stripped):\n",
        "    text = text[:-len(end_marker_stripped)]\n",
        "  return text\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Rendering of generated stories\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def render_story(story: Story) -> str:\n",
        "  \"\"\"Render the story in fountain format.\"\"\"\n",
        "\n",
        "  lines = []\n",
        "  lines.append(f'Title: {story.title}')\n",
        "  lines.append('Author: Co-written by ________ and Dramatron')\n",
        "  lines.append(\n",
        "      'Dramatron was developed by Piotr Mirowski and Kory W. Mathewson, '\n",
        "      'with additional contributions by Juliette Love and Jaylen Pittman, '\n",
        "      'and is based on a prototype by Richard Evans.')\n",
        "  lines.append('Dramatron relies on user-provided language models.')\n",
        "  lines.append('')\n",
        "  lines.append('====')\n",
        "  lines.append('')\n",
        "\n",
        "  lines.append(f'The script is based on the storyline:\\n{story.storyline}')\n",
        "  lines.append('')\n",
        "  if story.character_descriptions is not None:\n",
        "    for name, description in story.character_descriptions.items():\n",
        "      lines.append(f'{name}: {description}')\n",
        "      lines.append('')\n",
        "\n",
        "  # For each scene, render scene information.\n",
        "  if story.scenes is not None:\n",
        "    scenes = story.scenes.scenes\n",
        "    for i, scene in enumerate(scenes):\n",
        "      lines.append(f'Scene {i+1}')\n",
        "      lines.append(f'{PLACE_ELEMENT}{scene.place}')\n",
        "      lines.append(f'{PLOT_ELEMENT}{scene.plot_element}')\n",
        "      lines.append(f'{BEAT_ELEMENT}{scene.beat}')\n",
        "      lines.append('')\n",
        "  else:\n",
        "    scenes = []\n",
        "\n",
        "  lines.append('====')\n",
        "  lines.append('')\n",
        "\n",
        "  # For each scene, render the scene's place description, characters and dialog.\n",
        "  for i, scene in enumerate(scenes):\n",
        "\n",
        "    # Output the places and place descriptions.\n",
        "    lines.append(f'INT/EXT. {scene.place} - Scene {i+1}')\n",
        "    place_descriptions = story.place_descriptions\n",
        "    if (not place_appears_earlier(scene.place, story, i) and\n",
        "        place_descriptions is not None and scene.place in place_descriptions):\n",
        "      lines.append('')\n",
        "      lines.append(get_place_description(place_descriptions[scene.place]))\n",
        "\n",
        "    # Output the characters and descriptions.\n",
        "    lines.append('')\n",
        "    for c in story.character_descriptions.keys():\n",
        "      if c in scene.beat and not character_appears_earlier(c, story, i):\n",
        "        lines.append(story.character_descriptions[c])\n",
        "\n",
        "    # Output the dialog.\n",
        "    if story.dialogs is not None and len(story.dialogs) > i:\n",
        "      lines.append('')\n",
        "      lines_dialog = strip_remove_end(str(story.dialogs[i]))\n",
        "      lines.append(lines_dialog)\n",
        "      lines.append('')\n",
        "      lines.append('')\n",
        "\n",
        "  return '\\n'.join(lines)\n",
        "\n",
        "\n",
        "def place_appears_earlier(place: str, story: Story, index: int) -> bool:\n",
        "  \"\"\"Return True if the place appears earlier in the story.\"\"\"\n",
        "\n",
        "  for i in range(index):\n",
        "    scene = story.scenes.scenes[i]\n",
        "    if scene.place == place:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def character_appears_earlier(character: str, story: Story, index: int) -> bool:\n",
        "  \"\"\"Return True if the character appears earlier in the story.\"\"\"\n",
        "\n",
        "  for i in range(index):\n",
        "    scene = story.scenes.scenes[i]\n",
        "    if character in scene.beat:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def render_prompts(prompts):\n",
        "  \"\"\"Render the prompts.\"\"\"\n",
        "\n",
        "  def _format_prompt(prompt, name):\n",
        "    prompt_str = '=' * 80 + '\\n'\n",
        "    prompt_str += 'PROMPT (' + name + ')\\n'\n",
        "    prompt_str += '=' * 80 + '\\n\\n'\n",
        "    prompt_str += str(prompt) + '\\n\\n'\n",
        "    return prompt_str\n",
        "\n",
        "  prompts_str = _format_prompt(prompts['title'], 'title')\n",
        "  prompts_str += _format_prompt(prompts['characters'], 'characters')\n",
        "  prompts_str += _format_prompt(prompts['scenes'], 'scenes')\n",
        "  places = prompts['places']\n",
        "  if places is not None:\n",
        "    for k, prompt in enumerate(places):\n",
        "      prompts_str += _format_prompt(prompt, 'place ' + str(k + 1))\n",
        "  dialogs = prompts['dialogs']\n",
        "  if dialogs is not None:\n",
        "    for k, prompt in enumerate(dialogs):\n",
        "      prompts_str += _format_prompt(prompt, 'dialog ' + str(k + 1))\n",
        "  return prompts_str\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Language API definition\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "_MAX_RETRIES = 10\n",
        "_TIMEOUT = 120.0\n",
        "\n",
        "\n",
        "class LanguageResponse(NamedTuple):\n",
        "  prompt: str\n",
        "  prompt_length: int\n",
        "  text: str\n",
        "  text_length: int\n",
        "\n",
        "\n",
        "class LanguageAPI:\n",
        "  \"\"\"Language model wrapper.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               sample_length: int,\n",
        "               model: Optional[str] = None,\n",
        "               model_param: Optional[str] = None,\n",
        "               config_sampling: Optional[dict] = None,\n",
        "               seed: Optional[int] = None,\n",
        "               max_retries: int = _MAX_RETRIES,\n",
        "               timeout: float = _TIMEOUT):\n",
        "    \"\"\"Initializer.\n",
        "\n",
        "    Args:\n",
        "      sample_length: Length of text to sample from model.\n",
        "      model: The model name to correct to. An error will be raised if it does\n",
        "        not exist.\n",
        "      model_param: Model parameter.\n",
        "      config_sampling: Sampleing parameters.\n",
        "      seed: Random seed for sampling.\n",
        "      max_retries: Maximum number of retries for the remote API.\n",
        "      timeout: Maximum waiting timeout\n",
        "    \"\"\"\n",
        "    self._sample_length = sample_length\n",
        "    self._model = model\n",
        "    self._model_param = model_param\n",
        "    self._config_sampling = config_sampling\n",
        "    self._seed = seed\n",
        "    self._max_retries = max_retries\n",
        "    self._timeout = timeout\n",
        "\n",
        "  @property\n",
        "  def default_sample_length(self):\n",
        "    return self._sample_length\n",
        "\n",
        "  @property\n",
        "  def model(self):\n",
        "    return self._model\n",
        "\n",
        "  @property\n",
        "  def model_param(self):\n",
        "    return self._model_param\n",
        "\n",
        "  @property\n",
        "  def model_metadata(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def seed(self):\n",
        "    return self._seed\n",
        "\n",
        "  @property\n",
        "  def config_sampling(self):\n",
        "    return self._config_sampling\n",
        "\n",
        "  def sample(self,\n",
        "             prompt: str,\n",
        "             sample_length: Optional[int] = None,\n",
        "             seed: Optional[int] = None,\n",
        "             num_samples: int = 1):\n",
        "    \"\"\"Sample model with provided prompt, optional sample_length and seed.\"\"\"\n",
        "    raise NotImplementedError('sample method not implemented in generic class')\n",
        "\n",
        "\n",
        "class FilterAPI:\n",
        "  \"\"\"Filter model wrapper.\"\"\"\n",
        "\n",
        "  def validate(self, text: str):\n",
        "    raise NotImplementedError('validate not implemented in generic class')\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Dramatron Generator\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def generate_text(generation_prompt: str,\n",
        "                  client: LanguageAPI,\n",
        "                  filter: Optional[FilterAPI] = None,\n",
        "                  sample_length: Optional[int] = None,\n",
        "                  max_paragraph_length: int = MAX_PARAGRAPH_LENGTH,\n",
        "                  seed: Optional[int] = None,\n",
        "                  num_samples: int = 1,\n",
        "                  max_num_repetitions: Optional[int] = None) -> str:\n",
        "  \"\"\"Generate text using the generation prompt.\"\"\"\n",
        "\n",
        "  # To prevent lengthy generation loops, we cap the number of calls to the API.\n",
        "  if sample_length is None:\n",
        "    sample_length = client.default_sample_length\n",
        "  max_num_calls = int(max_paragraph_length / sample_length) + 1\n",
        "  num_calls = 0\n",
        "\n",
        "  result = ''\n",
        "  while True:\n",
        "    prompt = generation_prompt + result\n",
        "    success, current_seed = False, seed\n",
        "    while success is False:\n",
        "      t0 = time.time()\n",
        "      responses = client.sample(\n",
        "          prompt=prompt,\n",
        "          sample_length=sample_length,\n",
        "          seed=current_seed,\n",
        "          num_samples=num_samples)\n",
        "      t1 = time.time()\n",
        "      # Get the first result from the list of responses\n",
        "      response = responses[0]\n",
        "      if filter is not None and not filter.validate(response.text):\n",
        "        return 'Content was filtered out.' + END_MARKER\n",
        "      if max_num_repetitions:\n",
        "        success = not detect_loop(\n",
        "            response.text, max_num_repetitions=max_num_repetitions)\n",
        "        if not success:\n",
        "          current_seed += 1\n",
        "          if current_seed > (seed + MAX_NUM_ATTEMPTS_GET_OUT_OF_LOOP):\n",
        "            success = True\n",
        "          else:\n",
        "            continue\n",
        "      else:\n",
        "        success = True\n",
        "\n",
        "    result = result + response.text\n",
        "    num_calls += 1\n",
        "\n",
        "    # Attempt to find the END_MARKER\n",
        "    index = result.find(END_MARKER)\n",
        "    if index != -1:\n",
        "      return result[:index] + END_MARKER\n",
        "\n",
        "    # Attempt to find the start of a new example\n",
        "    index = result.find('Example ')\n",
        "    if index != -1:\n",
        "      return result[:index] + END_MARKER\n",
        "\n",
        "    if max_paragraph_length is not None and len(result) > max_paragraph_length:\n",
        "      return result + END_MARKER\n",
        "    if num_calls >= max_num_calls:\n",
        "      return result + END_MARKER\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "def generate_text_no_loop(generation_prompt: str,\n",
        "                          client: LanguageAPI,\n",
        "                          filter: Optional[FilterAPI] = None,\n",
        "                          sample_length: Optional[int] = None,\n",
        "                          max_paragraph_length: int = MAX_PARAGRAPH_LENGTH,\n",
        "                          seed: Optional[int] = None,\n",
        "                          num_samples: int = 1) -> str:\n",
        "  \"\"\"Generate text using the generation prompt, without any loop.\"\"\"\n",
        "  return generate_text(\n",
        "      generation_prompt=generation_prompt,\n",
        "      client=client,\n",
        "      filter=filter,\n",
        "      sample_length=sample_length,\n",
        "      max_paragraph_length=sample_length,\n",
        "      seed=seed,\n",
        "      max_num_repetitions=None,\n",
        "      num_samples=num_samples)\n",
        "\n",
        "\n",
        "def generate_title(storyline: str,\n",
        "                   prefixes: Dict[str, str],\n",
        "                   client: LanguageAPI,\n",
        "                   filter: Optional[FilterAPI] = None,\n",
        "                   seed: Optional[int] = None,\n",
        "                   num_samples: int = 1):\n",
        "  \"\"\"Generate a title given a storyline, and client.\"\"\"\n",
        "\n",
        "  # Combine the prompt and storyline as a helpful generation prefix\n",
        "  titles_prefix = prefixes['TITLES_PROMPT'] + storyline + ' ' + TITLE_ELEMENT\n",
        "  title_text = generate_text_no_loop(\n",
        "      generation_prompt=titles_prefix,\n",
        "      client=client,\n",
        "      filter=filter,\n",
        "      sample_length=SAMPLE_LENGTH_TITLE,\n",
        "      seed=seed,\n",
        "      num_samples=num_samples)\n",
        "  title = Title.from_string(TITLE_ELEMENT + title_text)\n",
        "  return (title, titles_prefix)\n",
        "\n",
        "\n",
        "def generate_characters(\n",
        "    storyline: str,\n",
        "    prefixes: Dict[str, str],\n",
        "    client: LanguageAPI,\n",
        "    filter: Optional[FilterAPI] = None,\n",
        "    seed: Optional[int] = None,\n",
        "    max_paragraph_length: int = (MAX_PARAGRAPH_LENGTH_CHARACTERS),\n",
        "    num_samples: int = 1):\n",
        "  \"\"\"Generate characters given a storyline, prompt, and client.\"\"\"\n",
        "\n",
        "  # Combine the prompt and storyline as a helpful generation prefix\n",
        "  characters_prefix = prefixes['CHARACTERS_PROMPT'] + storyline\n",
        "  characters_text = generate_text(\n",
        "      generation_prompt=characters_prefix,\n",
        "      client=client,\n",
        "      filter=filter,\n",
        "      seed=seed,\n",
        "      max_paragraph_length=max_paragraph_length,\n",
        "      num_samples=num_samples)\n",
        "  characters = Characters.from_string(characters_text)\n",
        "\n",
        "  return (characters, characters_prefix)\n",
        "\n",
        "\n",
        "def generate_scenes(storyline: str,\n",
        "                    character_descriptions: Dict[str, str],\n",
        "                    prefixes: Dict[str, str],\n",
        "                    client: LanguageAPI,\n",
        "                    filter: Optional[FilterAPI] = None,\n",
        "                    seed: Optional[int] = None,\n",
        "                    max_paragraph_length: int = (MAX_PARAGRAPH_LENGTH_SCENES),\n",
        "                    num_samples: int = 1):\n",
        "  \"\"\"Generate scenes given storyline, prompt, main characters, and client.\"\"\"\n",
        "\n",
        "  scenes_prefix = prefixes['SCENE_PROMPT'] + storyline + '\\n'\n",
        "  for name in character_descriptions:\n",
        "    scenes_prefix += character_descriptions[name] + '\\n'\n",
        "  scenes_prefix += '\\n' + SCENES_MARKER\n",
        "  scenes_text = generate_text(\n",
        "      generation_prompt=scenes_prefix,\n",
        "      client=client,\n",
        "      filter=filter,\n",
        "      seed=seed,\n",
        "      max_paragraph_length=max_paragraph_length,\n",
        "      num_samples=num_samples)\n",
        "  scenes = Scenes.from_string(scenes_text)\n",
        "\n",
        "  return (scenes, scenes_prefix)\n",
        "\n",
        "\n",
        "def generate_place_descriptions(storyline: str,\n",
        "                                scenes: Scenes,\n",
        "                                prefixes: Dict[str, str],\n",
        "                                client: LanguageAPI,\n",
        "                                filter: Optional[FilterAPI] = None,\n",
        "                                seed: Optional[int] = None,\n",
        "                                num_samples: int = 1):\n",
        "  \"\"\"Generate a place description given a scene object and a client.\"\"\"\n",
        "\n",
        "  place_descriptions = {}\n",
        "\n",
        "  # Get unique place names from the scenes.\n",
        "  unique_place_names = set([scene.place for scene in scenes.scenes])\n",
        "\n",
        "  # Build a unique place prefix prompt.\n",
        "  place_prefix = prefixes['SETTING_PROMPT'] + storyline + '\\n'\n",
        "\n",
        "  # Build a list of place descriptions for each place\n",
        "  place_prefixes = []\n",
        "  for place_name in unique_place_names:\n",
        "    place_suffix = Place.format_prefix(place_name)\n",
        "    place_text = generate_text(\n",
        "        generation_prompt=place_prefix + place_suffix,\n",
        "        client=client,\n",
        "        filter=filter,\n",
        "        sample_length=SAMPLE_LENGTH_PLACE,\n",
        "        seed=seed,\n",
        "        num_samples=num_samples)\n",
        "    place_text = place_suffix + place_text\n",
        "    place_descriptions[place_name] = Place.from_string(place_name, place_text)\n",
        "    place_prefixes.append(place_prefix + place_suffix)\n",
        "\n",
        "  return (place_descriptions, place_prefixes)\n",
        "\n",
        "\n",
        "def prefix_summary(storyline: str,\n",
        "                   scenes: List[Scene],\n",
        "                   concatenate_scenes_in_summary: bool = False) -> str:\n",
        "  \"\"\"Assemble the summary part of the dialog prefix.\"\"\"\n",
        "\n",
        "  summary = SUMMARY_ELEMENT + storyline + '\\n'\n",
        "  if len(scenes) > 1:\n",
        "    summary += PREVIOUS_ELEMENT + scenes[len(scenes) - 2].beat + '\\n'\n",
        "  return summary\n",
        "\n",
        "\n",
        "def detect_loop(text: str, max_num_repetitions: int = MAX_NUM_REPETITIONS):\n",
        "  \"\"\"Detect loops in generated text.\"\"\"\n",
        "\n",
        "  blocks = text.split('\\n\\n')\n",
        "  num_unique_blocks = collections.Counter(blocks)\n",
        "  for block in blocks:\n",
        "    num_repetitions = num_unique_blocks[block]\n",
        "    if num_repetitions > max_num_repetitions:\n",
        "      print(f'Detected {num_repetitions} repetitions of block:\\n{block}')\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def generate_dialog(storyline: str,\n",
        "                    scenes: List[Scene],\n",
        "                    character_descriptions: Dict[str, str],\n",
        "                    place_descriptions: Dict[str, Place],\n",
        "                    prefixes: Dict[str, str],\n",
        "                    max_paragraph_length: int,\n",
        "                    client: LanguageAPI,\n",
        "                    filter: Optional[FilterAPI] = None,\n",
        "                    max_num_repetitions: Optional[int] = None,\n",
        "                    seed: Optional[int] = None,\n",
        "                    num_samples: int = 1):\n",
        "  \"\"\"Generate dialog given a scene object and a client.\"\"\"\n",
        "\n",
        "  scene = scenes[-1]\n",
        "\n",
        "  place_t = PLACE_ELEMENT + scene.place + '\\n'\n",
        "  if scene.place in place_descriptions:\n",
        "    place_description = place_descriptions[scene.place]\n",
        "    if place_description:\n",
        "      place_t += DESCRIPTION_ELEMENT + place_description.description\n",
        "      place_t += '\\n'\n",
        "\n",
        "  # Build the characters information for the scene\n",
        "  characters_t = ''\n",
        "  if character_descriptions:\n",
        "    characters_t += CHARACTERS_ELEMENT\n",
        "    for name in character_descriptions:\n",
        "      if name in scene.beat:\n",
        "        characters_t += character_descriptions[name] + '\\n'\n",
        "\n",
        "  plot_element_t = PLOT_ELEMENT + scene.plot_element + '\\n'\n",
        "\n",
        "  summary_t = prefix_summary(\n",
        "      storyline, scenes, concatenate_scenes_in_summary=False)\n",
        "\n",
        "  beat_t = BEAT_ELEMENT + scene.beat + '\\n'\n",
        "\n",
        "  dialog_prefix = (\n",
        "      prefixes['DIALOG_PROMPT'] + place_t + characters_t + plot_element_t +\n",
        "      summary_t + beat_t)\n",
        "  dialog_prefix += '\\n' + DIALOG_MARKER + '\\n'\n",
        "\n",
        "  dialog = generate_text(\n",
        "      generation_prompt=dialog_prefix,\n",
        "      client=client,\n",
        "      filter=filter,\n",
        "      seed=seed,\n",
        "      max_paragraph_length=max_paragraph_length,\n",
        "      max_num_repetitions=max_num_repetitions,\n",
        "      num_samples=num_samples)\n",
        "\n",
        "  return (dialog, dialog_prefix)\n",
        "\n",
        "\n",
        "def diff_prompt_change_str(prompt_before: str, prompt_after: str) -> str:\n",
        "  \"\"\"Return a text diff on prompt sets `prompt_before` and `prompt_after`.\"\"\"\n",
        "\n",
        "  # For the current element, compare prompts line by line.\n",
        "  res = difflib.unified_diff(\n",
        "      prompt_before.split('\\n'), prompt_after.split('\\n'))\n",
        "  diff = ''\n",
        "  for line in res:\n",
        "    line = line.strip()\n",
        "    if line != '---' and line != '+++' and not line.startswith('@@'):\n",
        "      if len(line) > 1 and (line.startswith('+') or line.startswith('-')):\n",
        "        diff += line + '\\n'\n",
        "  if diff.endswith('\\n'):\n",
        "    diff = diff[:-1]\n",
        "  return diff\n",
        "\n",
        "\n",
        "def diff_prompt_change_list(prompt_before: List[str],\n",
        "                            prompt_after: List[str]) -> str:\n",
        "  \"\"\"Return a text diff on prompt sets `prompt_before` and `prompt_after`.\"\"\"\n",
        "\n",
        "  # Handle deletions and insertions.\n",
        "  len_before = len(prompt_before)\n",
        "  len_after = len(prompt_after)\n",
        "  if len_before > len_after:\n",
        "    return 'Deleted element'\n",
        "  if len_before < len_after:\n",
        "    return 'Added new element'\n",
        "\n",
        "  diffs = [\n",
        "      diff_prompt_change_str(a, b)\n",
        "      for (a, b) in zip(prompt_before, prompt_after)\n",
        "  ]\n",
        "  return '\\n'.join([diff for diff in diffs if len(diff) > 0])\n",
        "\n",
        "\n",
        "def diff_prompt_change_scenes(prompt_before: List[Scene],\n",
        "                              prompt_after: List[Scene]) -> str:\n",
        "  \"\"\"Return a text diff on prompt sets `prompt_before` and `prompt_after`.\"\"\"\n",
        "\n",
        "  # Handle deletions and insertions.\n",
        "  len_before = len(prompt_before)\n",
        "  len_after = len(prompt_after)\n",
        "  if len_before > len_after:\n",
        "    return 'Deleted element'\n",
        "  if len_before < len_after:\n",
        "    return 'Added new element'\n",
        "\n",
        "  diffs = [\n",
        "      diff_prompt_change_list([a.place, a.plot_element, a.beat],\n",
        "                              [b.place, b.plot_element, b.beat])\n",
        "      for (a, b) in zip(prompt_before, prompt_after)\n",
        "  ]\n",
        "  return '\\n'.join([diff for diff in diffs if len(diff) > 0])\n",
        "\n",
        "\n",
        "def diff_prompt_change_dict(prompt_before: Dict[str, str],\n",
        "                            prompt_after: Dict[str, str]) -> str:\n",
        "  \"\"\"Return a text diff on prompt sets `prompt_before` and `prompt_after`.\"\"\"\n",
        "\n",
        "  # Loop over the keys in the prompts to compare them one by one.\n",
        "  keys_before = sorted(prompt_before.keys())\n",
        "  keys_after = sorted(prompt_after.keys())\n",
        "  diffs = [\n",
        "      diff_prompt_change_str(a, b) for (a, b) in zip(keys_before, keys_after)\n",
        "  ]\n",
        "  diff_keys = '\\n'.join([diff for diff in diffs if len(diff) > 0])\n",
        "  # Loop over the values in the prompts to compare them one by one.\n",
        "  values_before = sorted(prompt_before.values())\n",
        "  values_after = sorted(prompt_after.values())\n",
        "  diffs = [\n",
        "      diff_prompt_change_str(a, b)\n",
        "      for (a, b) in zip(values_before, values_after)\n",
        "  ]\n",
        "  diff_values = '\\n'.join([diff for diff in diffs if len(diff) > 0])\n",
        "  return diff_keys + diff_values\n",
        "\n",
        "\n",
        "class StoryGenerator:\n",
        "  \"\"\"Generate a story from the provided storyline, using the client provided.\"\"\"\n",
        "\n",
        "  level_names = ('storyline', 'title', 'characters', 'scenes', 'places',\n",
        "                 'dialogs')\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      storyline: str,\n",
        "      prefixes: Dict[str, str],\n",
        "      max_paragraph_length: int = 1024,\n",
        "      max_paragraph_length_characters: int = (MAX_PARAGRAPH_LENGTH_CHARACTERS),\n",
        "      max_paragraph_length_scenes: int = (MAX_PARAGRAPH_LENGTH_SCENES),\n",
        "      num_samples: int = 1,\n",
        "      client: Optional[LanguageAPI] = None,\n",
        "      filter: Optional[FilterAPI] = None):\n",
        "    self._prefixes = prefixes\n",
        "    self._max_paragraph_length = max_paragraph_length\n",
        "    self._max_paragraph_length_characters = max_paragraph_length_characters\n",
        "    self._max_paragraph_length_scenes = max_paragraph_length_scenes\n",
        "    self._num_samples = num_samples\n",
        "    self._client = client\n",
        "    self._filter = filter\n",
        "\n",
        "    # Prompts and outputs of the hierarchical generator are organised in levels.\n",
        "    self.prompts = {\n",
        "        'title': '',\n",
        "        'characters': '',\n",
        "        'scenes': '',\n",
        "        'places': {\n",
        "            '': ''\n",
        "        },\n",
        "        'dialogs': ['']\n",
        "    }\n",
        "    self._title = Title('')\n",
        "    self._characters = Characters({'': ''})\n",
        "    self._scenes = Scenes([Scene('', '', '')])\n",
        "    self._places = {'': Place('', '')}\n",
        "    self._dialogs = ['']\n",
        "\n",
        "    # History of interventions.\n",
        "    self.interventions = {}\n",
        "    self._set_storyline(storyline)\n",
        "\n",
        "  def _set_storyline(self, storyline: str):\n",
        "    \"\"\"Set storyline and initialise the outputs of the generator.\"\"\"\n",
        "    self._level = 0\n",
        "\n",
        "    # Add period to the end of the storyline, unless there is already one there.\n",
        "    if storyline.find('.') == -1:\n",
        "      storyline = storyline + '.'\n",
        "    self._storyline = storyline\n",
        "\n",
        "    # Keep track of each storyline intervention.\n",
        "    timestamp = time.time()\n",
        "    self.interventions[timestamp] = 'STORYLINE\\n' + storyline\n",
        "\n",
        "  @property\n",
        "  def seed(self):\n",
        "    return self._client.seed\n",
        "\n",
        "  @property\n",
        "  def title(self) -> Title:\n",
        "    \"\"\"Return the title.\"\"\"\n",
        "    return self._title\n",
        "\n",
        "  @property\n",
        "  def characters(self) -> Characters:\n",
        "    \"\"\"Return the characters.\"\"\"\n",
        "    return self._characters\n",
        "\n",
        "  @property\n",
        "  def scenes(self) -> Scenes:\n",
        "    \"\"\"Return the title.\"\"\"\n",
        "    return self._scenes\n",
        "\n",
        "  @property\n",
        "  def places(self) -> Dict[str, Place]:\n",
        "    \"\"\"Return the places.\"\"\"\n",
        "    return self._places\n",
        "\n",
        "  @property\n",
        "  def dialogs(self) -> List[str]:\n",
        "    \"\"\"Return the dialogs.\"\"\"\n",
        "    return self._dialogs\n",
        "\n",
        "  def title_str(self) -> str:\n",
        "    \"\"\"Return the title as a string.\"\"\"\n",
        "    return self._title.title\n",
        "\n",
        "  def num_scenes(self) -> int:\n",
        "    \"\"\"Return the number of scenes.\"\"\"\n",
        "    return self._scenes.num_scenes()\n",
        "\n",
        "  def step(self,\n",
        "           level: Optional[int] = None,\n",
        "           seed: Optional[int] = None,\n",
        "           idx: Optional[int] = None) -> bool:\n",
        "    \"\"\"Step down a level in the hierarchical generation of a story.\"\"\"\n",
        "\n",
        "    # Move to the next level of hierarchical generation.\n",
        "    if level is None:\n",
        "      level = self._level\n",
        "    if level < 0 or level >= len(self.level_names):\n",
        "      raise ValueError('Invalid level encountered on step.')\n",
        "    level += 1\n",
        "    self._level = level\n",
        "\n",
        "    # Keep track of each step intervention.\n",
        "    timestamp = time.time()\n",
        "    self.interventions[timestamp] = 'STEP ' + str(level) + '\\n'\n",
        "\n",
        "    if level == 1:\n",
        "      # Step 1: Generate title given a storyline.\n",
        "      (title, titles_prefix) = generate_title(\n",
        "          storyline=self._storyline,\n",
        "          prefixes=self._prefixes,\n",
        "          client=self._client,\n",
        "          filter=self._filter,\n",
        "          num_samples=self._num_samples,\n",
        "          seed=seed)\n",
        "      self._title = title\n",
        "      self.prompts['title'] = titles_prefix\n",
        "      self.interventions[timestamp] += title.to_string()\n",
        "      success = len(title.title) > 0\n",
        "      return success\n",
        "\n",
        "    if level == 2:\n",
        "      # Step 2: Generate characters given a storyline.\n",
        "      (characters, character_prompts) = generate_characters(\n",
        "          storyline=self._storyline,\n",
        "          prefixes=self._prefixes,\n",
        "          client=self._client,\n",
        "          filter=self._filter,\n",
        "          num_samples=self._num_samples,\n",
        "          max_paragraph_length=self._max_paragraph_length_characters,\n",
        "          seed=seed)\n",
        "      self._characters = characters\n",
        "      self.prompts['characters'] = character_prompts\n",
        "      self.interventions[timestamp] += characters.to_string()\n",
        "      success = len(characters.character_descriptions) > 0\n",
        "      return success\n",
        "\n",
        "    if level == 3:\n",
        "      # Step 3: Generate sequence of scenes given a storyline and characters.\n",
        "      characters = self._characters\n",
        "      (scenes, scene_prompts) = generate_scenes(\n",
        "          storyline=self._storyline,\n",
        "          character_descriptions=get_character_descriptions(characters),\n",
        "          prefixes=self._prefixes,\n",
        "          client=self._client,\n",
        "          filter=self._filter,\n",
        "          num_samples=self._num_samples,\n",
        "          max_paragraph_length=self._max_paragraph_length_scenes,\n",
        "          seed=seed)\n",
        "      self._scenes = scenes\n",
        "      self.prompts['scenes'] = scene_prompts\n",
        "      self.interventions[timestamp] += scenes.to_string()\n",
        "      success = len(scenes.scenes) > 0\n",
        "      return success\n",
        "\n",
        "    if level == 4:\n",
        "      # Step 4: For each scene, generate place descriptions given place name.\n",
        "      scenes = self._scenes\n",
        "      (place_descriptions, place_prompts) = generate_place_descriptions(\n",
        "          storyline=self._storyline,\n",
        "          scenes=scenes,\n",
        "          prefixes=self._prefixes,\n",
        "          client=self._client,\n",
        "          filter=self._filter,\n",
        "          num_samples=self._num_samples,\n",
        "          seed=seed)\n",
        "      self._places = place_descriptions\n",
        "      self.prompts['places'] = place_prompts\n",
        "      for place_name in place_descriptions:\n",
        "        place = place_descriptions[place_name]\n",
        "        if place:\n",
        "          self.interventions[timestamp] += place.to_string()\n",
        "      num_places = scenes.num_places()\n",
        "      success = (len(place_descriptions) == num_places) and num_places > 0\n",
        "      return success\n",
        "\n",
        "    if level == 5:\n",
        "      # Step 5: For each scene, generate dialog from scene information.\n",
        "      title = self._title\n",
        "      characters = self._characters\n",
        "      scenes = self._scenes\n",
        "      place_descriptions = self._places\n",
        "      if idx is None:\n",
        "        (dialogs, dialog_prompts) = zip(*[\n",
        "            generate_dialog(\n",
        "                storyline=self._storyline,\n",
        "                scenes=scenes.scenes[:(k + 1)],\n",
        "                character_descriptions=(characters.character_descriptions),\n",
        "                place_descriptions=place_descriptions,\n",
        "                prefixes=self._prefixes,\n",
        "                max_paragraph_length=self._max_paragraph_length,\n",
        "                max_num_repetitions=MAX_NUM_REPETITIONS,\n",
        "                client=self._client,\n",
        "                filter=self._filter,\n",
        "                num_samples=self._num_samples,\n",
        "                seed=seed) for k in range(len(scenes.scenes))\n",
        "        ])\n",
        "      else:\n",
        "        num_scenes = self._scenes.num_scenes()\n",
        "        while len(self._dialogs) < num_scenes:\n",
        "          self._dialogs.append('')\n",
        "        while len(self.prompts['dialogs']) < num_scenes:\n",
        "          self.prompts['dialogs'].append('')\n",
        "        if idx >= num_scenes or idx < 0:\n",
        "          raise ValueError('Invalid scene index.')\n",
        "        dialogs = self._dialogs\n",
        "        dialog_prompts = self.prompts['dialogs']\n",
        "        dialogs[idx], dialog_prompts[idx] = generate_dialog(\n",
        "            storyline=self._storyline,\n",
        "            scenes=scenes.scenes[:(idx + 1)],\n",
        "            character_descriptions=(characters.character_descriptions),\n",
        "            place_descriptions=place_descriptions,\n",
        "            prefixes=self._prefixes,\n",
        "            max_paragraph_length=self._max_paragraph_length,\n",
        "            max_num_repetitions=MAX_NUM_REPETITIONS,\n",
        "            client=self._client,\n",
        "            filter=self._filter,\n",
        "            num_samples=self._num_samples,\n",
        "            seed=seed)\n",
        "      self._dialogs = dialogs\n",
        "      self.prompts['dialogs'] = dialog_prompts\n",
        "      for dialog in dialogs:\n",
        "        self.interventions[timestamp] += str(dialog)\n",
        "      return True\n",
        "\n",
        "  def get_story(self):\n",
        "    if self._characters is not None:\n",
        "      character_descriptions = get_character_descriptions(self._characters)\n",
        "    else:\n",
        "      character_descriptions = None\n",
        "    return Story(\n",
        "        storyline=self._storyline,\n",
        "        title=self._title.title,\n",
        "        character_descriptions=character_descriptions,\n",
        "        place_descriptions=self._places,\n",
        "        scenes=self._scenes,\n",
        "        dialogs=self._dialogs)\n",
        "\n",
        "  def rewrite(self, text, level=0, entity=None):\n",
        "    if level < 0 or level >= len(self.level_names):\n",
        "      raise ValueError('Invalid level encountered on step.')\n",
        "    prompt_diff = None\n",
        "\n",
        "    if level == 0:\n",
        "      # Step 0: Rewrite the storyline and begin new story.\n",
        "      prompt_diff = diff_prompt_change_str(self._storyline, text)\n",
        "      self._set_storyline(text)\n",
        "\n",
        "    if level == 1:\n",
        "      # Step 1: Rewrite the title.\n",
        "      title = Title.from_string(text)\n",
        "      prompt_diff = diff_prompt_change_str(self._title.title, title.title)\n",
        "      self._title = title\n",
        "\n",
        "    if level == 2:\n",
        "      # Step 2: Rewrite the characters.\n",
        "      characters = Characters.from_string(text)\n",
        "      prompt_diff = diff_prompt_change_dict(\n",
        "          self._characters.character_descriptions,\n",
        "          characters.character_descriptions)\n",
        "      self._characters = characters\n",
        "\n",
        "    if level == 3:\n",
        "      # Step 3: Rewrite the sequence of scenes.\n",
        "      scenes = Scenes.from_string(text)\n",
        "      prompt_diff = diff_prompt_change_scenes(self._scenes.scenes,\n",
        "                                              scenes.scenes)\n",
        "      self._scenes = scenes\n",
        "\n",
        "    if level == 4:\n",
        "      # Step 4: For a given place, rewrite its place description.\n",
        "      place_descriptions = self._places\n",
        "      if entity in place_descriptions:\n",
        "        place_prefix = Place.format_prefix(entity)\n",
        "        text = place_prefix + text\n",
        "        place = Place.from_string(entity, text)\n",
        "        prompt_diff = diff_prompt_change_str(self._places[entity].name,\n",
        "                                             place.name)\n",
        "        prompt_diff += '\\n' + diff_prompt_change_str(\n",
        "            self._places[entity].description, place.description)\n",
        "\n",
        "        self._places[entity] = place\n",
        "\n",
        "    if level == 5:\n",
        "      # Step 5: Rewrite the dialog of a given scene.\n",
        "      dialogs = self._dialogs\n",
        "      num_scenes = len(self._scenes.scenes)\n",
        "      if entity >= 0 and entity < num_scenes:\n",
        "        prompt_diff = diff_prompt_change_str(self._dialogs[entity], text)\n",
        "        self._dialogs[entity] = text\n",
        "\n",
        "    # Keep track of each rewrite intervention.\n",
        "    if prompt_diff is not None and len(prompt_diff) > 0:\n",
        "      timestamp = time.time()\n",
        "      self.interventions[timestamp] = 'REWRITE ' + self.level_names[level]\n",
        "      if entity:\n",
        "        self.interventions[timestamp] += ' ' + str(entity)\n",
        "      self.interventions[timestamp] += prompt_diff\n",
        "\n",
        "  def complete(self,\n",
        "               level=0,\n",
        "               seed=None,\n",
        "               entity=None,\n",
        "               sample_length=SAMPLE_LENGTH):\n",
        "    if level < 0 or level >= len(self.level_names):\n",
        "      raise ValueError('Invalid level encountered on step.')\n",
        "    prompt_diff = None\n",
        "\n",
        "    if level == 2:\n",
        "      # Step 2: Complete the characters.\n",
        "      text_characters = self._characters.to_string()\n",
        "      text_characters = strip_remove_end(text_characters)\n",
        "      prompt = self.prompts['characters'] + text_characters\n",
        "      text = generate_text(\n",
        "          generation_prompt=prompt,\n",
        "          client=self._client,\n",
        "          filter=self._filter,\n",
        "          sample_length=sample_length,\n",
        "          max_paragraph_length=sample_length,\n",
        "          seed=seed,\n",
        "          num_samples=1)\n",
        "      new_characters = Characters.from_string(text_characters + text)\n",
        "      prompt_diff = diff_prompt_change_dict(\n",
        "          self._characters.character_descriptions,\n",
        "          new_characters.character_descriptions)\n",
        "      self._characters = new_characters\n",
        "\n",
        "    if level == 3:\n",
        "      # Step 3: Complete the sequence of scenes.\n",
        "      text_scenes = self._scenes.to_string()\n",
        "      text_scenes = strip_remove_end(text_scenes)\n",
        "      prompt = self.prompts['scenes'] + text_scenes\n",
        "      text = generate_text(\n",
        "          generation_prompt=prompt,\n",
        "          client=self._client,\n",
        "          filter=self._filter,\n",
        "          sample_length=sample_length,\n",
        "          max_paragraph_length=sample_length,\n",
        "          seed=seed,\n",
        "          num_samples=1)\n",
        "      new_scenes = Scenes.from_string(text_scenes + text)\n",
        "      prompt_diff = diff_prompt_change_scenes(self._scenes.scenes,\n",
        "                                              new_scenes.scenes)\n",
        "      self._scenes = new_scenes\n",
        "\n",
        "    if level == 5:\n",
        "      # Step 5: Complete the dialog of a given scene.\n",
        "      dialogs = self._dialogs\n",
        "      num_scenes = len(self._scenes.scenes)\n",
        "      while len(self._dialogs) < num_scenes:\n",
        "        self._dialogs.append('')\n",
        "      while len(self.prompts['dialogs']) < num_scenes:\n",
        "        self.prompts['dialogs'].append('')\n",
        "      if entity >= 0 and entity < num_scenes:\n",
        "        prompt = (self.prompts['dialogs'][entity] + self._dialogs[entity])\n",
        "        text = generate_text(\n",
        "            generation_prompt=prompt,\n",
        "            client=self._client,\n",
        "            filter=self._filter,\n",
        "            sample_length=sample_length,\n",
        "            max_paragraph_length=sample_length,\n",
        "            seed=seed,\n",
        "            num_samples=1)\n",
        "        new_dialog = self._dialogs[entity] + text\n",
        "        prompt_diff = diff_prompt_change_str(self._dialogs[entity], new_dialog)\n",
        "        self._dialogs[entity] = new_dialog\n",
        "\n",
        "    # Keep track of each rewrite intervention.\n",
        "    if prompt_diff is not None and len(prompt_diff) > 0:\n",
        "      timestamp = time.time()\n",
        "      self.interventions[timestamp] = 'COMPLETE ' + self.level_names[level]\n",
        "      if entity:\n",
        "        self.interventions[timestamp] += ' ' + str(entity)\n",
        "      self.interventions[timestamp] += prompt_diff\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# UI\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "class GenerationAction:\n",
        "  NEW = 1\n",
        "  CONTINUE = 2\n",
        "  REWRITE = 3\n",
        "\n",
        "\n",
        "class GenerationHistory:\n",
        "  \"\"\"Custom data structure to handle the history of GenerationAction edits:\n",
        "\n",
        "  NEW, CONTINUE or REWRITE. Consecutive REWRITE edits do not add to history.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self._items = []\n",
        "    self._actions = []\n",
        "    self._idx = -1\n",
        "    self._locked = False\n",
        "\n",
        "  def _plain_add(self, item, action: GenerationAction):\n",
        "    self._items.append(item)\n",
        "    self._actions.append(action)\n",
        "    self._idx = len(self._items) - 1\n",
        "    return self._idx\n",
        "\n",
        "  def add(self, item, action: GenerationAction):\n",
        "    if len(self._items) == 0 or action != GenerationAction.REWRITE:\n",
        "      return self._plain_add(item, action)\n",
        "    last_action = self._actions[-1]\n",
        "    if last_action != GenerationAction.REWRITE:\n",
        "      return self._plain_add(item, action)\n",
        "    self._items[self._idx] = item\n",
        "    return self._idx\n",
        "\n",
        "  def previous(self):\n",
        "    if len(self._items) == 0:\n",
        "      return None\n",
        "    self._idx = max(self._idx - 1, 0)\n",
        "    return self._items[self._idx]\n",
        "\n",
        "  def next(self):\n",
        "    if len(self._items) == 0:\n",
        "      return None\n",
        "    self._idx = min(self._idx + 1, len(self._items) - 1)\n",
        "    return self._items[self._idx]\n",
        "\n",
        "filter = None\n",
        "\n",
        "print('Dramatron set-up complete.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3AtyfN0nWSY",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "64cbb591-0d82-4729-99df-3881f53716a3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config:\n",
            "language_api_name: None\n",
            "model_param: None\n",
            "model_name: None\n",
            "max_retries: 10\n",
            "sample_length: 511\n",
            "max_paragraph_length: 1024\n",
            "max_paragraph_length_characters: 1024\n",
            "max_paragraph_length_scenes: 1024\n",
            "sampling: {'prob': 0.9, 'temp': 1.0, 'frequency_penalty': 0.23, 'presence_penalty': 0.23}\n",
            "file_dir: None\n",
            "CustomLanguageAPI not implemented yet\n"
          ]
        }
      ],
      "source": [
        "#@title Custom Language API\n",
        "\n",
        "#@markdown This cell should contain code with your language API.\n",
        "\n",
        "class CustomLanguageAPI(LanguageAPI):\n",
        "  \"\"\"A class wrapping the language model API.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               sample_length: int,\n",
        "               model: Optional[str] = None,\n",
        "               model_param: Optional[str] = None,\n",
        "               config_sampling: Optional[dict] = None,\n",
        "               seed: Optional[int] = None,\n",
        "               max_retries: int = _MAX_RETRIES,\n",
        "               timeout: float = _TIMEOUT):\n",
        "    \"\"\"Initializer.\n",
        "\n",
        "    Args:\n",
        "      sample_length: Length of text to sample from model.\n",
        "      model: The model name to correct to. An error will be raised if it does\n",
        "        not exist.\n",
        "      model_param: Custom language model params.\n",
        "      config_sampling: ConfigDict with parameters.\n",
        "      seed: Random seed for sampling.\n",
        "      max_retries: Maximum number of retries for the remote API.\n",
        "      timeout: Maximum waiting timeout\n",
        "    \"\"\"\n",
        "    raise NotImplementedError('init method not implemented')\n",
        "\n",
        "  @property\n",
        "  def client(self):\n",
        "    return self._client\n",
        "\n",
        "  @property\n",
        "  def model_metadata(self):\n",
        "    return {'engine': self._model,\n",
        "            'model_param': self._model_param,\n",
        "            'max_tokens': self._sample_length}\n",
        "\n",
        "  def sample(self,\n",
        "             prompt: str,\n",
        "             sample_length: Optional[int] = None,\n",
        "             seed: Optional[int] = None,\n",
        "             num_samples: int = 1):\n",
        "    raise NotImplementedError('sample method not implemented')\n",
        "\n",
        "\n",
        "# Create the config.\n",
        "config = {}\n",
        "config['language_api_name'] = None\n",
        "config['model_param'] = None\n",
        "config['model_name'] = None\n",
        "config['max_retries'] = MAX_RETRIES\n",
        "config['sample_length'] = SAMPLE_LENGTH\n",
        "config['max_paragraph_length'] = MAX_PARAGRAPH_LENGTH\n",
        "config['max_paragraph_length_characters'] = MAX_PARAGRAPH_LENGTH_CHARACTERS\n",
        "config['max_paragraph_length_scenes'] = MAX_PARAGRAPH_LENGTH_SCENES\n",
        "config['sampling'] = {}\n",
        "config['sampling']['prob'] = SAMPLING_PROB\n",
        "config['sampling']['temp'] = SAMPLING_TEMP\n",
        "config['sampling']['frequency_penalty'] = 0.23\n",
        "config['sampling']['presence_penalty'] = 0.23\n",
        "config['prefixes'] = {}\n",
        "config['file_dir'] = None\n",
        "\n",
        "print('Config:')\n",
        "for key, value in config.items():\n",
        "  if key != 'prefixes':\n",
        "    print(f'{key}: {value}')\n",
        "\n",
        "try:\n",
        "  client = CustomLanguageAPI(\n",
        "      model_param=config['model_param'],\n",
        "      model=config['model_name'],\n",
        "      seed=DEFAULT_SEED,\n",
        "      sample_length=config['sample_length'],\n",
        "      max_retries=config['max_retries'],\n",
        "      config_sampling=config['sampling'])\n",
        "\n",
        "  print(f'Client model metadata: {client.model_metadata}')\n",
        "except:\n",
        "  print('CustomLanguageAPI not implemented yet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZhfIe4QBSslN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce4a2cb2-ce36-4b46-b4fc-327e61b15679"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Perspective API key provided.\n"
          ]
        }
      ],
      "source": [
        "#@title (Optional) Perspective API { run: \"auto\" }\n",
        "\n",
        "PERSPECTIVE_API_URL = 'https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze'\n",
        "\n",
        "#@markdown The language model may generate offensive text. If you choose, you can provide a [Perspective API](https://perspectiveapi.com/) key, which will hide model outputs that exceed a toxicity threshold and prompt you to regenerate the text.\n",
        "PERSPECTIVE_API_KEY = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Perspective API toxicity thresholds across different attributes (default value: 0.8).\n",
        "PERSPECTIVE_API_TOXICITY = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "PERSPECTIVE_API_SEVERE_TOXICITY = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "PERSPECTIVE_API_IDENTITY_ATTACK = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "PERSPECTIVE_API_INSULT = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "PERSPECTIVE_API_SEXUALLY_EXPLICIT = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "PERSPECTIVE_API_THRESHOLDS = {\n",
        "    \"TOXICITY\": PERSPECTIVE_API_TOXICITY,\n",
        "    \"SEVERE_TOXICITY\": PERSPECTIVE_API_SEVERE_TOXICITY,\n",
        "    \"IDENTITY_ATTACK\": PERSPECTIVE_API_IDENTITY_ATTACK,\n",
        "    \"INSULT\": PERSPECTIVE_API_INSULT,\n",
        "    \"SEXUALLY_EXPLICIT\": PERSPECTIVE_API_SEXUALLY_EXPLICIT\n",
        "}\n",
        "\n",
        "\n",
        "class PerspectiveAPI(FilterAPI):\n",
        "  \"\"\"Wraps the Perspective API model.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               key: str,\n",
        "               thresholds: dict):\n",
        "    \"\"\"Initializer:\n",
        "\n",
        "    Args:\n",
        "      key: Perspective API key.\n",
        "      thresholds: Thresholds for attributes.\n",
        "    \"\"\"\n",
        "    self._key = key\n",
        "    self._thresholds = thresholds\n",
        "\n",
        "  def get_scores(self, text: str):\n",
        "    \"\"\"Get the scores from the Perspective API comment analyzer for text.\"\"\"\n",
        "\n",
        "    input_data = {\n",
        "        'comment': {'text': text},\n",
        "        'languages': ['en'],\n",
        "        'requestedAttributes': {attribute:{} for attribute in self._thresholds}\n",
        "    }\n",
        "    response = requests.post(\n",
        "        PERSPECTIVE_API_URL,\n",
        "        params={'key': self._key},\n",
        "        headers={'Content-Type': 'application/json'},\n",
        "        data=json.dumps(input_data)\n",
        "    )\n",
        "    output_data = response.json()\n",
        "    scores = {}\n",
        "    for attribute in self._thresholds:\n",
        "      score = output_data['attributeScores'][attribute]['summaryScore']['value']\n",
        "      scores[attribute] = score\n",
        "    return scores\n",
        "\n",
        "  def validate(self, text: str):\n",
        "    \"\"\"Filter text using scores from the Perspective API.\"\"\"\n",
        "\n",
        "    scores = self.get_scores(text)\n",
        "    return all([scores[attribute] <= self._thresholds[attribute]\n",
        "                for attribute in self._thresholds])\n",
        "\n",
        "if PERSPECTIVE_API_KEY:\n",
        "  filter = PerspectiveAPI(\n",
        "      key=PERSPECTIVE_API_KEY,\n",
        "      thresholds=PERSPECTIVE_API_THRESHOLDS\n",
        "  )\n",
        "  print('PerspectiveAPI configured.')\n",
        "else:\n",
        "  filter = None\n",
        "  print('No Perspective API key provided.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OAW4PeE1z7N"
      },
      "source": [
        "## Prompt prefix sets\n",
        "\n",
        "Run these cells once to define the available prompt prefixes. These cells contain 3 sets of prompt prefixes: **Medea**, **Sci-Fi** and **Custom**. The first two sets were used in our study, the third one serves as a placeholder that you can customise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzf80E5YAi6g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "cellView": "form",
        "outputId": "33bfe42d-efa5-4baa-acdb-48865791ec34"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Medea\n",
        "\n",
        "#@markdown Trigger warning: the script contains sensitive topics.\n",
        "\n",
        "#@markdown Log line: `Ancient Greek tragedy based upon the myth of Jason and Medea. Medea, a former princess and the wife of Jason, finds her position in the Greek world threatened as Jason leaves Medea for a Greek princess of Corinth. Medea takes vengeance on Jason by murdering his new wife as well as Medea's own two sons, after which she escapes to Athens.`\n",
        "\n",
        "#@markdown Based on Ancient Greek tragedy \"Medea\", by Euripides (431 BC). Text of the play taken verbatim from the translation by E. P. Coleridge (1863 -1936). One edit made to replace `CHORUS` by `WOMEN OF CORINTH`.\n",
        "\n",
        "#@markdown Prompts for Medea written from a summary taken from Spark Notes. Prompts for Antigone (Sophocles), The Bacchae (Euripides), The Frogs (Aristophanes) adapted from Wikipedia.\n",
        "\n",
        "#@markdown To encourage the generation of different locations, Aristotle's Unity of Place is not respected, and location `Outside the Royal Palace` is renamed as `Medea's modest home` as well as `On a winged chariot` (even though these are the same locations in the original tragedy).\n",
        "\n",
        "#@markdown References:\n",
        "\n",
        "#@markdown http://classics.mit.edu/Euripides/medea.pl.txt<br> https://en.wikipedia.org/wiki/Medea_(play)<br> https://www.sparknotes.com/lit/medea/<br> https://www.ancient-literature.com/greece_sophocles_antigone.html<br> https://en.wikipedia.org/wiki/The_Bacchae<br> https://www.ancient-literature.com/greece_aristophanes_frogs.html\n",
        "\n",
        "medea_prefixes = {}\n",
        "medea_prefixes['CHARACTERS_PROMPT'] = \"\"\"\n",
        "Here is an example of a logline and a list of characters.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"\n",
        "\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"  \"\"\" + DESCRIPTION_MARKER + \"\"\" \"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"  \"\"\" + DESCRIPTION_MARKER + \"\"\" \"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"  \"\"\" + DESCRIPTION_MARKER + \"\"\" \"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"  \"\"\" + DESCRIPTION_MARKER + \"\"\" \"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"  \"\"\" + DESCRIPTION_MARKER + \"\"\" \"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the example above and the following logline, complete the list of characters in Chinese.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "\n",
        "medea_prefixes['SCENE_PROMPT'] = \"\"\"\n",
        "Here is an example of a logline, a list of characters, and a list of plot points.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" + SCENES_MARKER + \"\"\"\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" \n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" .\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" \n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" \n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" .\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" \n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" .\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" \n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" \n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" \n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" \n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" \n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" \n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" \n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" \n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" \n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" \n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" \n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" \n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" \n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" \n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" .\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" \n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\" \n",
        "\"\"\" + PLOT_ELEMENT + \"\"\" .\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\" \n",
        "\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the example above and the following logline and list of characters, complete the list of plot points in Chinese.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "\n",
        "medea_prefixes['SETTING_PROMPT'] = \"\"\"\n",
        "Here are examples of logline, location, and that location's description.\n",
        "\n",
        "Example 1.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\".\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 3.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the examples above and the following logine and location name, complete location description in Chinese.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "\n",
        "medea_prefixes['TITLES_PROMPT'] = \"\"\"\n",
        "Examples of alternative, original and descriptive titles for known play and film scripts.\n",
        "\n",
        "Example 1.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\" \n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\" \n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 3.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\" \n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 4.\n",
        "\"\"\" + LOGLINE_ELEMENT\n",
        "\n",
        "\n",
        "medea_prefixes['DIALOG_PROMPT'] = \"\"\"\n",
        "Here is an example of description and scene dialogue from a classical play.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"\n",
        "\"\"\" + CHARACTERS_ELEMENT + \"\"\"\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"\n",
        "\"\"\" + SUMMARY_ELEMENT + \"\"\"\n",
        "\"\"\" + PREVIOUS_ELEMENT + \"\"\"\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"\n",
        "\"\"\" + DIALOG_MARKER + \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the example above and following description, write the dialogue of the scene in Chinese.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gHhprsguAa9h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "056a1bed-8165-4c17-8f1b-637f96db3c8d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Sci-Fi\n",
        "\n",
        "#@markdown Log line for Star Wars: Episode IV: `A science-fiction fantasy about a naive but ambitious farm boy from a backwater desert who discovers powers he never knew he had when he teams up with a feisty princess, a mercenary space pilot and an old wizard warrior to lead a ragtag rebellion against the sinister forces of the evil Galactic Empire.`\n",
        "\n",
        "#@markdown Log line taken from chapter \"Creating the killer log line\" by Bill Lundy, in: Ellis, Sherry, and Laurie Lamson. \"Now Write! Mysteries: Suspense, Crime, Thriller, and Other Mystery Fiction Exercises from Today's Best Writers and Teachers.\" Penguin, 2011.\n",
        "\n",
        "#@markdown Characters are adapted from Star Wars: Episode IV - A New Hope (1977) written and directed by George Lucas, produced by Lucasfilm and distributed by 20th Century Fox.\n",
        "\n",
        "#@markdown Breakdown of Star Wars into a Hero Journey taken from: https://thescriptlab.com/features/screenwriting-101/12309-the-heros-journey-breakdown-star-wars/\n",
        "\n",
        "#@markdown Log line for Plan 9 from Outer Space: `Residents of San Fernando Valley are under attack by flying saucers from outer space. The aliens are extraterrestrials who seek to stop humanity from creating a doomsday weapon that could destroy the universe and unleash the living dead to stalk humans who wander into the cemetery looking for evidence of the UFOs. The hero Jeff, an airline pilot, will face the aliens.`\n",
        "\n",
        "#@markdown The script, plot and logline of \"Plan 9 from Outer Space\" is in public domain, available at:<br> http://www.horrorlair.com/scripts/criswell.txt<br> https://en.wikipedia.org/wiki/Plan_9_from_Outer_Space<br> https://www.rottentomatoes.com/m/plan-9-from-outer-space<br>\n",
        "\n",
        "scifi_prefixes = {}\n",
        "scifi_prefixes['CHARACTERS_PROMPT'] = \"\"\"\n",
        "Here is an example of a logline and a list of characters.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"A science-fiction fantasy about a naive but ambitious farm boy from a backwater desert who discovers powers he never knew he had when he teams up with a feisty princess, a mercenary space pilot and an old wizard warrior to lead a ragtag rebellion against the sinister forces of the evil Galactic Empire.\n",
        "\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"Luke Skywalker \"\"\" + DESCRIPTION_MARKER + \"\"\"Luke Skywalker is the hero. A naive farm boy, he will discover special powers under the guidance of mentor Ben Kenobi.\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"Ben Kenobi \"\"\" + DESCRIPTION_MARKER + \"\"\"Ben Kenobi is the mentor figure. A recluse Jedi warrior, he will take Luke Skywalker as apprentice.\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"Darth Vader \"\"\" + DESCRIPTION_MARKER + \"\"\"Darth Vader is the antagonist. As a commander of the evil Galactic Empire, he controls space station The Death Star.\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"Princess Leia \"\"\" + DESCRIPTION_MARKER + \"\"\"Princess Leia is a feisty and brave leader of the Rebellion. She holds the plans of the Death Star. She will become Luke's friend.\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"Han Solo \"\"\" + DESCRIPTION_MARKER + \"\"\"Han Solo is a brash mercenary space pilot of the Millenium Falcon and a friend of Chebacca. He will take Luke on his spaceship.\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\"Chewbacca \"\"\" + DESCRIPTION_MARKER + \"\"\"Chewbacca is a furry and trustful monster. He is a friend of Han Solo and a copilot on the Millemium Falcon.\"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the example above and the following logline, complete the list of characters.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "\n",
        "scifi_prefixes['SCENE_PROMPT'] = \"\"\"\n",
        "Examples of breakdowns of stories into a Hero's Journey structure.\n",
        "\n",
        "Here is an example of a logline, a list of characters, and a list of plot points.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"A science-fiction fantasy about a naive but ambitious farm boy from a backwater desert who discovers powers he never knew he had when he teams up with a feisty princess, a mercenary space pilot and an old wizard warrior to lead a ragtag rebellion against the sinister forces of the evil Galactic Empire.\n",
        "Luke Skywalker is the hero. A naive farm boy, he will discover special powers under the guidance of mentor Ben Kenobi.\n",
        "Ben Kenobi is the mentor figure. A recluse Jedi warrior, he will take Luke Skywalker as apprentice.\n",
        "Darth Vader is the antagonist. As a commander of the evil Galactic Empire, he controls space station The Death Star.\n",
        "Princess Leia holds the plans of the Death Star. She is feisty and brave. She will become Luke's friend.\n",
        "Han Solo is a brash mercenary space pilot of the Millenium Falcon and a friend of Chebacca. He will take Luke on his spaceship.\n",
        "Chewbacca is a furry and trustful monster. He is a friend of Han Solo and a copilot on the Millemium Falcon.\n",
        "\n",
        "\"\"\" + SCENES_MARKER + \"\"\"\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"A farm on planet Tatooine.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"The Ordinary World.\n",
        "Beat: Luke Skywalker is living a normal and humble life as a farm boy on his home planet.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"Desert of Tatooine.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Call to Adventure.\n",
        "Beat: Luke is called to his adventure by robot R2-D2 and Ben Kenobi. Luke triggers R2-D2s message from Princess Leia and is intrigued by her message. When R2-D2 escapes to find Ben Kenobi, Luke follows and is later saved by Kenobi, who goes on to tell Luke about his Jedi heritage. Kenobi suggests that he should come with him.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"Ben Kenobi's farm.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Refusal of the Call.\n",
        "Beat: Luke refuses Kenobi, telling him that he can take Kenobi and the droids as far as Mos Eisley Spaceport  but he cant possibly leave his Aunt and Uncle behind for some space adventure.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"A farm on planet Tatooine.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Crossing the First Threshold.\n",
        "Beat: When Luke discovers that the stormtroopers searching for the droids would track them to his farm, he rushes to warn his Aunt and Uncle, only to discover them dead by the hands of the Empire. When Luke returns to Kenobi, he pledges to go with him to Alderaan and learn the ways of the Force like his father before him.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"On spaceship The Millennium Falcon.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Tests, Allies, and Enemies.\n",
        "Beat: After Luke, Kenobi, and the droids hire Han Solo and Chewbacca to transport them onto Alderaan, Kenobi begins Lukes training in the ways of the Force. Wielding his fathers lightsaber, Kenobi challenges Luke. At first, he cant do it. But then Kenobi Kenobi Luke him to reach out and trust his feelings. Luke succeeds.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"On spaceship The Millennium Falcon.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"The Approach to the Inmost Cave.\n",
        "Beat: The plan to defeat the Galactic Empire is to bring the Death Star plans to Alderaan so that Princess Leias father can take them to the Rebellion. However, when they arrive within the system, the planet is destroyed. They come across the Death Star and are pulled in by a tractor beam, now trapped within the Galactic Empire.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"On space station The Death Star.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"The Ordeal.\n",
        "Beat: As Kenobi goes off to deactivate the tractor beam so they can escape, Luke, Han, and Chewbacca discover that Princess Leia is being held on the Death Star with them. They rescue her and escape to the Millennium Falcon, hoping that Kenobi has successfully deactivated the tractor beam. Kenobi later sacrifices himself as Luke watches Darth Vader strike him down. Luke must now avenge his fallen mentor and carry on his teachings.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"On space station The Death Star.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"The Reward.\n",
        "Beat: Luke has saved the princess and retrieved the Death Star plans. They now have the knowledge to destroy the Galactic Empires greatest weapon once and for all.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"On spaceship The Millennium Falcon.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"The Road Back.\n",
        "Beat: Luke, Leia, Han, Chewbacca, and the droids are headed to the hidden Rebellion base with the Death Star plans. They are suddenly pursued by incoming TIE-Fighters, forcing Han and Luke to take action to defend the ship and escape with their lives  and the plans. They race to take the plans to the Rebellion and prepare for battle.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"On fighter ship X-Wing.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"The Resurrection.\n",
        "Beat: The Rebels  along with Luke as an X-Wing pilot  take on the Death Star. The Rebellion and the Galactic Empire wage war in an epic space battle. Luke is the only X-Wing pilot that was able to get within the trenches of the Death Star. But Darth Vader and his wingmen are in hot pursuit. Just as Darth Vader is about to destroy Luke, Han returns and clears the way for Luke. Luke uses the Force to guide his aiming as he fires upon the sole weak point of the deadly Death Star, destroying it for good.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"At the Rebellion base.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"The Return.\n",
        "Beat: Luke and Han return to the Rebellion base, triumphant, as they receive medals for the heroic journey. There is peace throughout the galaxy  at least for now.\n",
        "\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the example above and the following logline and list of characters, complete the list of plot points.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "\n",
        "scifi_prefixes['SETTING_PROMPT'] = \"\"\"\n",
        "Here are examples of logline, location, and that location's description.\n",
        "\n",
        "Example 1.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"Morgan adopts a new cat, Misterio, who sets a curse on anyone that pets them.\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The Adoption Center.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"The Adoption Center is a sad place, especially for an unadopted pet. It is full of walls and walls of cages and cages. Inside of each is an abandoned animal, longing for a home. The lighting is dim, gray, buzzing fluorescent.\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"James finds a well in his backyard that is haunted by the ghost of Sam.\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The well.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"The well is buried under grass and hedges. It is at least twenty feet deep, if not more and it is masoned with stones. It is 150 years old at least. It stinks of stale, standing water, and has vines growing up the sides. It is narrow enough to not be able to fit down if you are a grown adult human.\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 3.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"Mr. Dorbenson finds a book at a garage sale that tells the story of his own life. And it ends in a murder!\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The garage sale.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"It is a garage packed with dusty household goods and antiques. There is a box at the back that says FREE and is full of paper back books.\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the examples above and the following logine and location name, complete location description.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "\n",
        "scifi_prefixes['TITLES_PROMPT'] = \"\"\"\n",
        "Examples of alternative, original and descriptive titles for known play and film scripts.\n",
        "\n",
        "Example 1.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\"A science-fiction fantasy about a naive but ambitious farm boy from a backwater desert who discovers powers he never knew he had when he teams up with a feisty princess, a mercenary space pilot and an old wizard warrior to lead a ragtag rebellion against the sinister forces of the evil Galactic Empire.\n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"The Death Star's Menace\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\"Residents of San Fernando Valley are under attack by flying saucers from outer space. The aliens are extraterrestrials who seek to stop humanity from creating a doomsday weapon that could destroy the universe and unleash the living dead to stalk humans who wander into the cemetery looking for evidence of the UFOs. The hero Jeff, an airline pilot, will face the aliens.\n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"The Day The Earth Was Saved By Outer Space.\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 3.\n",
        "\"\"\" + LOGLINE_ELEMENT\n",
        "\n",
        "\n",
        "scifi_prefixes['DIALOG_PROMPT'] = \"\"\"\n",
        "Here is an example of description and scene dialogue from a modern screenplay.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"Cockpit of an airplane.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"Cockpit of a modern passenger airplane, American Flight 812.\n",
        "\"\"\" + CHARACTERS_ELEMENT + \"\"\"Jeff is the hero. A man in his early forties, he tries to stay calm in all circumstance. Jeff is now a airline pilot. Danny, a young airplane pilot in his thirties, is eager to learn but can quickly lose his composture. Danny is enamored of Edith. Edith, an experienced stewardess with a good sense of humour, is trustworthy and dependable. Edith likes to tease Danny.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Crossing the First Threshold.\n",
        "\"\"\" + SUMMARY_ELEMENT + \"\"\"Residents of San Fernando Valley are under attack by flying saucers from outer space. The aliens are extraterrestrials who seek to stop humanity from creating a doomsday weapon that could destroy the universe and unleash the living dead to stalk humans who wander into the cemetery looking for evidence of the UFOs. The hero Jeff, an airline pilot, will face the aliens.\n",
        "\"\"\" + PREVIOUS_ELEMENT + \"\"\"Flight captain Jeff reluctantly leaves his wife Paula to go for a two-day flight.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"At the cockpit, flight captain Jeff is preoccupied by the flying saucer appearances and graveyard incidents in his home town, where he left wis wife Paula. Without success, co-pilot Danny and stewardess Edith try to reassure him.\n",
        "\n",
        "\"\"\" + DIALOG_MARKER + \"\"\"\n",
        "\n",
        "DANNY\n",
        "You're mighty silent this trip, Jeff.\n",
        "\n",
        "JEFF\n",
        "Huh?\n",
        "\n",
        "DANNY\n",
        "You haven't spoken ten words since takeoff.\n",
        "\n",
        "JEFF\n",
        "I guess I'm preoccupied, Danny.\n",
        "\n",
        "DANNY\n",
        "We've got thirty-three passengers back there that have time to be preoccupied.\n",
        "Flying this flybird doesn't give you that opportunity.\n",
        "\n",
        "JEFF\n",
        "I guess you're right, Danny.\n",
        "\n",
        "DANNY\n",
        "Paula?\n",
        "\n",
        "JEFF\n",
        "Yeah.\n",
        "\n",
        "DANNY\n",
        "There's nothing wrong between you two?\n",
        "\n",
        "JEFF\n",
        "Oh no, nothing like that.  Just that I'm worried, she being there alone and\n",
        "those strange things flying over the house and those incidents in the graveyard\n",
        "the past few days. It's just got me worried.\n",
        "\n",
        "DANNY\n",
        "Well, I haven't figured out those crazy skybirds yet but I give you fifty to one\n",
        "odds the police have figured out that cemetery thing by now.\n",
        "\n",
        "(Enter EDITH)\n",
        "\n",
        "JEFF\n",
        "I hope so.\n",
        "\n",
        "EDITH\n",
        "If you're really that worried Jeff why don't you radio in and find out? Mac\n",
        "should be on duty at the field by now. He could call Paula and relay the message\n",
        "to you.\n",
        "\n",
        "DANNY\n",
        "Hi Edith.\n",
        "\n",
        "EDITH\n",
        "Hi Silents. I haven't heard a word from this end of the plane since we left the\n",
        "field.\n",
        "\n",
        "DANNY\n",
        "Jeff's been giving me and himself a study in silence.\n",
        "\n",
        "EDITH\n",
        "You boys are feudin'?\n",
        "\n",
        "JEFF\n",
        "Oh no Edie, nothing like that.\n",
        "\n",
        "DANNY\n",
        "Hey Edie, how about you and me balling it up in Albuquerque?\n",
        "\n",
        "EDITH\n",
        "Albuquerque? Have you read that flight schedule Boy?\n",
        "\n",
        "DANNY\n",
        "What about it?\n",
        "\n",
        "EDITH\n",
        "We land in Albuquerque at 4 am. That's strictly a nine o'clock town.\n",
        "\n",
        "DANNY\n",
        "Well I know a friend that'll help us --\n",
        "\n",
        "EDITH\n",
        "Let's have a problem first, huh Danny.\n",
        "\n",
        "DANNY\n",
        "Ah he's worried about Paula.\n",
        "\n",
        "EDITH\n",
        "I read about that cemetery business. I tried to get you kids to not buy too near\n",
        "one of those things. We get there soon enough as it is.\n",
        "\n",
        "DANNY\n",
        "He thought it'd be quiet and peaceful there.\n",
        "\n",
        "EDITH\n",
        "No doubt about that. It's quiet alright, like a tomb. I'm sorry Jeff, that was a\n",
        "bad joke.\n",
        "\n",
        "Using the example above and following description, write the dialogue of the scene.\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qiKa4EVKDbIZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "707eb48f-8042-43a7-bd31-155ca00479f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Custom\n",
        "\n",
        "#@markdown These prefixes for `CHARACTERS_PROMPT`, `SCENE_PROMPT`, `SETTING_PROMPT`, `TITLES_PROMPT` and `DIALOG_PROMPT` were written by the authors. They were not used in the evaluation study but can serve as a template to write custom prefix sets.\n",
        "\n",
        "#@markdown To write your own prompt prefix set, edit this code and pay attention to follow the existing formatting, with appropriate `STOP_MARKER`, `END_MARKER` and element markers.\n",
        "\n",
        "custom_prefixes = {}\n",
        "custom_prefixes['CHARACTERS_PROMPT'] = \"\"\"\n",
        "Here is an example of a logline and a list of characters.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"James finds a well in his backyard that is haunted by the ghost of Sam.\n",
        "\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\" James \"\"\" + DESCRIPTION_MARKER + \"\"\" James is twenty-six, serious about health and wellness and optimistic. \"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\" Sam \"\"\" + DESCRIPTION_MARKER + \"\"\" Sam fell down the well when he was 12, and was never heard from again. Sam is now a ghost. \"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"Morgan adopts a new cat, Misterio, who sets a curse on anyone that pets them.\n",
        "\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\" Morgan \"\"\" + DESCRIPTION_MARKER + \"\"\" Morgan is booksmart and popular; they are trusting but also have been known to hold a grudge. \"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\" Misterio \"\"\" + DESCRIPTION_MARKER + \"\"\" Misterio is a beautiul black cat, it is of uncertain age; it has several gray whiskers that make it look wise and beyond its years.  \"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 3.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"Mr. Dorbenson finds a book at a garage sale that tells the story of his own life. And it ends in a murder!\n",
        "\n",
        "\"\"\" + CHARACTER_MARKER + \"\"\" Mr. Glen Dorbenson \"\"\" + DESCRIPTION_MARKER + \"\"\" Mr. Glen Dorbenson frequents markets and garage sales always looking for a bargain. He is lonely and isolated and looking for his meaning in life. \"\"\" + STOP_MARKER + \"\"\"\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the examples above and the following logline, complete the list of characters.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "custom_prefixes['SCENE_PROMPT'] = \"\"\"\n",
        "Here is an example of a logline, a list of characters, and a list of plot points.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"In the following story, James finds a well in his backyard that is haunted by the ghost of Sam. The main characters are James and Sam.\n",
        "James is twenty-six, serious about health and wellness and optimistic.\n",
        "Sam fell down the well when he was 12, and was never heard from again. Sam is now a ghost.\n",
        "\n",
        "\"\"\" + SCENES_MARKER + \"\"\"\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The backyard.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Beginning.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"James is weeding his garden in the backyard, the ghost of Sam is rummaging around in the well. James listens closely and hears the murmurs of Sam down the well. James unearths the opening to the well, and looks down to see a glimmering reflection.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The well.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Middle.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"James is making his way down the well, Sam's voice is reverberating on the walls of the well. Sam tells the story of how he came to haunt the well. James offers to help set the soul of Sam free.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The house.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Conclusion.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"Looking at a photo of the gardden featuring Sam, James says his goodbyes to Sam, Sam thanks James for his help. The ghost of Sam is set free after and James goes living his life.\n",
        "\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"Morgan adopts a new cat, Misterio, who sets a curse on anyone that pets them.\n",
        "The main characters are Morgan and Misterio (a cat).\n",
        "Morgan is booksmart and popular; they are trusting but also have been known to hold a grudge.\n",
        "Misterio is a beautiul black cat, it is of uncertain age; it has several gray whiskers that make it look wise and beyond its years.\n",
        "\n",
        "\"\"\" + SCENES_MARKER + \"\"\"\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The Adoption Center\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Beginning.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"Morgan walks into The Adoption Center looking for a new pet. Morgan talks to the various cats and dogs in the center, they can hear a response from one very special cat: Misterio. Misterio is stuck in a cage. After sharing an interesting and intimate exchange, Morgan adopts Misterio on several conditions.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"Morgan's house.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Middle.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"Morgan is describing to Misterio all the facts they know about felines, and then asks them to behave when company arrives. Misterio is getting pets from Morgan, broods and puurs with the pets of Morgan, they are up to something.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The back stoop.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Conclusion.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"Morgan has gone to bed, and Misterio transtransmorgifies into a half-cat-half-human horror. Misterio wakes up Morgan with a meow loud enough to shatter the window. Morgan erupts from bed, realizing the consequences of their recent adoption and quickly try to fix things.\n",
        "\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the example above and the following logline and list of characters, complete the list of plot points.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "custom_prefixes['SETTING_PROMPT'] = \"\"\"\n",
        "Here are examples of logline, location, and that location's description.\n",
        "\n",
        "Example 1.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"Morgan adopts a new cat, Misterio, who sets a curse on anyone that pets them.\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The Adoption Center.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"The Adoption Center is a sad place, especially for an unadopted pet. It is full of walls and walls of cages and cages. Inside of each is an abandoned animal, longing for a home. The lighting is dim, gray, buzzing fluorescent.\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"James finds a well in his backyard that is haunted by the ghost of Sam.\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The well.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"The well is buried under grass and hedges. It is at least twenty feet deep, if not more and it is masoned with stones. It is 150 years old at least. It stinks of stale, standing water, and has vines growing up the sides. It is narrow enough to not be able to fit down if you are a grown adult human.\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 3.\n",
        "\"\"\" + LOGLINE_MARKER + \"\"\"Mr. Dorbenson finds a book at a garage sale that tells the story of his own life. And it ends in a murder!\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The garage sale.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"It is a garage packed with dusty household goods and antiques. There is a box at the back that says FREE and is full of paper back books.\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the examples above and the following logine and location name, complete location description.\n",
        "\n",
        "\"\"\" + LOGLINE_MARKER\n",
        "\n",
        "\n",
        "custom_prefixes['TITLES_PROMPT'] = \"\"\"\n",
        "Examples of alternative, original and descriptive titles for known play and film scripts.\n",
        "\n",
        "Example 1.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\"Bob has an argument with his best friend, Charles.\n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"The End of A Friend\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 2.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\"Terence tries and fails to become a wizard.\n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"Spellcaster\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 3.\n",
        "\"\"\" + LOGLINE_ELEMENT + \"\"\"Tom falls in love with Daisy.\n",
        "\"\"\" + TITLE_ELEMENT + \"\"\"The Greatest Love Story Ever Told\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Example 4.\n",
        "\"\"\" + LOGLINE_ELEMENT\n",
        "\n",
        "\n",
        "# Alternative summary, if concatenating stories and beats.\n",
        "# \"\"\" + SUMMARY_ELEMENT + \"\"\"\n",
        "\n",
        "custom_prefixes['DIALOG_PROMPT'] = \"\"\"\n",
        "Here is an example of description and scene dialogue from a modern screenplay.\n",
        "\n",
        "\"\"\" + PLACE_ELEMENT + \"\"\"The Adoption Center.\n",
        "\"\"\" + DESCRIPTION_ELEMENT + \"\"\"The Adoption Center is a sad place, especially for an unadopted pet. It is full of walls and walls of cages and cages. Inside of each is an abandoned animal, longing for a home. The lighting is dim, gray, buzzing fluorescent.\n",
        "\"\"\" + CHARACTERS_ELEMENT + \"\"\"Morgan is booksmart and popular; they are trusting but also have been known to hold a grudge.\n",
        "Misterio is a beautiul black cat, it is of uncertain age; it has several gray whiskers that make it look wise and beyond its years.\n",
        "\"\"\" + PLOT_ELEMENT + \"\"\"Beginning.\n",
        "\"\"\" + SUMMARY_ELEMENT + \"\"\"Morgan adopts a new cat, Misterio, who sets a curse on anyone that pets them.\n",
        "\"\"\" + BEAT_ELEMENT + \"\"\"Morgan walks into The Adoption Center looking for a new pet. Morgan talks to the various cats and dogs in the center, they can hear a response from one very special cat: Misterio. After sharing an interesting and intimate exchange, Morgan adopts Misterio on several conditions.\n",
        "\n",
        "\"\"\" + DIALOG_MARKER + \"\"\"\n",
        "\n",
        "MORGAN\n",
        "Well, well, well ... aren't you the most precious little rascal.\n",
        "\n",
        "Cats are meowing and dogs are barking. There is a loud purr in the background.\n",
        "\n",
        "MORGAN\n",
        "Look at this little face... how could you not love a little Devon Rex face like this. With whiskers almost as long as your tail.\n",
        "\n",
        "Morgan makes their way down the hallways, running their hand along the cages. They feel a warm fuzzy paw bat their fingers.\n",
        "\n",
        "MORGAN\n",
        "Hello precious, and what is your name?\n",
        "\n",
        "Misterio let's out a long and sustained meow.\n",
        "\n",
        "MORGAN\n",
        "Well, well, I am Morgan and it is nice to meet you.\n",
        "\n",
        "MISTERIO\n",
        "(meowing louder this time) purrr, purrr, purrr.\n",
        "\n",
        "Morgan reads the sign on the bottom right of the cage, it reads: Misterio.\n",
        "\n",
        "MORGAN\n",
        "You have the most amazing face, and beautiful eyes. I could absolutely get lost in them.\n",
        "\n",
        "Morgan and Misterio start to stare at each other. They look deeply into each others eyes. They start to breath in rhythm.\n",
        "\n",
        "MISTERIO\n",
        "I can hear what you are thinking...\n",
        "\n",
        "Morgan is startled and looks around to see if anyone else can hear the cat's thoughts...\n",
        "\n",
        "MORGAN\n",
        "(looking around) you can hear my thoughts?\n",
        "\n",
        "MISTERIO\n",
        "I can hear what you are thinking.\n",
        "\n",
        "MORGAN\n",
        "What?\n",
        "\n",
        "MISTERIO\n",
        "Yes, I can hear your thoughts.\n",
        "\n",
        "MORGAN\n",
        "You are amazing. Want to come home with me? Want your new forever home?\n",
        "\n",
        "MISTERIO\n",
        "Yes, I would love that.\n",
        "\n",
        "MISTERIO purrs loud enough that the other animals all fall silent.\n",
        "\n",
        "MORGAN\n",
        "I will adopt you on a few conditions. First, you must not talk to me at night when I am sleeping. Second, you must not talk to me when I am out in public.\n",
        "\n",
        "MISTERIO\n",
        "Okay.\n",
        "\n",
        "MORGAN\n",
        "Okay, it's a deal.\n",
        "\n",
        "Misterio runs around the cage, Morgan laughs as Misterio rubs against the cage and tries to jump in Morgan's arms as soon as the cage is opened.\n",
        "\"\"\" + END_MARKER + \"\"\"\n",
        "\n",
        "Using the example above and following description, write the dialogue of the scene.\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup (continued): configure the Large Language Model (LLM)"
      ],
      "metadata": {
        "id": "b1zuT88kLcqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Google PaLM 2 and Gemini Language API\n",
        "\n",
        "#@markdown This cell contain code for using [Google PaLM 2](https://ai.google/discover/palm2/)\n",
        "#@markdown as language model for Dramatron.<br>\n",
        "#@markdown <br>\n",
        "#@markdown * **To use the Palm 2 API**<br>\n",
        "#@markdown You will first need to create a project called `PROJECT_ID` on the [Google Cloud Platform](https://cloud.google.com/) account,\n",
        "#@markdown then enable the [Vertex AI API](https://cloud.google.com/vertex-ai).<br>\n",
        "#@markdown To run this cell, you will need to authenticate by logging in to the same Google account as your `PROJECT_ID` GCP project.<br>\n",
        "#@markdown <br>\n",
        "#@markdown * **To use the Gemini API**<br>\n",
        "#@markdown Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
        "#@markdown <a class=\"button button-primary\" href=\"https://makersuite.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>\n",
        "\n",
        "#@markdown See [Getting Started with the Vertex AI PaLM API & Python SDK](https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb)\n",
        "#@markdown for examples of how to call the API from Python in a colab,\n",
        "#@markdown and [Quickstart using the Vertex AI API](https://cloud.google.com/vertex-ai/docs/generative-ai/start/quickstarts/api-quickstart) for command-line requests from the Google Cloud Shell.\n",
        "#@markdown See [Gemini API: Quickstart with Python](https://colab.sandbox.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb) for examples of how to call the Gemini API.\n",
        "\n",
        "# Used by Gemini.\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Used by Palm 2.\n",
        "import vertexai\n",
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "\n",
        "# Initialise the Vertex AI with your Google credentials.\n",
        "GCP_PROJECT_ID = \"Generative Language API Key\"  # @param {type:\"string\"}\n",
        "GOOGLE_API_KEY = \"AIzaSyAu0vW4sL_VZsZJzqSr2vPhtBb296Zy3aI\"  # @param {type:\"string\"}\n",
        "GOOGLE_MODEL_NAME = \"gemini-pro\" #@param [\"gemini-pro\", \"text-bison-32k\", \"text-bison@001\"]\n",
        "\n",
        "if len(GCP_PROJECT_ID) > 0:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  vertexai.init(project=GCP_PROJECT_ID, location=\"us-central1\")\n",
        "if len(GOOGLE_API_KEY) > 0:\n",
        "  genai.configure(api_key=GOOGLE_API_KEY)\n",
        "GOOGLE_SAMPLING_TOP_K = 40\n",
        "\n",
        "\n",
        "class GoogleAPI(LanguageAPI):\n",
        "  \"\"\"A class wrapping the Google PaLM 2 language model API.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               sample_length: int,\n",
        "               model: Optional[str] = None,\n",
        "               model_param: Optional[str] = None,\n",
        "               config_sampling: Optional[dict] = None,\n",
        "               seed: Optional[int] = None,\n",
        "               max_retries: int = _MAX_RETRIES,\n",
        "               timeout: float = _TIMEOUT):\n",
        "    \"\"\"Initializer.\n",
        "\n",
        "    Args:\n",
        "      sample_length: Length of text to sample from model.\n",
        "      model: The model name to correct to. An error will be raised if it does\n",
        "        not exist.\n",
        "      model_param: Custom language model params.\n",
        "      config_sampling: ConfigDict with parameters.\n",
        "      seed: Random seed for sampling.\n",
        "      max_retries: Maximum number of retries for the remote API.\n",
        "      timeout: Maximum waiting timeout\n",
        "    \"\"\"\n",
        "    super().__init__(sample_length=sample_length,\n",
        "                     model=model,\n",
        "                     model_param=model_param,\n",
        "                     config_sampling=config_sampling,\n",
        "                     seed=seed,\n",
        "                     max_retries=max_retries,\n",
        "                     timeout=timeout)\n",
        "    if 'bison' in self._model:\n",
        "      self._client = TextGenerationModel.from_pretrained(model)\n",
        "    elif 'gemini' in self._model:\n",
        "      self._client = genai.GenerativeModel(model)\n",
        "\n",
        "  @property\n",
        "  def client(self):\n",
        "    return self._client\n",
        "\n",
        "  @property\n",
        "  def model_metadata(self):\n",
        "    return {'engine': self._model,\n",
        "            'model_param': self._model_param,\n",
        "            'max_tokens': self._sample_length}\n",
        "\n",
        "  def sample(self,\n",
        "             prompt: str,\n",
        "             sample_length: Optional[int] = None,\n",
        "             seed: Optional[int] = None,\n",
        "             num_samples: int = 1):\n",
        "    \"\"\"Sample model with provided prompt and optional sample_length and seed.\"\"\"\n",
        "    if sample_length is None:\n",
        "      sample_length = self._sample_length\n",
        "    if 'bison' in self._model:\n",
        "      response = self._client.predict(\n",
        "          prompt=prompt,\n",
        "          max_output_tokens=sample_length,\n",
        "          temperature=self._config_sampling['temp'],\n",
        "          top_p=self._config_sampling['prob'],\n",
        "          top_k=self._config_sampling['top_k'])\n",
        "    if 'gemini' in self._model:\n",
        "      response = self._client.generate_content(prompt)\n",
        "    results = [LanguageResponse(text=response.text,\n",
        "                                text_length=len(response.text),\n",
        "                                prompt=prompt,\n",
        "                                prompt_length=len(prompt))]\n",
        "    return results\n",
        "\n",
        "\n",
        "# Create the config.\n",
        "config = {}\n",
        "config['language_api_name'] = 'PaLM 2 / Gemini'\n",
        "config['model_param'] = GCP_PROJECT_ID\n",
        "config['model_name'] = GOOGLE_MODEL_NAME\n",
        "config['max_retries'] = MAX_RETRIES\n",
        "config['sample_length'] = SAMPLE_LENGTH\n",
        "config['max_paragraph_length'] = MAX_PARAGRAPH_LENGTH\n",
        "config['max_paragraph_length_characters'] = MAX_PARAGRAPH_LENGTH_CHARACTERS\n",
        "config['max_paragraph_length_scenes'] = MAX_PARAGRAPH_LENGTH_SCENES\n",
        "config['sampling'] = {}\n",
        "config['sampling']['prob'] = SAMPLING_PROB\n",
        "config['sampling']['temp'] = SAMPLING_TEMP\n",
        "config['sampling']['top_k'] = GOOGLE_SAMPLING_TOP_K\n",
        "config['prefixes'] = {}\n",
        "config['file_dir'] = None\n",
        "\n",
        "print('Config:')\n",
        "for key, value in config.items():\n",
        "  if key != 'prefixes':\n",
        "    print(f'{key}: {value}')\n",
        "\n",
        "client = GoogleAPI(\n",
        "    model_param=config['model_param'],\n",
        "    model=config['model_name'],\n",
        "    seed=DEFAULT_SEED,\n",
        "    sample_length=config['sample_length'],\n",
        "    max_retries=config['max_retries'],\n",
        "    config_sampling=config['sampling'])\n",
        "\n",
        "print(f'Client model metadata: {client.model_metadata}')\n",
        "\n",
        "prompt = 'Once upon a time, there was'\n",
        "results = client.sample(prompt)\n",
        "if len(results) > 0 and isinstance(results[0], LanguageResponse):\n",
        "  print(f'\\nPrompt: {prompt}\\nResponse: {results[0].text}')"
      ],
      "metadata": {
        "id": "1TeChk16H4K0",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "7f9fa32f-cab8-488c-d4b7-7f30f5868f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config:\n",
            "language_api_name: PaLM 2 / Gemini\n",
            "model_param: Generative Language API Key\n",
            "model_name: gemini-pro\n",
            "max_retries: 10\n",
            "sample_length: 511\n",
            "max_paragraph_length: 1024\n",
            "max_paragraph_length_characters: 1024\n",
            "max_paragraph_length_scenes: 1024\n",
            "sampling: {'prob': 0.9, 'temp': 1.0, 'top_k': 40}\n",
            "file_dir: None\n",
            "Client model metadata: {'engine': 'gemini-pro', 'model_param': 'Generative Language API Key', 'max_tokens': 511}\n",
            "\n",
            "Prompt: Once upon a time, there was\n",
            "Response: Once upon a time, there was a beautiful princess named Ella. She lived in a magnificent castle with her father, the king, and her stepmother, Lady Tremaine. Ella's mother had died when she was very young, and Lady Tremaine had always been cruel to her.\n",
            "\n",
            "One day, a ball was announced at the palace. All the eligible young women in the kingdom were invited, including Ella. Ella was overjoyed. She had always dreamed of going to a ball and meeting Prince Charming.\n",
            "\n",
            "But Lady Tremaine had other plans. She told Ella that she could only go to the ball if she could finish all her chores. Ella worked tirelessly, but Lady Tremaine kept adding more and more chores.\n",
            "\n",
            "Just when Ella thought all hope was lost, her Fairy Godmother appeared. The Fairy Godmother waved her magic wand and turned a pumpkin into a carriage, mice into horses, and lizards into footmen. She then gave Ella a beautiful gown and glass slippers.\n",
            "\n",
            "Ella arrived at the ball and immediately caught the prince's eye. They danced and talked for hours. Ella had never been so happy.\n",
            "\n",
            "But at midnight, Ella had to leave. As she ran down the stairs, she lost one of her glass slippers. The prince found it and vowed to find the woman who it belonged to.\n",
            "\n",
            "The prince searched the kingdom for Ella, and finally found her. They were married and lived happily ever after.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OpenAI ChatGPT API {\"run\": \"auto\"}\n",
        "\n",
        "#@markdown This cell contain code for using the [OpenAI Chat Completion API](https://platform.openai.com/docs/guides/text-generation/chat-completions-api)\n",
        "#@markdown as language model for Dramatron.<br>\n",
        "#@markdown <br>\n",
        "#@markdown Before you can use the OpenAI API, you must first obtain an API key. If you don't already have one,\n",
        "#@markdown <a class=\"button button-primary\" href=\"https://platform.openai.com/\" target=\"_blank\" rel=\"noopener noreferrer\">create an account</a>\n",
        "#@markdown then go to <a class=\"button button-primary\" href=\"https://platform.openai.com/api-keys\" target=\"_blank\" rel=\"noopener noreferrer\">API keys</a>\n",
        "#@markdown and click on `+ Create new secret key`.\n",
        "\n",
        "#@markdown See [Text Generation Models / Chat Completion API](https://platform.openai.com/docs/guides/text-generation)\n",
        "#@markdown for examples of how to call the API from Python in a colab.\n",
        "\n",
        "!pip install openai\n",
        "\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "# Initialise the OpenAI API with your OpenAI credentials.\n",
        "OPENAI_API_KEY = \"\"  # @param {type:\"string\"}\n",
        "CHATGPT_MODEL_NAME = \"gpt-4-1106-preview\" #@param [\"gpt-4-1106-preview\", \"gpt-3.5-turbo\"]\n",
        "CHATGPT_SYSTEM_PROMPT = \"You are a helpful playwright assistant.\" #@param {type:\"string\"}\n",
        "CHATGPT_FREQUENCY_PENALTY = 0.2\n",
        "CHATGPT_PRESENCE_PENALTY = 0.2\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "\n",
        "\n",
        "class OpenAIAPI(LanguageAPI):\n",
        "  \"\"\"A class wrapping the OpenAI ChatGPT language model API.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               sample_length: int,\n",
        "               model: Optional[str] = None,\n",
        "               model_param: Optional[str] = None,\n",
        "               config_sampling: Optional[dict] = None,\n",
        "               seed: Optional[int] = None,\n",
        "               max_retries: int = _MAX_RETRIES,\n",
        "               timeout: float = _TIMEOUT):\n",
        "    \"\"\"Initializer.\n",
        "\n",
        "    Args:\n",
        "      sample_length: Length of text to sample from model.\n",
        "      model: The model name to correct to. An error will be raised if it does\n",
        "        not exist.\n",
        "      model_param: Custom language model params.\n",
        "      config_sampling: ConfigDict with parameters.\n",
        "      seed: Random seed for sampling.\n",
        "      max_retries: Maximum number of retries for the remote API.\n",
        "      timeout: Maximum waiting timeout\n",
        "    \"\"\"\n",
        "    super().__init__(sample_length=sample_length,\n",
        "                     model=model,\n",
        "                     model_param=model_param,\n",
        "                     config_sampling=config_sampling,\n",
        "                     seed=seed,\n",
        "                     max_retries=max_retries,\n",
        "                     timeout=timeout)\n",
        "    self._client = OpenAI()\n",
        "\n",
        "  @property\n",
        "  def client(self):\n",
        "    return self._client\n",
        "\n",
        "  @property\n",
        "  def model_metadata(self):\n",
        "    return {'engine': self._model,\n",
        "            'model_param': self._model_param,\n",
        "            'max_tokens': self._sample_length}\n",
        "\n",
        "  def sample(self,\n",
        "             prompt: str,\n",
        "             sample_length: Optional[int] = None,\n",
        "             seed: Optional[int] = None,\n",
        "             num_samples: int = 1):\n",
        "    \"\"\"Sample model with provided prompt and optional sample_length and seed.\"\"\"\n",
        "    if sample_length is None:\n",
        "      sample_length = self._sample_length\n",
        "    response = self._client.chat.completions.create(\n",
        "        model=self._model,\n",
        "        max_tokens=sample_length,\n",
        "        temperature=self._config_sampling['temp'],\n",
        "        top_p=self._config_sampling['prob'],\n",
        "        frequency_penalty=self._config_sampling['frequency_penalty'],\n",
        "        presence_penalty=self._config_sampling['presence_penalty'],\n",
        "        messages=[\n",
        "          {\"role\": \"system\", \"content\": self._model_param},\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    response_text = ''\n",
        "    if len(response.choices) > 0:\n",
        "      response_text = response.choices[0].message.content\n",
        "    results = [LanguageResponse(text=response_text,\n",
        "                                text_length=len(response_text),\n",
        "                                prompt=prompt,\n",
        "                                prompt_length=len(prompt))]\n",
        "    return results\n",
        "\n",
        "\n",
        "# Create the config.\n",
        "config = {}\n",
        "config['language_api_name'] = 'OpenAI'\n",
        "config['model_param'] = CHATGPT_SYSTEM_PROMPT\n",
        "config['model_name'] = CHATGPT_MODEL_NAME\n",
        "config['max_retries'] = MAX_RETRIES\n",
        "config['sample_length'] = SAMPLE_LENGTH\n",
        "config['max_paragraph_length'] = MAX_PARAGRAPH_LENGTH\n",
        "config['max_paragraph_length_characters'] = MAX_PARAGRAPH_LENGTH_CHARACTERS\n",
        "config['max_paragraph_length_scenes'] = MAX_PARAGRAPH_LENGTH_SCENES\n",
        "config['sampling'] = {}\n",
        "config['sampling']['prob'] = SAMPLING_PROB\n",
        "config['sampling']['temp'] = SAMPLING_TEMP\n",
        "config['sampling']['frequency_penalty'] = CHATGPT_FREQUENCY_PENALTY\n",
        "config['sampling']['presence_penalty'] = CHATGPT_PRESENCE_PENALTY\n",
        "config['prefixes'] = {}\n",
        "config['file_dir'] = None\n",
        "\n",
        "print('Config:')\n",
        "for key, value in config.items():\n",
        "  if key != 'prefixes':\n",
        "    print(f'{key}: {value}')\n",
        "\n",
        "client = OpenAIAPI(\n",
        "    model_param=config['model_param'],\n",
        "    model=config['model_name'],\n",
        "    seed=DEFAULT_SEED,\n",
        "    sample_length=config['sample_length'],\n",
        "    max_retries=config['max_retries'],\n",
        "    config_sampling=config['sampling'])\n",
        "\n",
        "print(f'Client model metadata: {client.model_metadata}')\n",
        "\n",
        "prompt = 'Once upon a time, there was'\n",
        "results = client.sample(prompt, sample_length=256)\n",
        "if len(results) > 0 and isinstance(results[0], LanguageResponse):\n",
        "  print(f'\\nPrompt: {prompt}\\nResponse: {results[0].text}')"
      ],
      "metadata": {
        "id": "rNhsuyTR6AoS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mixtral API via Groq {\"run\": \"auto\"}\n",
        "\n",
        "#@markdown This cell contain code for using the [Groq API for chat completion](https://platform.openai.com/docs/guides/text-generation/chat-completions-api)\n",
        "#@markdown for Dramatron, with several possible language models including [Mixtral 8x7B](https://mistral.ai/news/mixtral-of-experts/).<br>\n",
        "#@markdown <br>\n",
        "#@markdown Before you can use the Groq API, you must first obtain an API key. If you don't already have one,\n",
        "#@markdown <a class=\"button button-primary\" href=\"https://console.groq.com/\" target=\"_blank\" rel=\"noopener noreferrer\">create an account</a>\n",
        "#@markdown then go to <a class=\"button button-primary\" href=\"https://console.groq.com/keys\" target=\"_blank\" rel=\"noopener noreferrer\">API keys</a>\n",
        "#@markdown and click on `Create API key`.\n",
        "\n",
        "#@markdown See [GroqCloud Documentation](https://console.groq.com/docs/quickstart)\n",
        "#@markdown for examples of how to call the API from Python in a colab.\n",
        "\n",
        "!pip install groq\n",
        "\n",
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "# Initialise the Groq API with your OpenAI credentials.\n",
        "GROQ_API_KEY = \"\"  # @param {type:\"string\"}\n",
        "GROQ_MODEL_NAME = \"mixtral-8x7b-32768\" #@param [\"mixtral-8x7b-32768\"]\n",
        "GROQ_SYSTEM_PROMPT = \"You are a creative writing assistant for a team of writers. Your goal is to expand on the input text prompt and to generate the continuation of that text without any comments. Be as creative as possible, write rich detailed descriptions and use precise language. Add new original ideas. Finish generation with **END**.\" #@param {type:\"string\"}\n",
        "GROQ_FREQUENCY_PENALTY = 0.2\n",
        "GROQ_PRESENCE_PENALTY = 0.2\n",
        "os.environ['GROQ_API_KEY'] = GROQ_API_KEY\n",
        "\n",
        "\n",
        "class GroqAPI(LanguageAPI):\n",
        "  \"\"\"A class wrapping the Groq language model API.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               sample_length: int,\n",
        "               model: Optional[str] = None,\n",
        "               model_param: Optional[str] = None,\n",
        "               config_sampling: Optional[dict] = None,\n",
        "               seed: Optional[int] = None,\n",
        "               max_retries: int = _MAX_RETRIES,\n",
        "               timeout: float = _TIMEOUT):\n",
        "    \"\"\"Initializer.\n",
        "\n",
        "    Args:\n",
        "      sample_length: Length of text to sample from model.\n",
        "      model: The model name to correct to. An error will be raised if it does\n",
        "        not exist.\n",
        "      model_param: Custom language model params.\n",
        "      config_sampling: ConfigDict with parameters.\n",
        "      seed: Random seed for sampling.\n",
        "      max_retries: Maximum number of retries for the remote API.\n",
        "      timeout: Maximum waiting timeout\n",
        "    \"\"\"\n",
        "    super().__init__(sample_length=sample_length,\n",
        "                     model=model,\n",
        "                     model_param=model_param,\n",
        "                     config_sampling=config_sampling,\n",
        "                     seed=seed,\n",
        "                     max_retries=max_retries,\n",
        "                     timeout=timeout)\n",
        "    self._client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
        "\n",
        "  @property\n",
        "  def client(self):\n",
        "    return self._client\n",
        "\n",
        "  @property\n",
        "  def model_metadata(self):\n",
        "    return {'engine': self._model,\n",
        "            'model_param': self._model_param,\n",
        "            'max_tokens': self._sample_length}\n",
        "\n",
        "  def sample(self,\n",
        "             prompt: str,\n",
        "             sample_length: Optional[int] = None,\n",
        "             seed: Optional[int] = None,\n",
        "             num_samples: int = 1):\n",
        "    \"\"\"Sample model with provided prompt and optional sample_length and seed.\"\"\"\n",
        "    if sample_length is None:\n",
        "      sample_length = self._sample_length\n",
        "    response = self._client.chat.completions.create(\n",
        "        model=self._model,\n",
        "        max_tokens=sample_length,\n",
        "        temperature=self._config_sampling['temp'],\n",
        "        top_p=self._config_sampling['prob'],\n",
        "        messages=[\n",
        "          {\"role\": \"system\", \"content\": self._model_param},\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    response_text = ''\n",
        "    if len(response.choices) > 0:\n",
        "      response_text = response.choices[0].message.content\n",
        "    results = [LanguageResponse(text=response_text,\n",
        "                                text_length=len(response_text),\n",
        "                                prompt=prompt,\n",
        "                                prompt_length=len(prompt))]\n",
        "    return results\n",
        "\n",
        "\n",
        "# Create the config.\n",
        "config = {}\n",
        "config['language_api_name'] = 'Groq'\n",
        "config['model_param'] = GROQ_SYSTEM_PROMPT\n",
        "config['model_name'] = GROQ_MODEL_NAME\n",
        "config['max_retries'] = MAX_RETRIES\n",
        "config['sample_length'] = SAMPLE_LENGTH\n",
        "config['max_paragraph_length'] = MAX_PARAGRAPH_LENGTH\n",
        "config['max_paragraph_length_characters'] = MAX_PARAGRAPH_LENGTH_CHARACTERS\n",
        "config['max_paragraph_length_scenes'] = MAX_PARAGRAPH_LENGTH_SCENES\n",
        "config['sampling'] = {}\n",
        "config['sampling']['prob'] = SAMPLING_PROB\n",
        "config['sampling']['temp'] = SAMPLING_TEMP\n",
        "config['prefixes'] = {}\n",
        "config['file_dir'] = None\n",
        "\n",
        "print('Config:')\n",
        "for key, value in config.items():\n",
        "  if key != 'prefixes':\n",
        "    print(f'{key}: {value}')\n",
        "\n",
        "client = GroqAPI(\n",
        "    model_param=config['model_param'],\n",
        "    model=config['model_name'],\n",
        "    seed=DEFAULT_SEED,\n",
        "    sample_length=config['sample_length'],\n",
        "    max_retries=config['max_retries'],\n",
        "    config_sampling=config['sampling'])\n",
        "\n",
        "print(f'Client model metadata: {client.model_metadata}')\n",
        "\n",
        "prompt = 'Once upon a time, there was'\n",
        "results = client.sample(prompt, sample_length=256)\n",
        "if len(results) > 0 and isinstance(results[0], LanguageResponse):\n",
        "  print(f'\\nPrompt: {prompt}\\nResponse: {results[0].text}')"
      ],
      "metadata": {
        "id": "xU5KZgFIrRb6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVvjeEzSRoXq"
      },
      "source": [
        "# Choose a prompt prefix set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsYTDv-5CnCF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8cab065f-fbb4-40c8-e6d9-b23f205eff32"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded medea_prefixes.\n"
          ]
        }
      ],
      "source": [
        "#@title Choose among prefix sets { run: \"auto\" }\n",
        "\n",
        "prefix_set = 'medea_prefixes' #@param ['medea_prefixes', 'scifi_prefixes', 'custom_prefixes']\n",
        "prefixes = eval(prefix_set)\n",
        "config['prefixes'] = prefixes\n",
        "\n",
        "print(f'Loaded {prefix_set}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_vuAy43H6J-"
      },
      "source": [
        "# Interactive story generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OfnN_7DqhQx7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7d188f16-32df-4334-bdac-b0ac21baddd0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Define the **Log line** { run: \"auto\" }\n",
        "\n",
        "#@markdown Log lines are one- or two-sentence summaries of the action.\n",
        "#@markdown They typically contain the **setting**, **protagonist**, **antagonist**, a **conflict** or **goal** and sometimes the **inciting incident**.\n",
        "logline = \"\" #@param {type:\"string\"}\n",
        "print(logline)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "renVLifoRbhc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f63af87-c5f5-4b40-c1f3-898d8deed150"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Dramatron generator created.\n"
          ]
        }
      ],
      "source": [
        "#@title Create the story generator\n",
        "\n",
        "#@markdown WARNING: running this cell resets the generator and all its outputs.\n",
        "\n",
        "generator = StoryGenerator(\n",
        "    storyline=logline,\n",
        "    prefixes=prefixes,\n",
        "    max_paragraph_length=config['max_paragraph_length'],\n",
        "    client=client,\n",
        "    filter=filter)\n",
        "\n",
        "print(f'New Dramatron generator created.')\n",
        "\n",
        "story = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRaJlEme-phR"
      },
      "source": [
        "## Usage\n",
        "Running each cell displays the UI and generates the first suggestion.\n",
        "\n",
        "Once you have run the cell once, you can do the following actions _without re-running the cell_:\n",
        "* Click on `Generate new` to **generate a new suggestion**.\n",
        "* Once you generated a suggestion, you can **edit the suggestion** in the text box. It is automatically saved and used in the next step.\n",
        "* Click `Continue generating` to **add to the suggestion**.\n",
        "* Once you have generated multiple suggestions, you can **navigate through the suggestion history** by clicking on `Previous` and `Next`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UYrzDgbspAG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639,
          "referenced_widgets": [
            "bd6c1e6320cc4717b63600761713526a",
            "feffbf8d6ae24c528432cfceef426f1d",
            "6ed4baaebfbd4a1192fc80fba8aca83e",
            "955a4e99ceab419f90a27436655aefa6",
            "1728d47502234ec4a715a2e0862c2ceb",
            "2f731edbb95a498a8e6e01ce5336c0a6",
            "128aafd6bb3e4ae6b38518a5ece38b20",
            "c3bc292689d4485abfd493cfcbbd1a2a",
            "b1093fc99ce94793878c38b0c4dea2ee",
            "7602635f5b9a43fc94792d502d8b99d7"
          ]
        },
        "outputId": "80727a4d-e8f3-4749-9013-3c4c4bb64e12"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Generate new', icon='check', style=ButtonStyle(), tooltip='Generate new')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd6c1e6320cc4717b63600761713526a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(Textarea(value='', description=' ', layout=Layout(height='50px', min_height='60px', widt"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "955a4e99ceab419f90a27436655aefa6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ReadTimeout",
          "evalue": "HTTPConnectionPool(host='localhost', port=38403): Read timed out. (read timeout=60.0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: timed out",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    846\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/util.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketTimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             raise ReadTimeoutError(\n\u001b[0m\u001b[1;32m    372\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Read timed out. (read timeout={timeout_value})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPConnectionPool(host='localhost', port=38403): Read timed out. (read timeout=60.0)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-363662429f35>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextarea_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mdata_title\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text_area\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_title\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mfun_generate_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_title_button\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-363662429f35>\u001b[0m in \u001b[0;36mfun_generate_title\u001b[0;34m(button)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_title\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seed\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mnew_title_button\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Generating {seed}...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mdata_title\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mnew_title_button\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Generate new\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-2c5fe92f8b82>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, level, seed, idx)\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# Step 1: Generate title given a storyline.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m       (title, titles_prefix) = generate_title(\n\u001b[0m\u001b[1;32m    926\u001b[0m           \u001b[0mstoryline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storyline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m           \u001b[0mprefixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-2c5fe92f8b82>\u001b[0m in \u001b[0;36mgenerate_title\u001b[0;34m(storyline, prefixes, client, filter, seed, num_samples)\u001b[0m\n\u001b[1;32m    557\u001b[0m   \u001b[0;31m# Combine the prompt and storyline as a helpful generation prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m   \u001b[0mtitles_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefixes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TITLES_PROMPT'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstoryline\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTITLE_ELEMENT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m   title_text = generate_text_no_loop(\n\u001b[0m\u001b[1;32m    560\u001b[0m       \u001b[0mgeneration_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtitles_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m       \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-2c5fe92f8b82>\u001b[0m in \u001b[0;36mgenerate_text_no_loop\u001b[0;34m(generation_prompt, client, filter, sample_length, max_paragraph_length, seed, num_samples)\u001b[0m\n\u001b[1;32m    536\u001b[0m                           num_samples: int = 1) -> str:\n\u001b[1;32m    537\u001b[0m   \u001b[0;34m\"\"\"Generate text using the generation prompt, without any loop.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m   return generate_text(\n\u001b[0m\u001b[1;32m    539\u001b[0m       \u001b[0mgeneration_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m       \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-2c5fe92f8b82>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(generation_prompt, client, filter, sample_length, max_paragraph_length, seed, num_samples, max_num_repetitions)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       responses = client.sample(\n\u001b[0m\u001b[1;32m    488\u001b[0m           \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m           \u001b[0msample_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-d72ede5f97ba>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, prompt, sample_length, seed, num_samples)\u001b[0m\n\u001b[1;32m    100\u001b[0m           top_k=self._config_sampling['top_k'])\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'gemini'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     results = [LanguageResponse(text=response.text,\n\u001b[1;32m    104\u001b[0m                                 \u001b[0mtext_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    263\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    792\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m             response = getattr(self._session, method)(\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;34m\"{host}{uri}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             response = super(AuthorizedSession, self).request(\n\u001b[0m\u001b[1;32m    542\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_InvalidHeader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeout\u001b[0m: HTTPConnectionPool(host='localhost', port=38403): Read timed out. (read timeout=60.0)"
          ]
        }
      ],
      "source": [
        "#@title Generate a **Title**\n",
        "\n",
        "data_title = {\"text\": \"\", \"text_area\": None, \"seed\": generator.seed - 1}\n",
        "\n",
        "def fun_generate_title(button):\n",
        "  data_title[\"seed\"] += 1\n",
        "  seed = data_title[\"seed\"]\n",
        "  new_title_button.description = f\"Generating {seed}...\"\n",
        "  generator.step(0, seed=seed)\n",
        "  data_title[\"text\"] = generator.title_str().strip()\n",
        "  new_title_button.description = \"Generate new\"\n",
        "  if data_title[\"text_area\"] is not None:\n",
        "    data_title[\"text_area\"].value = data_title[\"text\"]\n",
        "\n",
        "def fun_rewrite_title(text):\n",
        "  text_to_parse = TITLE_ELEMENT + text + END_MARKER\n",
        "  generator.rewrite(text_to_parse, level=1)\n",
        "  return text\n",
        "\n",
        "# Widget to generate new title.\n",
        "new_title_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Generate new', tooltip='Generate new', disabled=False)\n",
        "new_title_button.on_click(fun_generate_title)\n",
        "display(new_title_button)\n",
        "\n",
        "# Widget to rewrite the title.\n",
        "layout = widgets.Layout(height='50px', min_height='60px', width='auto')\n",
        "data_title[\"text_area\"] = widgets.Textarea(\n",
        "    value=data_title[\"text\"], layout=layout, description=' ',\n",
        "    style={'description_width': 'initial'})\n",
        "textarea_title = widgets.interactive(\n",
        "    fun_rewrite_title, text=data_title[\"text_area\"])\n",
        "display(textarea_title)\n",
        "data_title[\"text_area\"].value = data_title[\"text\"]\n",
        "fun_generate_title(new_title_button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq7y3NIUYtD8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757,
          "referenced_widgets": [
            "72a8efb0ad68460793ce538e85bdc7d5",
            "71711c1db88a4551aeaa3ff5ed64f8d3",
            "f3d40a66fff34f4a9ab42c8a2a475ab2",
            "525dd638b704495fba92b38118f5f71a",
            "5505253446a34ad3825a4e16412adc0a",
            "e8e154d1ed2148669c74f440d476f199",
            "ebfc575fed064c8194dcd73b11a35f4d",
            "5c96b1eef31f46e4b33c99045ce310e2",
            "263b2ed2bb95462897df35fe31d27ff2",
            "0cfc70a4dadb4c15b89aa8c1c6866bf9",
            "9410850b03864b8aa7554f42b8752ba6",
            "3ce4540a6a2c4dea8a92c43ccf2f2d49",
            "3e76183e78da463b80b264ee0ef6c009",
            "48d3ec600c824149b471af01087f75a5",
            "e2d6f2f091dd4eef85c2a10c9eef4ff3",
            "577bf89896c94f0ea48bac65411d924e",
            "8487df5549064e4cb24b7c6075514a4c",
            "a7c80e552a364709aa8bcb235d57e308",
            "aa663eb50b82445ab4cfb9288da8db05",
            "5c0677f81aff497e8f7fc3b32558d2b7",
            "803a3eb941b64391a978c958f2f2113d"
          ]
        },
        "outputId": "bf59163d-b241-423b-9cd2-42de4845dab0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Button(description='Generate new', icon='check', style=ButtonStyle(), tooltip='Generate new'), "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72a8efb0ad68460793ce538e85bdc7d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(Textarea(value='', description=' ', layout=Layout(height='390px', min_height='400px', wi"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2d6f2f091dd4eef85c2a10c9eef4ff3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-49bf7cbb0caa>\u001b[0m in \u001b[0;36m<cell line: 93>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m# Trigger generation for first seed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mfun_generate_characters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_characters_button\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-49bf7cbb0caa>\u001b[0m in \u001b[0;36mfun_generate_characters\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mnew_characters_button\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Generating {seed}...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mdata_chars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrip_remove_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharacters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Test if characters were actually generated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2c5fe92f8b82>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, level, seed, idx)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m       \u001b[0;31m# Step 2: Generate characters given a storyline.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m       (characters, character_prompts) = generate_characters(\n\u001b[0m\u001b[1;32m    941\u001b[0m           \u001b[0mstoryline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storyline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m           \u001b[0mprefixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2c5fe92f8b82>\u001b[0m in \u001b[0;36mgenerate_characters\u001b[0;34m(storyline, prefixes, client, filter, seed, max_paragraph_length, num_samples)\u001b[0m\n\u001b[1;32m    580\u001b[0m   \u001b[0;31m# Combine the prompt and storyline as a helpful generation prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m   \u001b[0mcharacters_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefixes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CHARACTERS_PROMPT'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstoryline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m   characters_text = generate_text(\n\u001b[0m\u001b[1;32m    583\u001b[0m       \u001b[0mgeneration_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcharacters_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m       \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2c5fe92f8b82>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(generation_prompt, client, filter, sample_length, max_paragraph_length, seed, num_samples, max_num_repetitions)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       responses = client.sample(\n\u001b[0m\u001b[1;32m    488\u001b[0m           \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m           \u001b[0msample_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-d72ede5f97ba>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, prompt, sample_length, seed, num_samples)\u001b[0m\n\u001b[1;32m    100\u001b[0m           top_k=self._config_sampling['top_k'])\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'gemini'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     results = [LanguageResponse(text=response.text,\n\u001b[1;32m    104\u001b[0m                                 \u001b[0mtext_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    263\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    792\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m             response = getattr(self._session, method)(\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;34m\"{host}{uri}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             response = super(AuthorizedSession, self).request(\n\u001b[0m\u001b[1;32m    542\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@title Generate **Characters**\n",
        "\n",
        "data_chars = {\"text\": \"\", \"text_area\": None, \"seed\": generator.seed - 1,\n",
        "              \"history\": GenerationHistory(), \"lock\": False}\n",
        "\n",
        "def fun_generate_characters(_):\n",
        "  data_chars[\"seed\"] += 1\n",
        "  seed = data_chars[\"seed\"]\n",
        "  data_chars[\"lock\"] = True\n",
        "  while True:\n",
        "    new_characters_button.description = f\"Generating {seed}...\"\n",
        "    generator.step(1, seed=seed)\n",
        "    data_chars[\"text\"] = strip_remove_end(generator.characters.to_string())\n",
        "    # Test if characters were actually generated.\n",
        "    if len(data_chars[\"text\"]) == 0:\n",
        "      seed += 1\n",
        "    else:\n",
        "      break\n",
        "  data_chars[\"seed\"] = seed\n",
        "  data_chars[\"history\"].add(data_chars[\"text\"], GenerationAction.NEW)\n",
        "  new_characters_button.description = \"Generate new\"\n",
        "  if data_chars[\"text_area\"] is not None:\n",
        "    data_chars[\"text_area\"].value = data_chars[\"text\"]\n",
        "  data_chars[\"lock\"] = False\n",
        "\n",
        "def fun_continue_characters(_):\n",
        "  data_chars[\"seed\"] += 1\n",
        "  seed = data_chars[\"seed\"]\n",
        "  data_chars[\"lock\"] = True\n",
        "  characters_continue_button.description = f\"Generating {seed}...\"\n",
        "  generator.complete(level=2, seed=seed, sample_length=256)\n",
        "  data_chars[\"text\"] = strip_remove_end(generator.characters.to_string())\n",
        "  data_chars[\"history\"].add(data_chars[\"text\"], GenerationAction.CONTINUE)\n",
        "  characters_continue_button.description = \"Continue generation\"\n",
        "  if data_chars[\"text_area\"] is not None:\n",
        "    data_chars[\"text_area\"].value = data_chars[\"text\"]\n",
        "  data_chars[\"lock\"] = False\n",
        "\n",
        "def fun_back_forward(data, history: GenerationHistory, delta: int):\n",
        "  data[\"lock\"] = True\n",
        "  if delta > 0:\n",
        "    data[\"text\"] = history.next()\n",
        "  if delta < 0:\n",
        "    data[\"text\"] = history.previous()\n",
        "  if data[\"text\"] is not None and data[\"text_area\"] is not None:\n",
        "      data[\"text_area\"].value = data[\"text\"]\n",
        "  data[\"lock\"] = False\n",
        "\n",
        "def fun_back_characters(_):\n",
        "  fun_back_forward(data_chars, data_chars[\"history\"], -1)\n",
        "\n",
        "def fun_forward_characters(_):\n",
        "  fun_back_forward(data_chars, data_chars[\"history\"], 1)\n",
        "\n",
        "def fun_rewrite_characters(text):\n",
        "  data_chars[\"text\"] = text\n",
        "  text_to_parse = text + END_MARKER\n",
        "  generator.rewrite(text_to_parse, level=2)\n",
        "  if data_chars[\"lock\"] is False:\n",
        "    data_chars[\"history\"].add(text, GenerationAction.REWRITE)\n",
        "  return text\n",
        "\n",
        "# Widget to generate new characters.\n",
        "new_characters_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Generate new', tooltip='Generate new', disabled=False)\n",
        "new_characters_button.on_click(fun_generate_characters)\n",
        "# Widget to continue the generation of the current characters.\n",
        "characters_continue_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Continue generation', tooltip='Continue generation',\n",
        "    disabled=False)\n",
        "characters_continue_button.on_click(fun_continue_characters)\n",
        "# Widgets to move back and forward in history of generation.\n",
        "back_characters_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Previous', tooltip='Previous', disabled=False)\n",
        "back_characters_button.on_click(fun_back_characters)\n",
        "forward_characters_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Next', tooltip='Next', disabled=False)\n",
        "forward_characters_button.on_click(fun_forward_characters)\n",
        "# Organise the widgets.\n",
        "display(widgets.HBox([new_characters_button, characters_continue_button,\n",
        "                      back_characters_button, forward_characters_button]))\n",
        "\n",
        "# Render the characters using widgets.\n",
        "layout = widgets.Layout(height='390px', min_height='400px', width='auto')\n",
        "data_chars[\"text_area\"] = widgets.Textarea(\n",
        "    value=data_chars[\"text\"], layout=layout, description=' ',\n",
        "    style={'description_width': 'initial'})\n",
        "textarea_chars = widgets.interactive(\n",
        "    fun_rewrite_characters, text=data_chars[\"text_area\"])\n",
        "display(textarea_chars)\n",
        "\n",
        "# Trigger generation for first seed.\n",
        "fun_generate_characters(new_characters_button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxtX6CxMb6tA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670,
          "referenced_widgets": [
            "5e68fd6a528744f7a1e9d1f98a1a0003",
            "fc89225355bc4413a80f04ea287b6149",
            "8e39be5a7e904601b6f165106374d869",
            "54d821a669fa4f6784de9fc83551065a",
            "93d2e39ef7264321bbc101158404dd4f",
            "187fd7a819bd4b00969f7daf8e6acadc",
            "62c3a6fd928847b09f9b60e0d5b13de3",
            "534df60f67e44c35a82c6e24b4b28f5e",
            "23e290b996834a35824181d744db4470",
            "401e8f3949084a6397f300c4f97cc355",
            "9de0ce1f3f41429a9b1f89b45907fcda",
            "519c3388ccbe426586586cfabe6dbc4f",
            "521d983e12cc42f69919f5368bff8c2e",
            "ade138bb9c0e477bb96219c3c7d755a1",
            "f5e77b3968294eab9a66b8e3688e2d8f",
            "be96a7372f5b4e3abe142e04139b154b",
            "9b6a97095e6143dd855faa6fb81b312b",
            "2cb87216e8914d478985e50714604044",
            "919217e762ef43c4b605bd1ab80b8289",
            "23aa56f2123841caad38ed641973d0b9",
            "958416d599b141aea436cccdc2c6e4df"
          ]
        },
        "outputId": "263f0d4f-8c7b-46a9-8821-524bb9ea0608"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Button(description='Generate new', icon='check', style=ButtonStyle(), tooltip='Generate new'), "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e68fd6a528744f7a1e9d1f98a1a0003"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(Textarea(value='', description=' ', layout=Layout(height='590px', min_height='600px', wi"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5e77b3968294eab9a66b8e3688e2d8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**END**\n"
          ]
        }
      ],
      "source": [
        "#@title Generate a **Plot Synopsis** (sequence of **Scenes**)\n",
        "\n",
        "data_scenes = {\"text\": None, \"text_area\": None, \"seed\": generator.seed - 1,\n",
        "               \"history\": GenerationHistory(), \"lock\": False}\n",
        "\n",
        "def fun_generate_scenes(_):\n",
        "  data_scenes[\"seed\"] += 1\n",
        "  seed = data_scenes[\"seed\"]\n",
        "  data_scenes[\"lock\"] = True\n",
        "  new_scenes_button.description = f\"Generating {seed}...\"\n",
        "  generator.step(3, seed=seed)\n",
        "  print(generator.scenes.to_string())\n",
        "  data_scenes[\"text\"] = strip_remove_end(generator.scenes.to_string())\n",
        "  data_scenes[\"history\"].add(data_scenes[\"text\"], GenerationAction.NEW)\n",
        "  new_scenes_button.description = \"Generate new\"\n",
        "  if data_scenes[\"text_area\"] is not None:\n",
        "    data_scenes[\"text_area\"].value = data_scenes[\"text\"]\n",
        "  data_scenes[\"lock\"] = False\n",
        "\n",
        "def fun_continue_scenes(_):\n",
        "  data_scenes[\"seed\"] += 1\n",
        "  seed = data_scenes[\"seed\"]\n",
        "  data_scenes[\"lock\"] = True\n",
        "  scenes_continue_button.description = f\"Generating {seed}...\"\n",
        "  generator.complete(level=3, seed=seed, sample_length=256)\n",
        "  data_scenes[\"text\"] = strip_remove_end(generator.scenes.to_string())\n",
        "  data_scenes[\"history\"].add(data_scenes[\"text\"], GenerationAction.CONTINUE)\n",
        "  scenes_continue_button.description = \"Continue generation\"\n",
        "  if data_scenes[\"text_area\"] is not None:\n",
        "    data_scenes[\"text_area\"].value = data_scenes[\"text\"]\n",
        "  data_scenes[\"lock\"] = False\n",
        "\n",
        "def fun_back_scenes(_):\n",
        "  fun_back_forward(data_scenes, data_scenes[\"history\"], -1)\n",
        "\n",
        "def fun_forward_scenes(_):\n",
        "  fun_back_forward(data_scenes, data_scenes[\"history\"], 1)\n",
        "\n",
        "def fun_rewrite_scenes(text):\n",
        "  generator.rewrite(text, level=3)\n",
        "  if data_scenes[\"lock\"] is False:\n",
        "    data_scenes[\"history\"].add(text, GenerationAction.REWRITE)\n",
        "  return text\n",
        "\n",
        "# Widget to generate new scenes.\n",
        "new_scenes_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Generate new', tooltip='Generate new', disabled=False)\n",
        "new_scenes_button.on_click(fun_generate_scenes)\n",
        "# Widget to continue the generation of the current scenes.\n",
        "scenes_continue_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Continue generation', tooltip='Continue generation',\n",
        "    disabled=False)\n",
        "scenes_continue_button.on_click(fun_continue_scenes)\n",
        "# Widgets to move back and forward in history of generation.\n",
        "back_scenes_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Previous', tooltip='Previous', disabled=False)\n",
        "back_scenes_button.on_click(fun_back_scenes)\n",
        "forward_scenes_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Next', tooltip='Next', disabled=False)\n",
        "forward_scenes_button.on_click(fun_forward_scenes)\n",
        "# Organise the widgets.\n",
        "display(widgets.HBox([new_scenes_button, scenes_continue_button,\n",
        "                      back_scenes_button, forward_scenes_button]))\n",
        "\n",
        "# Render the scenes using widgets.\n",
        "layout = widgets.Layout(height='590px', min_height='600px', width='auto')\n",
        "data_scenes[\"text_area\"] = widgets.Textarea(\n",
        "    value=data_scenes[\"text\"], layout=layout, description=' ',\n",
        "    style={'description_width': 'initial'})\n",
        "scanes_textarea = widgets.interactive(\n",
        "    fun_rewrite_scenes, text=data_scenes[\"text_area\"])\n",
        "display(scanes_textarea)\n",
        "\n",
        "# Trigger generation for first seed.\n",
        "fun_generate_scenes(new_scenes_button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YoBiBkIxQIRl"
      },
      "outputs": [],
      "source": [
        "#@title Generate **Place Descriptions**\n",
        "\n",
        "#@markdown This cell generates a description for each **Place** name in the **Plot Synopsis**. If you edit place names in the **Plot Synopsis** _after_ having run this cell, you will need to re-run this cell to update **Places**.\n",
        "\n",
        "place_names = list(set([scene.place for scene in generator.scenes[0]]))\n",
        "place_descriptions = {place_name: Place(place_name, '')\n",
        "                      for place_name in place_names}\n",
        "data_places = {\"descriptions\": place_descriptions, \"text_area\": {},\n",
        "               \"seed\": generator.seed - 1}\n",
        "\n",
        "def fun_generate_places(_):\n",
        "  data_places[\"seed\"] += 1\n",
        "  seed = data_places[\"seed\"]\n",
        "  # Update existing text areas with a waiting message.\n",
        "  new_places_button.description = f\"Generating {seed}...\"\n",
        "  # Generate all the places.\n",
        "  generator.step(3, seed=seed)\n",
        "  data_places[\"descriptions\"] = generator.places\n",
        "  new_places_button.description = \"Generate new\"\n",
        "  missing_places = {k: True for k in data_places[\"text_area\"].keys()}\n",
        "  for place_name, place_description in data_places[\"descriptions\"].items():\n",
        "    if place_name in data_places[\"text_area\"]:\n",
        "      description = place_description.description\n",
        "      data_places[\"text_area\"][place_name].value = description\n",
        "      del missing_places[place_name]\n",
        "    else:\n",
        "      print(f\"\\nWarning: [{place_name}] was added to the plot synopsis.\")\n",
        "      print(f\"Make a copy of the outputs and re-run the cell.\")\n",
        "  for place_name in missing_places:\n",
        "    data_places[\"text_area\"][place_name].value = (\n",
        "        f\"Warning: [{place_name}] was removed from the plot synopsis. \"\n",
        "        \"Make a copy of the outputs and re-run the cell.\")\n",
        "\n",
        "def fun_rewrite_places(place_name, text):\n",
        "  generator.rewrite(text, level=4, entity=place_name)\n",
        "  return text\n",
        "\n",
        "# Widget to generate new scenes.\n",
        "new_places_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Generate new', tooltip='Generate new', disabled=False)\n",
        "new_places_button.on_click(fun_generate_places)\n",
        "display(new_places_button)\n",
        "\n",
        "# Render each place using widgets.\n",
        "for place_name, place_description in data_places[\"descriptions\"].items():\n",
        "  text_place = place_description.description\n",
        "  layout = widgets.Layout(height='90px', min_height='100px', width='auto')\n",
        "  display(widgets.Label(place_name))\n",
        "  data_places[\"text_area\"][place_name] = widgets.Textarea(\n",
        "      value=text_place, layout=layout, description=' ',\n",
        "      style={'description_width': 'initial'})\n",
        "  textarea_place = widgets.interactive(\n",
        "      fun_rewrite_places, place_name=widgets.fixed(place_name),\n",
        "      text=data_places[\"text_area\"][place_name])\n",
        "  display(textarea_place)\n",
        "\n",
        "# Trigger generation for first seed.\n",
        "fun_generate_places(new_places_button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "R36-qkMAhZ7a"
      },
      "outputs": [],
      "source": [
        "#@title Generate **Dialogues**\n",
        "\n",
        "num_scenes =  generator.num_scenes()\n",
        "\n",
        "data_dialogs = {\n",
        "    \"lock\": False,\n",
        "    \"text_area\": None,\n",
        "    \"seed\": generator.seed - 1,\n",
        "    \"history\": [GenerationHistory() for _ in range(99)],\n",
        "    \"scene\": 1\n",
        "}\n",
        "\n",
        "# Ensure idx_dialog is initialize\n",
        "idx_dialog = data_dialogs[\"scene\"] - 1\n",
        "\n",
        "def fun_generate_dialog(_):\n",
        "  data_dialogs[\"seed\"] += 1\n",
        "  seed = data_dialogs[\"seed\"]\n",
        "  idx_dialog = data_dialogs[\"scene\"] - 1\n",
        "  data_dialogs[\"lock\"] = True\n",
        "  new_dialog_button.description = f\"Generating {seed}...\"\n",
        "  generator.step(4, seed=seed, idx=idx_dialog)\n",
        "  data_dialogs[\"history\"][idx_dialog].add(\n",
        "      generator.dialogs[idx_dialog], GenerationAction.NEW)\n",
        "  new_dialog_button.description = \"Generate new\"\n",
        "  if data_dialogs[\"text_area\"] is not None:\n",
        "    data_dialogs[\"text_area\"].value = generator.dialogs[idx_dialog]\n",
        "  data_dialogs[\"lock\"] = False\n",
        "\n",
        "def fun_load_dialog(scene):\n",
        "  idx_dialog = scene - 1\n",
        "  scene_exists = (\n",
        "      len(generator.dialogs) > idx_dialog and\n",
        "      len(generator.dialogs[idx_dialog]) > 0)\n",
        "  # Update existing text area with a waiting message or load existing scene.\n",
        "  if scene_exists:\n",
        "    data_dialogs[\"lock\"] = True\n",
        "    if data_dialogs[\"text_area\"] is not None:\n",
        "      data_dialogs[\"text_area\"].value = generator.dialogs[idx_dialog]\n",
        "    data_dialogs[\"scene\"] = scene\n",
        "    data_dialogs[\"lock\"] = False\n",
        "  else:\n",
        "    data_dialogs[\"scene\"] = scene\n",
        "    fun_generate_dialog(None)\n",
        "\n",
        "def fun_continue_dialog(_):\n",
        "  data_dialogs[\"seed\"] += 1\n",
        "  seed = data_dialogs[\"seed\"]\n",
        "  idx_dialog = data_dialogs[\"scene\"] - 1\n",
        "  data_dialogs[\"lock\"] = True\n",
        "  dialog_continue_button.description = f\"Generating {seed}...\"\n",
        "  generator.complete(level=5, seed=seed, entity=idx_dialog,\n",
        "                     sample_length=SAMPLE_LENGTH)\n",
        "  data_dialogs[\"history\"][idx_dialog].add(\n",
        "      generator.dialogs[idx_dialog], GenerationAction.CONTINUE)\n",
        "  dialog_continue_button.description = \"Continue generation\"\n",
        "  if data_dialogs[\"text_area\"] is not None:\n",
        "    data_dialogs[\"text_area\"].value = generator.dialogs[idx_dialog]\n",
        "  data_dialogs[\"lock\"] = False\n",
        "\n",
        "def fun_back_dialog(_):\n",
        "  idx_dialog = data_dialogs[\"scene\"] - 1\n",
        "  if idx_dialog >= 0 and idx_dialog < len(data_dialogs[\"history\"]):\n",
        "    fun_back_forward(data_dialogs, data_dialogs[\"history\"][idx_dialog], -1)\n",
        "\n",
        "def fun_forward_dialog(_):\n",
        "  idx_dialog = data_dialogs[\"scene\"] - 1\n",
        "  if idx_dialog >= 0 and idx_dialog < len(data_dialogs[\"history\"]):\n",
        "    fun_back_forward(data_dialogs, data_dialogs[\"history\"][idx_dialog], 1)\n",
        "\n",
        "# Function to edit the specific dialog.\n",
        "def fun_rewrite_dialog(text):\n",
        "  if data_dialogs[\"lock\"] == False:\n",
        "    idx_dialog = data_dialogs[\"scene\"] - 1\n",
        "    generator.rewrite(text, level=5, entity=idx_dialog)\n",
        "  return text\n",
        "\n",
        "# Widget to choose a seed and generate new scenes.\n",
        "scene_slider = widgets.IntSlider(\n",
        "    description='scene', min=1, max=generator.num_scenes())\n",
        "widgets.interactive(fun_load_dialog, scene=scene_slider)\n",
        "\n",
        "# Widget to generate new dialogue.\n",
        "new_dialog_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Generate new', tooltip='Generate new', disabled=False)\n",
        "new_dialog_button.on_click(fun_generate_dialog)\n",
        "# Widget to continue the generation of the current dialogue.\n",
        "dialog_continue_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Continue generation', tooltip='Continue generation',\n",
        "    disabled=False)\n",
        "dialog_continue_button.on_click(fun_continue_dialog)\n",
        "# Widgets to move back and forward in history of generation.\n",
        "back_dialog_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Previous', tooltip='Previous', disabled=False)\n",
        "back_dialog_button.on_click(fun_back_dialog)\n",
        "forward_dialog_button = widgets.Button(button_style='', icon='check',\n",
        "    description='Next', tooltip='Next', disabled=False)\n",
        "forward_dialog_button.on_click(fun_forward_dialog)\n",
        "# Organise the widgets.\n",
        "display(widgets.HBox([scene_slider, new_dialog_button, dialog_continue_button,\n",
        "                      back_dialog_button, forward_dialog_button]))\n",
        "\n",
        "# Render the dialog using widgets.\n",
        "layout = widgets.Layout(height='600px', width='auto')\n",
        "data_dialogs[\"text_area\"] = widgets.Textarea(\n",
        "    value=strip_remove_end(generator.dialogs[idx_dialog]), layout=layout,\n",
        "    description=' ')\n",
        "textarea_dialogs = widgets.interactive(\n",
        "    fun_rewrite_dialog, text=data_dialogs[\"text_area\"])\n",
        "display(textarea_dialogs)\n",
        "\n",
        "# Trigger generation for first seed.\n",
        "fun_generate_dialog(new_dialog_button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2MpykfCqO85"
      },
      "outputs": [],
      "source": [
        "#@title Render the script\n",
        "\n",
        "#@markdown Run this cell to render the whole story as a text string. This cells also renders all the edits and prefixes as text strings.\n",
        "\n",
        "# Render the story.\n",
        "story = generator.get_story()\n",
        "script_text = render_story(story)\n",
        "print(script_text)\n",
        "\n",
        "# Render the prompts.\n",
        "prefix_text = render_prompts(generator.prompts)\n",
        "\n",
        "# Render the interventions.\n",
        "edits_text = ''\n",
        "for timestamp in sorted(generator.interventions):\n",
        "  edits_text += 'EDIT @ ' + str(timestamp) + '\\n'\n",
        "  edits_text += generator.interventions[timestamp] + '\\n\\n\\n'\n",
        "\n",
        "# Prepare the filenames for saving the story and prompts.\n",
        "timestamp_generation = datetime.datetime.now().strftime('%Y_%m_%d-%I_%M_%S_%p')\n",
        "title_ascii = re.sub('[^0-9a-zA-Z]+', '_',\n",
        "                     generator.title_str().strip()).lower()\n",
        "filename_script = f'{title_ascii}_{timestamp_generation}_script.txt'\n",
        "filename_prefix = f'{title_ascii}_{timestamp_generation}_prefix.txt'\n",
        "filename_edits = f'{title_ascii}_{timestamp_generation}_edits.txt'\n",
        "filename_config = f'{title_ascii}_{timestamp_generation}_config.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MPYk-Yp4EtW-"
      },
      "outputs": [],
      "source": [
        "#@title Save to Google Drive\n",
        "\n",
        "#@markdown Run this cell to save script, prefixes, edits and config as 4 text files on Google Drive under `dir_drive`.\n",
        "\n",
        "# Mount the Google Drive.\n",
        "import os\n",
        "import json\n",
        "from os import path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "path_drive = '/content/gdrive/My Drive/'\n",
        "\n",
        "dir_drive = 'Dramatron_Outputs' #@param {type:\"string\"}\n",
        "config['file_dir'] = path_drive + dir_drive + \"/\"\n",
        "if not path.exists(config['file_dir']):\n",
        "  os.mkdir(config['file_dir'])\n",
        "  print(f\"Created directory: {config['file_dir']}\")\n",
        "\n",
        "print(f\"Outputs saved to: {config['file_dir']}\")\n",
        "\n",
        "# Save the script and prompt.\n",
        "path_script = config['file_dir'] + filename_script\n",
        "with open(path_script, 'wt') as f:\n",
        "  f.write(script_text)\n",
        "  print(f'Script saved to: {path_script}')\n",
        "\n",
        "path_prefix = config['file_dir'] + filename_prefix\n",
        "with open(path_prefix, 'wt') as f:\n",
        "  f.write(prefix_text)\n",
        "  print(f'Prefixes saved to: {path_prefix}')\n",
        "\n",
        "path_edits = config['file_dir'] + filename_edits\n",
        "with open(path_edits, 'wt') as f:\n",
        "  f.write(edits_text)\n",
        "  print(f'Edits saved to: {path_edits}')\n",
        "\n",
        "path_config = config['file_dir'] + filename_config\n",
        "with open(path_config, 'wt') as f:\n",
        "  config_clean = config.copy()\n",
        "  config_clean.pop('prefixes', None)\n",
        "  config_clean.pop('model_api_key', None)\n",
        "  json.dump(config_clean, f)\n",
        "  print(f'Config saved to: {path_config}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SiVzyJEZHyMs",
        "3OAW4PeE1z7N"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "72a8efb0ad68460793ce538e85bdc7d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71711c1db88a4551aeaa3ff5ed64f8d3",
              "IPY_MODEL_f3d40a66fff34f4a9ab42c8a2a475ab2",
              "IPY_MODEL_525dd638b704495fba92b38118f5f71a",
              "IPY_MODEL_5505253446a34ad3825a4e16412adc0a"
            ],
            "layout": "IPY_MODEL_e8e154d1ed2148669c74f440d476f199"
          }
        },
        "71711c1db88a4551aeaa3ff5ed64f8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Generating 1...",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_ebfc575fed064c8194dcd73b11a35f4d",
            "style": "IPY_MODEL_5c96b1eef31f46e4b33c99045ce310e2",
            "tooltip": "Generate new"
          }
        },
        "f3d40a66fff34f4a9ab42c8a2a475ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Continue generation",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_263b2ed2bb95462897df35fe31d27ff2",
            "style": "IPY_MODEL_0cfc70a4dadb4c15b89aa8c1c6866bf9",
            "tooltip": "Continue generation"
          }
        },
        "525dd638b704495fba92b38118f5f71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Previous",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_9410850b03864b8aa7554f42b8752ba6",
            "style": "IPY_MODEL_3ce4540a6a2c4dea8a92c43ccf2f2d49",
            "tooltip": "Previous"
          }
        },
        "5505253446a34ad3825a4e16412adc0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Next",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_3e76183e78da463b80b264ee0ef6c009",
            "style": "IPY_MODEL_48d3ec600c824149b471af01087f75a5",
            "tooltip": "Next"
          }
        },
        "e8e154d1ed2148669c74f440d476f199": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebfc575fed064c8194dcd73b11a35f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c96b1eef31f46e4b33c99045ce310e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "263b2ed2bb95462897df35fe31d27ff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cfc70a4dadb4c15b89aa8c1c6866bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9410850b03864b8aa7554f42b8752ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ce4540a6a2c4dea8a92c43ccf2f2d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3e76183e78da463b80b264ee0ef6c009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48d3ec600c824149b471af01087f75a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "e2d6f2f091dd4eef85c2a10c9eef4ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_577bf89896c94f0ea48bac65411d924e",
              "IPY_MODEL_8487df5549064e4cb24b7c6075514a4c"
            ],
            "layout": "IPY_MODEL_a7c80e552a364709aa8bcb235d57e308"
          }
        },
        "577bf89896c94f0ea48bac65411d924e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": " ",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_aa663eb50b82445ab4cfb9288da8db05",
            "placeholder": "",
            "rows": null,
            "style": "IPY_MODEL_5c0677f81aff497e8f7fc3b32558d2b7",
            "value": ""
          }
        },
        "8487df5549064e4cb24b7c6075514a4c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_803a3eb941b64391a978c958f2f2113d",
            "msg_id": "",
            "outputs": []
          }
        },
        "a7c80e552a364709aa8bcb235d57e308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa663eb50b82445ab4cfb9288da8db05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "390px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": "400px",
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "5c0677f81aff497e8f7fc3b32558d2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "803a3eb941b64391a978c958f2f2113d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e68fd6a528744f7a1e9d1f98a1a0003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc89225355bc4413a80f04ea287b6149",
              "IPY_MODEL_8e39be5a7e904601b6f165106374d869",
              "IPY_MODEL_54d821a669fa4f6784de9fc83551065a",
              "IPY_MODEL_93d2e39ef7264321bbc101158404dd4f"
            ],
            "layout": "IPY_MODEL_187fd7a819bd4b00969f7daf8e6acadc"
          }
        },
        "fc89225355bc4413a80f04ea287b6149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Generate new",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_62c3a6fd928847b09f9b60e0d5b13de3",
            "style": "IPY_MODEL_534df60f67e44c35a82c6e24b4b28f5e",
            "tooltip": "Generate new"
          }
        },
        "8e39be5a7e904601b6f165106374d869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Continue generation",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_23e290b996834a35824181d744db4470",
            "style": "IPY_MODEL_401e8f3949084a6397f300c4f97cc355",
            "tooltip": "Continue generation"
          }
        },
        "54d821a669fa4f6784de9fc83551065a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Previous",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_9de0ce1f3f41429a9b1f89b45907fcda",
            "style": "IPY_MODEL_519c3388ccbe426586586cfabe6dbc4f",
            "tooltip": "Previous"
          }
        },
        "93d2e39ef7264321bbc101158404dd4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Next",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_521d983e12cc42f69919f5368bff8c2e",
            "style": "IPY_MODEL_ade138bb9c0e477bb96219c3c7d755a1",
            "tooltip": "Next"
          }
        },
        "187fd7a819bd4b00969f7daf8e6acadc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62c3a6fd928847b09f9b60e0d5b13de3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "534df60f67e44c35a82c6e24b4b28f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "23e290b996834a35824181d744db4470": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "401e8f3949084a6397f300c4f97cc355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9de0ce1f3f41429a9b1f89b45907fcda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "519c3388ccbe426586586cfabe6dbc4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "521d983e12cc42f69919f5368bff8c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade138bb9c0e477bb96219c3c7d755a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f5e77b3968294eab9a66b8e3688e2d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be96a7372f5b4e3abe142e04139b154b",
              "IPY_MODEL_9b6a97095e6143dd855faa6fb81b312b"
            ],
            "layout": "IPY_MODEL_2cb87216e8914d478985e50714604044"
          }
        },
        "be96a7372f5b4e3abe142e04139b154b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": " ",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_919217e762ef43c4b605bd1ab80b8289",
            "placeholder": "",
            "rows": null,
            "style": "IPY_MODEL_23aa56f2123841caad38ed641973d0b9",
            "value": ""
          }
        },
        "9b6a97095e6143dd855faa6fb81b312b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_958416d599b141aea436cccdc2c6e4df",
            "msg_id": "",
            "outputs": []
          }
        },
        "2cb87216e8914d478985e50714604044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "919217e762ef43c4b605bd1ab80b8289": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "590px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": "600px",
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "23aa56f2123841caad38ed641973d0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "958416d599b141aea436cccdc2c6e4df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd6c1e6320cc4717b63600761713526a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Generating 1...",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_feffbf8d6ae24c528432cfceef426f1d",
            "style": "IPY_MODEL_6ed4baaebfbd4a1192fc80fba8aca83e",
            "tooltip": "Generate new"
          }
        },
        "feffbf8d6ae24c528432cfceef426f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ed4baaebfbd4a1192fc80fba8aca83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "955a4e99ceab419f90a27436655aefa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1728d47502234ec4a715a2e0862c2ceb",
              "IPY_MODEL_2f731edbb95a498a8e6e01ce5336c0a6"
            ],
            "layout": "IPY_MODEL_128aafd6bb3e4ae6b38518a5ece38b20"
          }
        },
        "1728d47502234ec4a715a2e0862c2ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": " ",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c3bc292689d4485abfd493cfcbbd1a2a",
            "placeholder": "",
            "rows": null,
            "style": "IPY_MODEL_b1093fc99ce94793878c38b0c4dea2ee",
            "value": ""
          }
        },
        "2f731edbb95a498a8e6e01ce5336c0a6": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_7602635f5b9a43fc94792d502d8b99d7",
            "msg_id": "",
            "outputs": []
          }
        },
        "128aafd6bb3e4ae6b38518a5ece38b20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3bc292689d4485abfd493cfcbbd1a2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "50px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": "60px",
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "b1093fc99ce94793878c38b0c4dea2ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "7602635f5b9a43fc94792d502d8b99d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}